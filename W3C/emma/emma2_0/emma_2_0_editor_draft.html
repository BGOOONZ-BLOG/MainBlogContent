<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0041) -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="HTML Tidy for Linux/x86 (vers 1 September 2005), see www.w3.org">

<title>EMMA: Extensible MultiModal Annotation markup language Version 1.1</title>

<style type="text/css">
/*<![CDATA[*/
span.term {
  color: rgb(0,0,192);
  font-style: italic
  }
blockquote { margin-left: 4% }
.toc { list-style-type: none; marker-offset: 1em }
.tocline { list-style-type: none }
ul.toc a { text-decoration: none }
.fig { text-align: center }
pre { font-family: monospace }
pre.example {
  margin-left: 0;
  padding: 0.5em;
  width: 98%;
  font-family: monospace;
  white-space: pre;
  border: none;
  font-size: 95%;
  background-color: rgb(230,230,255);
  }
.note { color: red }
.new { color: green;} 
/*.new { color: black;} */
.old { text-decoration: line-through }
/*.old { display: none }*/
.newer { text-decoration: underline }
.change { color: red }
.changeTable { color: orange }
.remove { text-decoration: line-through }
div.issues {
  border-width: thin;
  border-style: solid;
  border-color: maroon;
  background-color: #FFEECC;
  color: maroon;
  width: 95%; padding: 0.5em; }
div.issues h4 { margin-top: 0 }
code {
  font-weight:bold;
  color: green;
  font-family: monospace;
  font-size: 110%;
  }
.good {
  border: green 2px solid;
  font-weight: bold;
  color: green;
  margin: 1em 5% 1em 0px;
  }
.bad {
  border: red 2px solid;
  font-weight: bold;
  color: rgb(192,101,101);
  margin: 1em 5% 1em 0px;
  }
div.navbar { text-align: center }
div.contents {
  border: medium none;
  padding: 0.5em;
  margin-right: 5%;
  background-color: rgb(230,230,255);
  }
table.exceptions {
  background-color: rgb(255,255,153)
  }
table.modes { font-size: 90% }
table.defn {
  border-width: thin;
  border-style: solid;
  border-color: black;
  color: black
  }
table.defn th { background-color: rgb(220,220,255);
  border-style: solid; border-color: black; border-width: thin }
table.defn td { background-color: rgb(230,230,255);
  border-style: solid; border-color: black; border-width: thin }
.diff { color: rgb(128,0,0) }
.reqs {  color: blue; font-style: italic  }
.editorial { color: maroon; font-style: italic }
/*]]>*/
</style>
<link href="W3C-WD.css" type="text/css" rel="stylesheet">

<!--<link rel="stylesheet" type="text/css" href=
"http://www.w3.org/StyleSheets/TR/W3C-REC.css" />-->

</head>
<body>
<div class="head">
<div class="banner"><a href="http://www.w3.org/"><img alt="W3C" src="w3c_home" width="72" height="48"></a></div>
<h1 class="notoc" id="s0">EMMA: Extensible MultiModal Annotation
markup language Version 2.0</h1>
<h2><a id="w3c-doctype" name="w3c-doctype"><acronym title="World Wide Web Consortium">W3C</acronym> Working Draft @@ June 2015</a></h2>
<dl>
<dt>This version:</dt>
<dd>&nbsp;</dd>
<dt>Latest version:</dt>
<dd><a href="http://www.w3.org/TR/emma11/">
http://www.w3.org/TR/emma20</a></dd>
<dt>Previous version:</dt>
<dd>&nbsp;</dd>
</dl>
<dl>
<dt>Editor:</dt>
<dd>Michael Johnston (Interactions Corporation)</dd>
<dt>Authors:</dt>
<dd>&nbsp;</dd>
<dd>Deborah A. Dahl (W3C Invited Expert)</dd>
<dd>Tim Denney (Boeing Corporation)</dd>
<dd>&nbsp;</dd>
<dd> Nagesh Kharidi (Openstream) </dd>
<dt>&nbsp;</dt>
</dl>

<p class="copyright"><a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> ©
2015 <a href="http://www.w3.org/"><acronym title="World Wide Web Consortium">W3C</acronym></a><sup>®</sup> (<a href="http://www.csail.mit.edu/"><acronym title="Massachusetts Institute of Technology">MIT</acronym></a>, <a href="http://www.ercim.eu/"><acronym title="European Research Consortium for Informatics and Mathematics">ERCIM</acronym></a>,
<a href="http://www.keio.ac.jp/">Keio</a>,
<a href="http://ev.buaa.edu.cn/">Beihang</a>), All Rights Reserved. W3C <a href="http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>,
<a href="http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a>
and <a href="http://www.w3.org/Consortium/Legal/copyright-documents">document
use</a> rules apply.</p>

<hr title="Separator for header"></div>
<h2 class="notoc" id="abstract">Abstract</h2>
<p>The W3C Multimodal Interaction Working Group aims to develop
specifications to enable access to the Web using multimodal
interaction. This document is part of a set of specifications for
multimodal systems, and provides details of an XML markup language
for containing and annotating the interpretation of user input and production of system output.
Examples of interpretation of user input are a transcription into
words of a raw signal, for instance derived from speech, pen or
keystroke input, a set of attribute/value pairs describing their
meaning, or a set of attribute/value pairs describing a gesture.
The interpretation of the user's input is expected to be generated
by signal interpretation processes, such as speech and ink
recognition, semantic interpreters, and other types of processors
for use by components that act on the user's inputs such as
interaction managers. Examples of stages in the production of a system output, are creation of a semantic representation, an assignment of that representation to a particular modality or modalities, and a surface string for realization by, for example, a text-to-speech engine. The production of the system's output is expected to be generated by output production processes, such as a dialog manager, multimodal presentation planner, content planner, and other types of processors such as surface generation.</p>
<h2 id="status">Status of this Document</h2>
<p><em>This section describes the status of this document at the
time of its publication. Other documents may supersede this
document. A list of current W3C publications and the latest
revision of this technical report can be found in the <a href="http://www.w3.org/TR/">W3C technical reports index</a> at
http://www.w3.org/TR/.</em></p>

<p>This is the @@ June 2015 Working Draft of "EMMA:
Extensible MultiModal Annotation markup language Version 2.0".

It has been produced by the
    <a href="http://www.w3.org/2002/mmi/">Multimodal Interaction Working Group</a>,
which is part of the
    <a href="http://www.w3.org/2002/mmi/Activity.html">Multimodal Interaction Activity</a>.
</p>


<p>This specification describes markup for representing
  interpretations of user input (speech, keystrokes, pen input etc.) and productions of system output together with annotations for confidence scores, timestamps, medium etc., and forms part of the proposals for the <a href="http://www.w3.org/TR/mmi-framework/">W3C Multimodal Interaction
Framework</a>.</p>
<p>The <a href="http://www.w3.org/TR/EMMA">EMMA: Extensible Multimodal Annotation 1.0</a> specification was published as a W3C Recommendation in February 2009. Since then there have been numerous implementations of the standard and extensive feedback has come in regarding desired new features and clarifications requested for existing features. The W3C Multimodal Interaction Working Group  examined a range of different use cases for extensions of the EMMA specification and published a W3C Note on Use Cases for Possible Future EMMA Features [<a href="emma_use_cases">EMMA Use Cases</a>]. In this working draft of EMMA 2.0, we have developed a set of new features based on feedback from implementers and have also added clarification text in a number of places throughout the specification. The new features include: support for adding human annotations (<code>emma:annotation</code>, <code>emma:annotated-tokens</code>), support for inline specification of process parameters (<code>emma:parameters</code>, <code>emma:parameter</code>, <code>emma:parameter-ref</code>), support for specification of models used in processing beyond grammars (<code>emma:process-model</code>, <code>emma:process-model-ref</code>), extensions to <code>emma:grammar</code> to enable inline specification of grammars, a new mechanism for indicating which grammars are active (<code>emma:grammar-active</code>, <code>emma:active</code>), support for non-XML semantic payloads (<code>emma:result-format</code>), support for multiple <code>emma:info</code> elements and reference to the <code>emma:info</code> relevant to an interpretation (<code>emma:info-ref</code>), and a new attribute to complement the <code>emma:medium</code> and <code>emma:mode</code> attributes that enables specification of the modality used to express an input (<code>emma:expressed-through</code>). 
In addition we have extended the specification to handle the production of system output, by adding the new element, <code>emma:output</code> and added a series of annotations enabling the use of EMMA for incremental results (Section 4.2.24). 
<p>Not addressed in this draft, but planned for a later Working Draft of EMMA 2.0, is a JSON serialization of EMMA documents for use in contexts were JSON is better suited than XML for representing user inputs and system outputs.</p>
<h3>Changes from the last working draft</h3>
<p >This working draft also adds a new <code>emma:location</code> element for specification of the location of the device or sensor which captured the input. The  <code>ref</code> attribute was added to a number of elements allowing for shorter EMMA documents which use URIs to point to content stored outside of the document: <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:group</code>, <code>emma:info</code>, <code>emma:parameters</code>, <code>emma:lattice</code>. A new attribute <code>emma:partial-content</code> is introduced which indicates whether the content in an element with <code>ref</code>, is the full content or whether it is partial and more can be retrieved by following the URI in <code>ref</code>. The <code>emma:emma</code> element is extended with <code>doc-ref</code> and <code>prev-doc</code> attributes that indicate where the document can be retrieved from and where the previous document in a sequence of inputs can be retrieved from. The application of <code>emma:lattice</code> is also extended so that an EMMA document can contain both a N-best and a lattice side-by-side. A new Section 3.3 includes an initial proposal for the extension of EMMA to output and the new element <code>emma:output</code>. A new Section 4.2.24 describes new attributes that extend EMMA so that it support incremental results.</p>

<p>
A <a href="diff.html">diff-marked version</a> from EMMA 1.1
is available for comparison purposes.

Also changes from EMMA 1.0 can be found in <a href="#appF">Appendix F</a>.
</p>

<p>Comments are welcome on <a href="mailto:www-multimodal@w3.org">www-multimodal@w3.org</a>
  (<a href="http://lists.w3.org/Archives/Public/www-multimodal/">archive</a>).
  
  See <a href="http://www.w3.org/Mail/">W3C mailing list and archive
    usage guidelines</a>.</p>
<p>This document was produced by a group operating under the
  <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/">5
  February 2004 W3C Patent Policy</a>. W3C maintains a <a rel="disclosure" href="http://www.w3.org/2004/01/pp-impl/34607/status">public list of any
      patent disclosures</a> made in connection with the deliverables of
  the group; that page also includes instructions for disclosing a
  patent. An individual who has actual knowledge of a patent which
  the individual believes contains <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#def-essential">
  Essential Claim(s)</a> must disclose the information in accordance
  with <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#sec-Disclosure">
section 6 of the W3C Patent Policy</a>.</p>

<p>The sections in the main body of this document are normative unless
otherwise specified.  The appendices in this document are informative
unless otherwise indicated explicitly.</p>


<h2 class="notoc" id="conv">Conventions of this Document</h2>
<p>All sections in this specification are normative, unless
otherwise indicated. The informative parts of this specification
are identified by "Informative" labels within sections.</p>
<p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL
NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL"
in this document are to be interpreted as described in [<a href="#ref-rfc2119">RFC2119</a>].</p>
<h2 class="notoc" id="toc">Table of Contents</h2>
<ul class="tocline">
<li>1. <a href="#s1">Introduction</a>
<ul class="tocline">
<li>1.1 <a href="#s1.1">Uses of EMMA</a></li>
<li>1.2 <a href="#s1.2">Terminology</a></li>
</ul>
</li>
<li>2. <a href="#s2">Structure of EMMA documents</a>
<ul class="tocline">
<li>2.<span>1</span> <a href="#s2.1">Data model</a></li>
<li>2.<span>2</span> <a href="#s2.2">EMMA namespace
prefixes</a></li>
</ul>
</li>
<li>3. <a href="#s3">EMMA structural elements</a>
<ul class="tocline">
<li>3.1 <a href="#s3.1">Root element:
<code>emma:emma</code></a></li>
<li>3.2 <a href="#s3.2">Interpretation element:
<code>emma:interpretation</code></a></li>
<li>3.3 <a href="#s3.3">Output: <code>emma:output</code></a></li>
<li>3.4 <a href="#s3.4">Container elements</a>
  <ul class="tocline">
<li>3.4.1 <a href="#s3.4.1"><code>emma:one-of</code>
element</a></li>
<li>3.4.2 <a href="#s3.4.2"><code>emma:group</code> element</a>
  <ul class="tocline">
<li>3.4.2.1 <a href="#s3.4.2.1">Indirect grouping criteria:
<code>emma:group-info</code> element</a></li>
</ul>
</li>
<li>3.4.3 <a href="#s3.4.3"><code>emma:sequence</code>
element</a></li>
</ul>
</li>
<li>3.5 <a href="#s3.5">Lattice element</a>
  <ul class="tocline">
<li>3.5.1 <a href="#s3.5.1">Lattice markup:
<code>emma:lattice</code>, <code>emma:arc</code>,
<code>emma:node</code> elements</a></li>
<li>3.5.2 <a href="#s3.5.2">Annotations on lattices</a></li>
<li>3.5.3 <a href="#s3.5.3">Relative timestamps on
lattices</a></li>
</ul>
</li>
<li>3.6 <a href="#s3.6">Literal semantics:
<code>emma:literal</code> element</a></li>
</ul>
</li>
<li>4 <a href="#s4">EMMA annotations</a>
<ul class="tocline">
<li>4.1 <a href="#s4.1">EMMA annotation elements</a>
<ul class="tocline">
<li>4.1.1 <a href="#s4.1.1">Data model: <code>emma:model</code>
element</a></li>
<li>4.1.2 <a href="#s4.1.2">Interpretation derivation:
<code>emma:derived-from</code> element and
<code>emma:derivation</code> element</a></li>
<li>4.1.3 <a href="#s4.1.3">Reference to grammar used:
<code>emma:grammar</code> element</a></li>
<li>4.1.4 <a href="#s4.1.4">Reference to grammars active: <code>emma:grammar-active</code> element</a></li>
<li>4.1.5 <a href="#s4.1.5">Extensibility to application/vendor
specific annotations: <code>emma:info</code> element</a></li>
<li>4.1.6 <a href="#s4.1.6">Endpoint reference:
<code>emma:endpoint-info</code> element and
<code>emma:endpoint</code> element</a></li>
<li>4.1.7 <a href="#s4.1.7">Reference to process model used: <code>emma:process-model</code> element</a></li>
<li>4.1.8 <a href="#s4.1.8">Reference parameters used by a process: <code>emma:parameters</code> and <code>emma:parameter</code> elements</a></li>
<li>4.1.9 <a href="#s4.1.9">Human annotation: <code>emma:annotation</code><code></code> element</a></li>
<li>4.1.10 <a href="#s4.1.10" >Location: <code>emma:location</code> element</a></li>
</ul>
</li>
<li>4.2 <a href="#s4.2">EMMA annotation attributes</a>
<ul class="tocline">
<li>4.2.1 <a href="#s4.2.1">Tokens of input:
      <code>emma:tokens</code>, <code>emma:token-type</code> and <code>emma:token-score</code> attributes</a></li>
<li>4.2.2 <a href="#s4.2.2">Reference to processing:
<code>emma:process</code> attribute</a></li>
<li>4.2.3 <a href="#s4.2.3">Lack of input:
<code>emma:no-input</code> attribute</a></li>
<li>4.2.4 <a href="#s4.2.4">Uninterpreted input:
<code>emma:uninterpreted</code> attribute</a></li>
<li>4.2.5 <a href="#s4.2.5">Human language of input:
<code>emma:lang</code> attribute</a></li>
<li>4.2.6 <a href="#s4.2.6">Reference to signal:
<code>emma:signal</code> <span>and
<code>emma:signal-size</code></span> attributes</a></li>
<li>4.2.7 <a href="#s4.2.7">Media type:
<code>emma:media-type</code> attribute</a></li>
<li>4.2.8 <a href="#s4.2.8">Confidence scores:
<code>emma:confidence</code> attribute</a></li>
<li>4.2.9 <a href="#s4.2.9">Input source: <code>emma:source</code>
attribute</a></li>
<li>4.2.10 <a href="#s4.2.10">Timestamps</a>
<ul class="tocline">
<li>4.2.10.1 <a href="#s4.2.10.1">Absolute timestamps:
<code>emma:start</code>, <code>emma:end</code> attributes</a></li>
<li>4.2.10.2 <a href="#s4.2.10.2">Relative timestamps:
<code>emma:time-ref-uri</code>,
<code>emma:time-ref-anchor-point</code>,
<code>emma:offset-to-start</code> attributes</a></li>
<li>4.2.10.3 <a href="#s4.2.10.3">Duration of input:
<code>emma:duration</code> attribute</a></li>
<li>4.2.10.4 <a href="#s4.2.10.4">Composite Input and
Relative Timestamps</a></li>
</ul>
</li>
<li>4.2.11 <a href="#s4.2.11">Medium, mode, and function of user
inputs: <code>emma:medium</code>, <code>emma:mode</code>,
<code>emma:function</code>, <code>emma:verbal,emma:device-type,</code> and <code>emma:expressed-through</code>
attributes</a></li>
<li>4.2.12 <a href="#s4.2.12">Composite multimodality:
<code>emma:hook</code> attribute</a></li>
<li>4.2.13 <a href="#s4.2.13">Cost: <code>emma:cost</code>
attribute</a></li>
<li>4.2.14 <a href="#s4.2.14">Endpoint properties:
<code>emma:endpoint-role</code>,
<code>emma:endpoint-address</code>, <code>emma:port-type</code>,
<code>emma:port-num</code>, <code>emma:message-id</code>,
<code>emma:service-name</code>, <code>emma:endpoint-pair-ref</code>,
<code>emma:endpoint-info-ref</code>
attributes</a></li>
<li>4.2.15 <a href="#s4.2.15">Reference to
<code>emma:grammar</code> element: <code>emma:grammar-ref</code>
attribute</a></li>
<li>4.2.16 <a href="#s4.2.16">Reference to <code>emma:model</code>
element: <code>emma:model-ref</code> attribute</a></li>
<li>4.2.17 <a href="#s4.2.17">Dialog turns:
<code>emma:dialog-turn</code> attribute</a></li>
<li>4.2.18 <a href="#s4.2.18">Semantic representation type:
<code>emma:output-format</code> attribute</a></li>
<li>4.2.19 <a href="#s4.2.19">Reference to <code>emma:info</code> element: <code>emma:info-ref</code> attribute</a></li>
<li>4.2.20 <a href="#s4.2.20">Reference to <code>emma:process-model</code> element: <code>emma:process-model-ref</code> attribute</a></li>
<li>4.2.21 <a href="#s4.2.21">Reference to <code>emma:parameters</code>
element: <code>emma:parameter-ref</code> attribute</a></li>
<li>4.2.22 <a href="#s4.2.22">Human transcription: the <code>emma:annotated-tokens</code> attribute</a></li>
<li >4.2.23 <a  href="#s4.2.23">Partial content: <code>emma:partial-content</code></a></li>
<li >4.2.24 <a href="#s4.2.24">Incremental results:<code> emma:stream-id</code>, <code>emma:stream-seq-num, emma:stream-status</code>, <code>emma:stream-full-result</code>, <code>emma:stream-token-span</code>, <code>emma:stream-token-span-full, emma:stream-token-immortals</code>, <code>emma:stream-immortal-vertex</code></a></li>
<ul class="tocline">
<li>4.2.24.1 <a href="#s4.2.24.1">Example use case of incremental results in dictation</a></li>
<li>4.2.24.2 <a href="#s4.2.24.2">Example use case of incremental results in voice search application</a></li>
<li>4.2.24.3 <a href="#s4.2.24.3">Example use case of incremental recognition of handwritten characters</a></li>
<li></li>
</ul>
<li > </li>
</ul>
</li>
<li>4.3 <a href="#s4.3">Scope of EMMA annotations</a></li>
</ul>
</li>
<li>5.<a href="#s5">Conformance</a>
<ul class="tocline">
<li>5.1 <a href="#s5.1">Conforming EMMA Documents</a></li>
<li>5.2 <a href="#s5.2">Using EMMA with other Namespaces</a></li>
<li>5.3 <a href="#s5.3">Conforming EMMA Processors</a></li>
</ul>
<li>6.<a href="#s6">Integration of EMMA with other Standards Related to Output</a>
<ul class="tocline">
<li>6.1 <a href="#s6.1">WAI-ARIA (Accessible Rich Internet Applications)</a></li>
<li>6.2 <a href="#s6.2">Integration of EMMA with TTML (Timed Text Markup Language)</a></li>
</ul>
</li>
<li><a href="#appendices">Appendices</a>
<ul class="tocline">
<li>Appendix A. <a href="#appA">XML and <span>RELAX NG</span>
schemata</a> <span>(Normative)</span></li>
<li>Appendix B. <a href="#appB">MIME type</a>
<span>(Normative)</span>
<ul>
<li>B.1 <a href="#media-type-registration">Registration of
MIME media type application/emma+xml</a></li>
</ul>
</li>
<li>Appendix C. <a href="#appC"><code>emma:hook</code> and SRGS</a>
<span>(Informative)</span></li>
<li>Appendix D. <a href="#appD">EMMA event interface</a>
<span>(Informative)</span></li>
<li>Appendix E. <a href="#appE">References</a>
<ul>
<li>E.1 <a href="#appE1">Normative references</a></li>
<li>E.2 <a href="#appE2"><span>Informative</span>
references</a></li>
</ul>
</li>
<li>Appendix F. <a href="#appF">Changes since EMMA 1.0</a>
<span>(Informative)</span></li>
<li>Appendix G. <a href="#appG">Acknowledgements</a>
<span>(Informative)</span></li>
</ul>
</li>
</ul>
<h2 id="s1">1. Introduction</h2>
<p>This section is <span>I</span>nformative.</p>
<p>This document presents an XML specification for EMMA, an
Extensible MultiModal Annotation markup language, responding to the
requirements documented in <span>Requirements for EMMA</span>
[<a href="#EMMAreqs">EMMA <span>Requirements</span></a>]. This
markup language is intended for use by systems that provide
semantic interpretations for a variety of inputs and representations for a variety of system outputs. Possible inputs include but are not
necessarily limited to, speech, natural language text, GUI and ink Possible outputs include speech, text, GUI, vibration, and gestures made by embodied agents or robots.</p>
<p>It is expected that this markup will be used primarily as a
  standard data interchange format between the components of a
  multimodal system; in particular, it will normally be automatically
  generated by interpretation components to represent the semantics
of users' inputs and by production components to represent system output, not directly authored by developers.</p>
<p>The language is focused on representing and annotating  inputs from users and system generated outputs,
  which may be either in a single mode or a composite input
  combining information from multiple modes, as opposed to
  information that might have been collected over multiple turns of a
  dialog</span>. The language provides a set of elements and attributes that
  are focused on enabling annotations on user inputs and system outputs and
  interpretations of those inputs and representation of those outputs.</p>
<p>An EMMA document can be considered to hold three types of
data:</p>
<ul>
<li>
<p><b>instance data</b></p>
<p>Application-specific markup corresponding to input or output information
which is meaningful to the consumer of an EMMA document. Instances
are application-specific and built by input and output processors at runtime.
Given that utterances may be ambiguous with respect to input
values, an EMMA document may hold more than one instance. Similarly for output, there may be more than one possible realization of the system output (e.g. different renderings of a semantic representation into a string) and so an EMMA document for output may also hold more than one instance.</p>
</li>
<li>
<p><b>data model</b></p>
<p>Constraints on structure and content of an instance. The data
model is typically pre-established by an application, and may be
implicit, that is, unspecified.</p>
</li>
<li>
<p><b>metadata</b></p>
<p>Annotations associated with the data contained in the instance.
Annotation values are added by input processors and output generators at runtime. In EMMA 2.0 1.1 annotations may also result from transcription and other activities by human annotators.</p>
</li>
</ul>
<p>Given the assumptions above about the nature of data represented
in an EMMA document, the following general principles apply to the
design of EMMA:</p>
<ul>
<li>The main prescriptive content of the EMMA specification will
consist of metadata: EMMA will provide a means to express the
metadata annotations which require standardization. (Notice,
however, that such annotations may express the relationship among
all the types of data within an EMMA document.)</li>
<li> <span>The instance and its data model are assumed to be specified in XML by default, but the instance may be specified in other formats as defined by the <code>emma:result-format</code> attribute. EMMA will remain agnostic to the specific details of the format (If it is XML, the instance data is assumed to be sufficiently structured to enable the association of annotative data.)</span></li>
<li>The extensibility of EMMA lies in the ability for additional
  kinds of metadata to be included in application specific
  vocabularies. EMMA itself can be extended with application and
  vendor specific annotations contained within the
  <code>emma:info</code> element <span>(<a href="#s4.1.5">Section
  4.1.5</a>)</span>.</li>
</ul>
<p>The annotations of EMMA should be considered 'normative' in the
sense that if an EMMA component produces annotations as described
in <a href="#s3">Section 3</a> <span>and <a href="#s4">Section
4</a></span>, these annotations must be represented using the EMMA
syntax. The Multimodal Interaction Working Group may address in
later drafts the issues of modularization and profiling; that is,
which sets of annotations are to be supported by which classes of
EMMA component.</p>
<h3 id="s1.1">1.1 Uses of EMMA</h3>
<p>The general purpose of EMMA is to represent the stages of processing of the inputs and outputs of an automated system. In the case of input this is information
  automatically extracted from a user's input by an interpretation
component, where input is to be taken in the general sense of a
  meaningful user input in any modality supported by the platform. In the case of output, EMMA represents the stages in the production of a system output.</p>
<p>The reader should refer to the sample architecture in <span>W3C
  Multimodal Interaction Framework</span> <a href="#MMIF">[<span>MMI
    Framework</span>]</a>, which shows EMMA conveying content between
  user input modality components and an interaction manager. EMMA is one potential transport for system output from an interaction manager to system output modality components.</p>
<p>Input processing components that generate EMMA markup:</p>
<ol>
<li>Speech recognizers</li>
<li>Handwriting recognizers</li>
<li>Natural language understanding engines</li>
<li>Other input media interpreters (e.g. DTMF, pointing,
keyboard)</li>
<li>Multimodal integration components</li>
</ol>
<p>Components that use EMMA representations of input include:</p>
<ol>
  <li>Interaction manager</li>
  <li>Multimodal integration component</li>
</ol>
<p >Output production components that may generate EMMA markup:</p>
<ol>
  <li >Dialog/interaction manager</li>
  <li >Multimodal presentation planning component</li>
  <li >Natural language generation component</li>
</ol>
<p >Components that use EMMA representations of output include:</p>
<ol>
  <li >Text-to-speech engine (audio and or video)</li>
  <li >Graphical presentation components (e.g. HTML, SVG renderer or browser)</li>
  <li >Media presentation components (e.g. video player)</li>
  <li >Robot/embodied agent motion planning or rendering component</li>
</ol>

<h3 id="s1.2">1.2 Terminology</h3>
<dl>
<dt id="anchor-point">anchor point</dt>
<dd>When referencing an input or output interval with <code>emma:time-ref-uri</code>,
<code>emma:time-ref-anchor-point</code> allows you to specify
whether the referenced anchor is the start or end of the
interval.</dd>
<dt id="annotation">annotation</dt>
<dd>Information about the interpreted input or produced output, for example,
timestamps, confidence scores, links to the raw signal, etc.</dd>
<dt id="composite-input">composite input</dt>
<dd>An input formed from several pieces, often in different modes,
for example, a combination of speech and pen gesture, such as
saying "zoom in here" and circling a region on a map.</dd>
<dt id="confidence">confidence</dt>
<dd>A numerical score describing the degree of certainty in a
particular interpretation of user input or the relative quality of a production of system output.</dd>
<dt id="data-model">data model</dt>
<dd>For EMMA, a data model defines a set of constraints on possible
interpretations of user input or representations of system output.</dd>
<dt id="derivation">derivation</dt>
<dd>Interpretations of user input are said to be derived from that
input, and higher level interpretations may be derived from lower
level ones. EMMA allows you to reference the user input or
interpretation a given interpretation was derived from, see
<a href="#semantic-interpretation"><em>semantic
interpretation</em></a>. A system output is said to be derived from a semantic representation produced by the system. There may be multiple stages to the production of a system output and EMMA allows you to reference the previous stage that it was derived from.</dd>
<dt id="dialog">dialog</dt>
<dd>For EMMA, dialog can be considered as a sequence of
interactions between 
a user and the application.</dd>
<dt id="endpoint">endpoint</dt>
<dd>In EMMA, this refers to a network location which is the source
or recipient of an EMMA document. It should be noted that the usage
of the term "endpoint" in this context is different from the way
that the term is used in speech processing, where it refers to the
end of a speech input.</dd>
<dt id="gestures">gestures</dt>
<dd>In multimodal applications gestures are communicative acts made
by the user or application. An example is circling an area on a map
to indicate a region of interest. Users may be able to gesture with
a pen, keystrokes, hand movements, head
movements, or sound. Gestures often form part of <a href="#composite-input"><em>composite input</em></a>. Application
gestures are typically animations and/or sound effects. Gestures may also be made by a system, e.g. highlighting on a graphical display or physical arm/hand motions by an embodied virtual agent or physical robotic agent.</dd>
<dt id="grammar">grammar</dt>
<dd>A set of rules that describe a sequence of tokens expected in a
given input or output. These can be used by speech and handwriting
recognizers to increase recognition accuracy and by natural language generation components to produce well formed output.</dd>
<dt id="handwriting-recognition">handwriting recognition</dt>
<dd>The process of converting pen strokes into text.</dd>
<dt id="ink-recognition">ink recognition</dt>
<dd>This includes the recognition of handwriting and pen
gestures.</dd>
<dt id="input-cost">input cost</dt>
<dd>In EMMA, this refers to a numerical measure indicating the
weight or processing cost associated with a user's input or part of
their input.</dd>
<dt id="input-device">input device</dt>
<dd>The device providing a particular input, for example, a
microphone, a pen, a mouse, a camera, or a keyboard.</dd>
<dt id="input-function">input function</dt>
<dd>In EMMA, this refers to <span>the</span> use a particular input
is serving, for example, as part of a recording or transcription,
as part of a dialog, or as a means to verify the user's
identity.</dd>
<dt id="input-medium">input medium</dt>
<dd>Whether the input is acoustic, visual, or tactile, for
instance, a spoken utterance is an example of an acoustic input, a
hand gesture as seen by a camera is an example of a visual input,
pointing with a mouse or pen is an example of a tactile input.</dd>
<dt id="input-mode">input mode</dt>
<dd>This distinguishes a particular means of providing an input
within a general input medium, for example, speech, DTMF, ink, key
strokes, video, photograph, etc.</dd>
<dt id="input-source">input source</dt>
<dd>This is the device that provided the input, for example a
particular microphone or camera. EMMA allows you to identify these
with a URI.</dd>
<dt id="input-tokens">input tokens</dt>
<dd>In EMMA, this refers to a sequence of characters, words or
other discrete units of input.</dd>
<dt id="instance-data">instance data</dt>
<dd>A representation in XML of an interpretation of user
input.</dd>
<dt id="interaction-manager">interaction manager</dt>
<dd>A processor that determines how an application interacts with a
user. This can be at multiple levels of abstraction, for example,
at a detailed level, determining what prompts to present to the
user and what actions to take in response to user input, versus a
higher level treatment in terms of goals and tasks for achieving
those goals. Interaction managers are frequently event driven.</dd>
<dt id="interpretation">interpretation</dt>
<dd>In EMMA, an interpretation of user input refers to information
derived from the user input that is meaningful to the
application.</dd>
<dt id="keystroke-input">keystroke input</dt>
<dd>Input provided by the user pressing on a sequence of keys
(buttons), such as a computer keyboard or keypad.</dd>
<dt id="lattice">lattice</dt>
<dd>A set of nodes interconnected with directed arcs such that by
following an arc, you can never find yourself back at a node you
have already visited (i.e. a directed acyclic graph). Lattices
provide a flexible means to represent the results of speech and
handwriting recognition, in terms of arcs representing words or
character sequences. Different arcs from the same node represent
different local hypotheses as to what the user said or wrote.</dd>
<dt id="metadata">metadata</dt>
<dd>Information describing another set of data, for instance, a
library catalog card with information on the author, title and
location of a book. EMMA is designed to support input and output processors in
providing metadata for interpretations of user input and system output.</dd>
<dt id="multimodal-integration">multimodal integration</dt>
<dd>The process of combining inputs from different modes to create
an interpretation of composite input. This is also sometimes
referred to as <em>multimodal fusion</em>.</dd>
<dt id="multimodal-interaction">multimodal interaction</dt>
<dd>The means for a user to interact with an application using more
than one mode of interaction, for instance, offering the user the
choice of speaking or typing, or in some cases, allowing the user
to provide a composite input involving multiple modes.</dd>
<dt >multimodal presentation planning</dt>
<dd >The process of generation multiple, possibly coordinated, outputs in different models to present information to the user. This is also sometimes referred to as <em>multimodal output generation</em> or <em>multimodal fission</em>.</dd>
<dt>natural language
  understanding</dt>
<dd>The process of interpreting text in terms that are useful for
  an application.</dd>
  <dt id="N-best-list">N-best list</dt>
  <dd>An N-best list is a list of the most likely hypotheses for what
    the user actually said or wrote, where N stands for an integral
  number such as 5 for the 5 most likely hypotheses. N-best lists can also be used for multiple different possible renderings of system output.</dd>
  <dt id="raw-signal">&nbsp;</dt>
  <dd>&nbsp;</dd>
  <dt >output device</dt>
  <dd >The device producing a particular output, for example, a loudspeaker, display screen, robot.</dd>
  <dt >output medium</dt>
  <dd >Whether the output is acoustic, visual, or tactile. For example, a spoken text to speech output is acoustic, a presentation of a table of information on a screen is visual, while haptic feedback is tactile.</dd>
<dt >output mode</dt>
<dd >This distinguishes a particular means of providing an output within a general output medium, for example, speech, non-speech audio (earcons, alerts), graphics, gesture.</dd>
<dt >output tokens</dt>
<dd >In EMMA, this refers to a sequence of characters, words, gestures, or other discrete units of output.</dd>
  <dt>raw signal</dt>
  <dd>An uninterpreted input, such as an audio waveform captured from
  a microphone.</dd>
  <dt id="semantic-interpretation">semantic interpretation</dt>
  <dd>A normalized representation of the meaning of a user input, for
    instance, mapping the speech for "San Francisco" into the airport
  code "SFO".</dd>
  <dt id="semantic-processor">semantic processor</dt>
  <dd>In EMMA, this refers to systems that can derive interpretations
    of user input, for instance, mapping the speech for "San Francisco"
  into the airport code "SFO".</dd>
  <dt id="signal-interpretation">signal interpretation</dt>
  <dd>The process of mapping a discrete or continuous signal into a
    symbolic representation that can be used by an application, for
    instance, transforming the audio waveform corresponding to someone
  saying "2005" into the number 2005.</dd>
  <dt id="speech-recognition">speech recognition</dt>
  <dd>The process of determining the textual transcription of a piece
  of speech.</dd>
  <dt id="speech-synthesis">speech synthesis</dt>
  <dd>The process of rendering a piece of text into the corresponding
  speech, i.e. synthesi<span>z</span>ing speech from text.</dd>
  <dt id="text-to-speech">text to speech</dt>
  <dd>The process of rendering a piece of text into the corresponding
  speech.</dd>
  <dt id="time-stamp">time stamp</dt>
  <dd>The time that a particular input or part of an input began or
  ended.</dd>
  <dt id="term-uri">URI: Uniform Resource Identifier</dt>
  <dd>A URI is a unifying syntax for the expression of names and
    addresses of objects on the network as used in the World Wide Web.
    <span>Within this specification, the term URI refers to a Universal
      Resource Identifier as defined in [<a href="#RFC3986">RFC3986</a>]
      and extended in [<a href="#RFC3987">RFC3987</a>] with the new name
      IRI. The term URI has been retained in preference to IRI to avoid
      introducing new names for concepts such as "Base URI" that are
      defined or referenced across the whole family of XML
    specifications</span>. A URI is defined as any legal
    <code>anyURI</code> primitive as defined in XML Schema Part 2:
  Datatypes Second Edition Section 3.2.17 [<a href="#XSD2">SCHEMA2</a>].</dd>
  <dt id="user-input">user input</dt>
  <dd>An input provided by a user as opposed to something generated
  automatically.</dd>
  <dt >system output</dt>
  <dd >An output produced by an automated interactive system. </dd>
</dl>
<h2 id="s2">2. Structure of EMMA documents</h2>
<p>This section is <span>I</span>nformative.</p>
<p>As noted above, the main components of an interpreted user input
or produced system output in EMMA are the instance data, an optional data model, and the
metadata annotations that may be applied to that input or output. The
realization of these components in EMMA is as follows:</p>
<ul>
<li><b>instance data</b> is contained within an EMMA
<i>interpretation</i>for input and an EMMA <em>output</em> for output</li>
<li>the <b>data model</b> is optionally specified as an annotation
of that instance</li>
<li>EMMA <b>annotations</b> may be applied at different levels of
an EMMA document.</li>
</ul>
<p>An EMMA <i>interpretation</i> is the primary unit for holding
user input as interpreted by an EMMA processor. As will be seen
below, multiple interpretations of a single input are possible.</p>
<p >An EMMA output is the primary unit for holding system output as generated by an EMMA processor. As will be seen below, multiple possible alternative system outputs are possible.</p>
<p>EMMA provides a simple structural syntax for the organization of
interpretations and instances, and an annotative syntax to apply
the annotation to the input data and output data at different levels.</p>
<p>An outline of the structural syntax and annotations found in
EMMA documents is as follows. A fuller definition may be found in
the description of individual elements and attributes in <a href="#s3"><span>S</span>ection 3</a> and <a href="#s4"><span>S</span>ection 4</a>.</p>
<ul>
<li><b><a href="#s3">EMMA <span>s</span>tructural
<span>e</span>lements</a></b> (<a href="#s3">Section 3</a>)
<ul>
<li><b><a href="#s3.1">Root element</a></b>: The root node of an
EMMA document, the <code>emma:emma</code> element, holds EMMA
version and namespace information, and provides a container for one
or more of the following interpretation and container elements
(<a href="#s3.1">Section 3.1</a>)</li>
<li><b><a href="#s3.2">Interpretation element</a></b>: The
<code>emma:interpretation</code> element contains a given
interpretation of the input and holds application specific markup
(<a href="#s3.2">Section 3.2</a>)</li>
<li><b><a href="#s3.3">Output element</a></b>: The <code>emma:output </code>element contains a given instantiation of system output and holds application specific markup. (<a href="#s3.3">Section 3.3</a>)</li>
<li><b><a href="#s3.4">Container elements</a>:</b>
<ul>
<li><code>emma:one-of</code> is a container for one or more
interpretation elements, output elements, or container elements and denotes that
these are mutually exclusive interpretations or possible system outputs (<a href="#s3.4.1">Section 3.4.1</a>)</li>
<li><code>emma:group</code> is a general container for one or more
interpretation elements, output elements, or container elements. It can be associated
with arbitrary grouping criteria (<a href="#s3.4.2">Section
3.4.2</a>).</li>
<li><code>emma:sequence</code> is a container for one or more
interpretation elements, output elements, or container elements and denotes that
these are sequential in time (<a href="#s3.4.3">Section
3.4.3</a>).</li>
</ul>
</li>
<li><b><a href="#s3.5">Lattice element</a></b>: The
<code>emma:lattice</code> element is used to contain a series of
<code>emma:arc</code> and <code>emma:node</code> elements that
define a lattice of words, gestures, meanings or other symbols. The
<code>emma:lattice</code> element appears within the
<code>emma:interpretation</code> element (<a href="#s3.5">Section
3.4</a>) or within the <code>emma:output</code> element.</li>
<li><b><a href="#s3.6">Literal element</a></b>: The
<code>emma:literal</code> element is used as a wrapper when the
application semantics is a string literal. (<a href="#s3.6">Section
3.5</a>)</li>
</ul>
</li>
<li><b><a href="#s4">EMMA annotations</a></b> (<a href="#s4">Section 4</a>)
<ul>
<li><b><a href="#s4.1">EMMA annotation elements</a></b>: These are
EMMA annotations such as <code>emma:derived-from</code>,
<code>emma:endpoint-info</code>, and <code>emma:info</code> which
are represented as elements so that they can occur more than once
within an element and can contain internal structure. (<a href="#s4.1">Section 4.1</a>)</li>
<li><b><a href="#s4.2">EMMA annotation attributes</a></b>: These
are EMMA annotations such as <code>emma:start</code>,
<code>emma:end</code> , <code>emma:confidence</code>, and
<code>emma:tokens</code> which are represented as attributes. They
can appear on <code>emma:interpretation</code> elements or <code>emma:output</code> elements<span>.
S</span>ome can appear on container elements, lattice elements, and
elements in the application-specific markup. (<a href="#s4.2">Section 4.2</a>)</li>
</ul>
</li>
</ul>
<p>From the defined root node <code>emma:emma</code> the structure
of an EMMA document consists of a tree of EMMA container elements
(<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:group</code>) terminating in a number of interpretation
elements (<code>emma:interpretation</code>) or output elements <code>(emma:output)</code>. The
<code>emma:interpretation</code> elements serve as wrappers for
either application namespace markup describing the interpretation
of the users input or an <code>emma:lattice</code> element or
<code>emma:literal</code> element . The
<code>emma:output</code> elements serve as wrappers for system output. A single <code>emma:interpretation</code> or a single <code>emma:output</code>  may also appear directly under the
root node.</p>


<p>
The EMMA elements
<code>emma:emma</code>,
<code>emma:interpretation</code>,
<code>emma:one-of</code>,
and <code>emma:literal</code>
and the EMMA attributes
<code>emma:no-input</code>,
<code>emma:uninterpreted</code>,
<code>emma:medium</code>,
and <code>emma:mode</code>
are required of all
implementations.  The remaining elements and attributes are optional
and may be used in some implementations and not other depending on the
specific modalities and processing being represented.</p>
<p>To illustrate this, here is an example of
  an EMMA document representing input
  to a flight reservation application. In this example there are two
  speech recognition results and associated semantic representations
  of the input. The system is uncertain whether the user meant
  "flights from Boston to Denver" or "flights from Austin to Denver".
  The annotations to be captured are timestamps and confidence scores
for the two inputs.</p>
<p>Example:</p>
<pre class="example">&lt;emma:emma version="2.0"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="r1" emma:start="1087995961542" emma:end="1087995963542"
<span>     emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"
    emma:tokens="flights from boston to denver"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;

    &lt;emma:interpretation id="int2" emma:confidence="0.68"
    emma:tokens="flights from austin to denver"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>Attributes on the root <code>emma:emma</code> element indicate
the version and namespace. The <code>emma:emma</code> element
contains an <code>emma:one-of</code> element which contains a
disjunctive list of possible interpretations of the input. The
actual semantic representation of each interpretation is within the
application namespace. In the example here the application specific
semantics involves elements <code>origin</code> and
<code>destination</code> indicating the origin and destination
cities for looking up a flight. The timestamp is the same for both
interpretations and it is annotated using values in milliseconds in
the <code>emma:start</code> and <code>emma:end</code> attributes on
the <code>emma:one-of</code>. The confidence scores and tokens
associated with each of the inputs are annotated using the EMMA
annotation attributes <code>emma:confidence</code> and
<code>emma:tokens</code> on each of the
<code>emma:interpretation</code> elements.</p>
<p>Attributes in EMMA cascade from a containing <code>emma:one-of</code> element to the individual interpretations. In the example above, the <code>emma:start</code>, <code>emma:end</code>, <code>emma:medium</code>, and <code>emma:mode</code> attributes are all specified once on <code>emma:one-of</code> but apply to both of the contained <code>emma:interpretation</code> elements. This is an important mechanism as it limits the need to repeat annotations. More details on the scope of annotations among EMMA structural elements, and also on the scope of annotations within derivations, where multiple different processing stages apply to an input, can be found in <a href="#s4.3">Section 4.3</a>.</p>
<p >The core of an EMMA document representing system output is <code>emma:output</code>. Like <code>emma:interpretation</code>, <code>emma:output</code> can appear within container elements. In the following example <code>emma:output</code> elements appear within <code>emma:one-of </code>indicating alternative text-to-speech prompts and this structure is captured with <code>emma:group</code> indicating a graphical table to be presented. The <code>emma:medium</code>, <code>emma:mode</code>, <code>emma:verbal</code>, <code>emma:function</code>, <code>emma:result-format</code>, and <code>emma:lang</code> are the same for both TTS prompts and so they can be specified once on the <code>emma:one-of</code> and are assumed to apply to both prompts.</p>

<pre class="example"><a name="fullOutputExample" id="fullOutputExample"></a>&lt;emma:emma version=&quot;2.0&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
&lt;emma:group 
    emma:process=&quot;http://example.com/multimodal_presentation_planner&quot;&gt;
    &lt;emma:one-of id=&quot;ooo1&quot;
         emma:medium=&quot;acoustic&quot;
         emma:mode=&quot;voice&quot;
         emma:verbal=&quot;true&quot;
         emma:function=&quot;dialog&quot;
         emma:result-format=&quot;application/ssml+xml&quot;
         emma:lang=&quot;en=US&quot;
         emma:process=&quot;http://example.com/nlg&quot;&gt;
        &lt;emma:output emma:confidence=&quot;0.8&quot; id=&quot;tts1&quot;&gt;
             &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;
                                  xml:lang=&quot;en-US&quot;&gt;
             I found three flights from Boston to Denver.
             &lt;/speak&gt;
        &lt;/emma:output&gt;
        &lt;emma:output emma:confidence=&quot;0.7&quot; id=&quot;tts2&quot;&gt;
             &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;
                                  xml:lang=&quot;en-US&quot;&gt;
             There are flights to Boston from Denver on United, American, and Delta.
             &lt;/speak&gt;
        &lt;/emma:output&gt;
     &lt;/emma:one-of&gt;
     &lt;emma:output id=&quot;gui1&quot; <span>
         emma:medium=&quot;visual&quot; 
         emma:mode=&quot;gui&quot; 
         emma:result-format=&quot;text/html&quot;
	       emma:lang=&quot;en-US&quot;
         emma:function=&quot;dialog&quot;
         emma:process=&quot;http://example.com/gui_gen&quot;&gt;
		   &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;
			&lt;body&gt;
				&lt;table&gt;
					&lt;tr&gt;&lt;td&gt;United&lt;/td&gt;&lt;td&gt;5.30pm&lt;/td&gt;&lt;/tr&gt;
                  &lt;tr&gt;&lt;td&gt;American&lt;/td&gt;&lt;td&gt;6.10pm&lt;/td&gt;&lt;/
                  &lt;tr&gt;&lt;td&gt;Delta&lt;/td&gt;&lt;td&gt;7pm&lt;/td&gt;&lt;/tr&gt;
				&lt;/table&gt;
          &lt;/body&gt;
         &lt;/html&gt;
      &lt;/emma:output&gt;
&lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>

<p>Many EMMA elements allow for content to be specified either inline or by reference using  the <code>ref</code> attribute.  This is an important mechanism as it allows for EMMA documents to be less verbose and yet allows the EMMA consumer to access content from an external document, possibly on a remote server. For example, in the case of <code>emma:grammar</code> a grammar can either be specified inline within the element or the <code>ref</code> attribute on <code>emma:grammar</code> can indicate the location where the grammar document can be retrieved. Similarly with <code>emma:model</code> a data model can be specified inline or by reference through the <code>ref</code> attribute.  A <code>ref</code> attribute can also be used on the EMMA container elements<code> emma:sequence</code>, <code>emma:one-of</code>, <code>emma:group</code>, and <code>emma:lattice</code>.  In these cases, the <code>ref</code> attribute provides a pointer to a portion of an external EMMA document, possibly on a remote server. This can be achieved using URI ID references to pick out a particular element within the external EMMA document. One use case for <code>ref</code> with the container elements is to allow for inline content to be partial and for the <code>ref</code> to provide access to the full content. For example, in the case of <code>emma:one-of</code>, an EMMA document delivered to an EMMA consumer could contain an abbreviated list of interpretations, e.g. the top 3, while an <code>emma:one-of</code> element accessible through the URI in ref to include a more inclusive list of 20 <code>emma:intepretation</code> elements. The <code>emma:partial-content</code> attribute MUST be used on the partially specified element if the <code>ref</code> refers to a more fully specified element. The <code>emma:ref</code> attribute can also be used on <code>emma:info</code>, <code>emma:parameters</code>, and <code>emma:annotation</code>. The use of <code>ref</code> on specific elements is described and exemplified in the specific section describing each element. </p>
<h3 id="s2.1">2.<span>1</span> Data model</h3>
<p>An EMMA data model expresses the constraints on the structure
and content of instance data, for the purposes of validation. As
such, the data model may be considered as a particular kind of
annotation (although, unlike other EMMA annotations, it is not a
feature pertaining <span>to</span> a specific user input or system output at a
specific moment in time, it is rather a static and, by its very
definition, application-specific structure). <span>The</span>
specification of <span>a data model</span> in EMMA is optional.</p>
<p>Since Web applications today use different formats to specify
data models, e.g. <span>XML Schema Part 1: Structures Second
Edition</span> [<a href="#XSD1">XML Schema
<span>Structures</span></a>], XForms <span>1.0 (Second
Edition)</span> [<a href="#XFORMS">XFORMS</a>], <span>RELAX NG
Specification</span> [<a href="#RELAXNG">RELAX-NG</a>], etc., EMMA
itself is agnostic to the format of data model used.</p>
<p>Data model definition and reference is defined in <a href="#s4.1.1">Section 4.1.1</a>.</p>
<h3 id="s2.2">2.<span>2</span> EMMA namespace prefixes</h3>
<p>An EMMA attribute is qualified with the EMMA namespace prefix if
the attribute can also be used as an in-line annotation on elements
in the application's namespace. Most of the EMMA annotation
attributes in <a href="#s4.2">Section 4.2</a> are in this category.
An EMMA attribute is not qualified with the EMMA namespace prefix
if the attribute only appears on an EMMA element. This rule ensures
consistent usage of the attributes across all examples.</p>
<p>Attributes from other namespaces are permissible on all EMMA
elements. As an example <code>xml:lang</code> may be used to
annotate the human language of character data content.</p>
<h2 id="s3">3. EMMA structural elements</h2>
<p>This section defines elements in the EMMA namespace which
provide the structural syntax of EMMA documents.</p>
<h3 id="s3.1">3.1 Root element: <code>emma:emma</code></h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:emma</th>
</tr>
<tr>
<th>Definition</th>
<td>The root element of an EMMA document.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:emma</code> element MUST immediately contain a
single <code>emma:interpretation</code> element or <code>emma:output</code> element or EMMA container
element: <code>emma:one-of</code>, <code>emma:group</code>,
<code>emma:sequence</code>. It MAY also contain an optional single
<code>emma:derivation</code> element. It MAY also contain
multiple optional <code>emma:grammar</code>  elements,
<code>emma:model</code>  elements, and
<code>emma:endpoint-info</code>  elements, <span><code>emma:info</code> elements, <code>emma:process-model</code> elements, <code>emma:parameters</code> elements, and <code>emma:annotation</code> elements. </span> It may also contain a single <code>emma:location</code> element.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>version</code>: the version of EMMA used for the
interpretation(s). Interpretations expressed using this
specification MUST use <code>1.1</code> for the value.</li>
<li>Namespace declaration for EMMA, see below.</li>
</ul>
</li>
<li><b>Optional</b>:
<ul>
<li>any other namespace declarations for application specific
namespaces.</li>
<li ><code>doc-ref</code>: an attribute of type <code>xsd:anyURI</code> providing a URI  indicating the location on a server where the EMMA document with emma:emma as root can be retrieved from.</li>
<li><code>prev-doc</code>: an attribute of type <code>xsd:anyURI</code> providing a URI  indicating the location on a server where the EMMA document previous to this EMMA document in the sequence of interaction can be retrieved from.</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>None</td>
</tr>
</tbody>
</table>
<p>The root element of an EMMA document is named
<code>emma:emma</code>. It holds a single
<code>emma:interpretation</code> or <code>emma:output</code> element, or an EMMA container element
(<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:group</code>). It MAY also contain a single
<code>emma:derivation</code> element containing earlier stages of
the processing of the input (See <a href="#s4.1.2">Section
4.1.2</a>). It MAY also contain multiple optional
<code>emma:grammar</code>, <code>emma:model</code>, and
<code>emma:endpoint-info</code> ,<span> <code>emma:info</code>, <code>emma:process-model</code>, <code>emma:parameters</code>, and <code>emma:annotation</code> elements.</span></p>
<p>It MAY hold attributes for information pertaining to EMMA
itself, along with any namespaces which are declared for the entire
document, and any other EMMA annotative data. The
<code>emma:emma</code> element and other elements and attributes
defined in this specification belong to the XML namespace
identified by the URI "http://www.w3.org/2003/04/emma". In the
examples, the EMMA namespace is generally declared using the
attribute <code>xmlns:emma</code> on the root
<code>emma:emma</code> element. EMMA processors MUST support the
full range of ways of declaring XML namespaces as defined by the
<span>Namespaces in XML 1.1 (Second Edition)</span> [<a href="#XMLNS">XMLNS</a>]. Application markup <span>MUST</span> be declared<span> either</span> in an
explicit application namespace, or an undefined namespace
by setting xmlns="".</p>
<p>For example:</p>
<pre class="example">&lt;emma:emma version="1.1" xmlns:emma="http://www.w3.org/2003/04/emma"&gt;
    ....
&lt;/emma:emma&gt;
</pre>
<p>or</p>
<pre class="example">&lt;emma version="1.1" xmlns="http://www.w3.org/2003/04/emma"&gt;
    ....
&lt;/emma&gt;</pre>

<p > The optional attributes <code>doc-ref</code> and <code>prev-doc</code> MAY be used on <code>emma:emma</code> in order to indicate the location where the EMMA document comprising that <code>emma:emma</code> element can be retrieved from, and the location of the previous EMMA document in a sequence of interactions. One important use case for <code>doc-ref</code> is for client side logging. A client receiving an EMMA document can record the URI found in <code>doc-ref</code> in a log file instead of  a local copy of the whole EMMA document. The<code> prev-doc</code> attribute provides a mechanism for tracking a sequence of EMMA documents representing the results of processing distinct turns of interaction by an EMMA processor.
</p><p >In the following example, <code>doc-ref</code> on EMMA provides a URI which indicates where the EMMA document embodied in this <code>emma:emma</code> can be retrieved from.
</p>

<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    doc-ref="http://example.com/trainapp/user123/emma0727080512.xml"&gt;
  &lt;emma:interpretation id="int1"
      emma:medium="acoustic" 
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:signal="http://example.com/audio/input678.amr"
      emma:process="http://example.com/asr/params.xml"
      emma:tokens="trains to london tomorrow"&gt;
    &lt;destination&gt;London&lt;/destination&gt;
    &lt;date&gt;tomorrow&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</pre>

<p >In the following example, again <code>doc-ref </code>indicates where the EMMA document can be retrieved from but in addition <code>prev-doc</code> indicates where the previous EMMA document can be retrieved from. </p>


<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    doc-ref="http://example.com/trainapp/user123/emma0730080512.xml"
    prev-doc="http://example.com/trainapp/user123/emma0727080512.xml"&gt;
  &lt;emma:interpretation id="int1"
      emma:medium="acoustic" 
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:signal="http://example.com/audio/input679.amr"
      emma:process="http://example.com/asr/params.xml"
      emma:tokens="from cambridge"&gt;
    &lt;origin&gt;Cambridge&lt;/origin&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>

EMMA processors may be use a number of different techniques to determine the <code>prev-doc</code>. It may, for example, be determined based on the session. In a session of interaction a server processing requests for processing can track the previous EMMA result for a client and indicate that in <code>prev-doc</code>. Alternatively, the URI of the last EMMA result could be passed in as a parameter in a request to an EMMA processor and returned in the <code>prev-doc</code> with the next result.

<h3>3.2 Interpretation element: <code>emma:interpretation</code></h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:interpretation</th>
</tr>
<tr>
<th>Definition</th>
<td>The <code>emma:interpretation</code> element acts as a wrapper
for application instance data or lattices.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:interpretation</code> element MUST immediately
contain either application instance data, or a single
<code>emma:lattice</code> element, or a single
<code>emma:literal</code> element, or in the case of uninterpreted
input or no input <code>emma:interpretation</code>
<span>MUST</span> be empty. It MAY also contain <span>multiple
optional</span> <code>emma:derived-from</code>
element<span>s</span> and an optional single
<code>emma:info</code> element multiple
optional <code>emma:info</code> element<span>s</span>.<span> It MAY also contain multiple optional<code> emma:annotation</code> elements. It MAY also contain multiple<code> emma:parameters</code> elements. It MAY also contain a single optional <code>emma:grammar-active</code> element.  It may also contain a single <code>emma:location</code> element.</span></td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>: Attribute <code>id</code> of type
<code>xsd:ID</code> that uniquely identifies the interpretation
within the EMMA document.</li>
<li><b>Optional</b>: The annotation attributes:
<code>emma:tokens</code>, <code>emma:process</code>,
<code>emma:no-input</code>, <code>emma:uninterpreted</code>,
<code>emma:lang</code>, <code>emma:signal</code>,
<code><span>emma:signal-size</span></code>,
<code>emma:media-type</code>, <code>emma:confidence</code>,
<code>emma:source</code>, <code>emma:start</code>,
<code>emma:end</code>, <code>emma:time-ref-uri</code>,
<code>emma:time-ref-anchor-point</code>,
<code>emma:offset-to-start</code>, <code>emma:duration</code>,
<code>emma:medium</code>, <code>emma:mode</code>,
<code>emma:function</code>, <code>emma:verbal</code>,
<code>emma:cost</code>, <code>emma:grammar-ref</code>,
<code>emma:endpoint-info-ref</code>, <code>emma:model-ref</code>,
<code>emma:dialog-turn</code>,<code> <span>emma:info-ref</span></code><span><strong>, </strong><code>emma:parameter-ref</code>, <code>emma:process-model-ref</code>, <code>emma:annotated-tokens</code>, <code>emma:result-format</code>, <code>emma:expressed-through, emma:device-type</code>, <code>emma:stream-id</code>, <code>emma:stream-seq-num, emma:stream-status</code>, <code>emma:stream-full-result</code>, <code>emma:stream-token-span</code>, <code>emma:stream-token-span-full, emma:stream-token-immortals</code>, <code>emma:stream-immortal-vertex</code></span></li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:interpretation</code> element is legal only as a
child of <code>emma:emma</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, or
<code>emma:derivation</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:interpretation</code> element holds a single
interpretation represented in application specific markup, or a
single <code>emma:lattice</code> element, or a single
<code>emma:literal</code> element.</p>
<p>The <code>emma:interpretation</code> element MUST be empty if it
is marked with <code>emma:no-input="true"</code> <span>(<a href="#s4.2.3">Section 4.2.3</a>)</span>. The
<code>emma:interpretation</code> element <span>MUST</span> be empty
if it has been annotated with
<code>emma:uninterpreted="true"</code> <span>(<a href="#s4.2.4">Section 4.2.4</a>)</span> or
<code>emma:function="recording"</code> <span>(<a href="#s4.2.11">Section 4.2.11</a>)</span>.</p>
<p>Attributes:</p>
<ol>
<li><b>id</b> a REQUIRED <code>xsd:ID</code> value that uniquely
identifies the interpretation within the EMMA document.</li>
</ol>
<pre class="example">&lt;emma:emma version="1.1" xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="r1" emma:medium="acoustic" emma:mode="voice"&gt;
    ...
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>While <code>emma:medium</code> and <code>emma:mode</code> are
optional on <code>emma:interpretation</code>, note that all EMMA
interpretations must be annotated for <code>emma:medium</code> and
<code>emma:mode</code>, so either these attributes must appear
directly on <code>emma:interpretation</code> or they must appear on
an ancestor <code>emma:one-of</code> node or they must appear on an
earlier stage of the derivation listed in
<code>emma:derivation</code>.</p>
<h3>3.3 Output element: <code>emma:output</code>
  
</h3>

<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:output</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>The <code>emma:output</code> element acts as a wrapper for application instance data specifying a system output.</td>
    </tr>
    <tr>
      <th>Children</th>
      <td >The <code>emma:output</code> element MUST immediately
        contain either application instance data or a single <code>emma:literal</code> element. It MAY also contain multiple
          optional <code>emma:derived-from</code> element<span>s</span> and <span>multiple optional</span> <code>emma:info</code> <span>elements</span>.<span>  It MAY also contain multiple<code> emma:parameters</code> elements.  It may also contain a single <code>emma:location</code> element.</span></td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><b>Required</b>: Attribute <code>id</code> of type <code>xsd:ID</code> that uniquely identifies the output
          within the EMMA document.</li>
        <li><b>Optional</b>: The annotation attributes: <code>emma:tokens</code>, <code>emma:process</code>, <code>emma:lang</code>, <code>emma:signal</code>, <code><span>emma:signal-size</span></code>, <code>emma:media-type</code>, <code>emma:confidence</code>, <code>emma:source</code>, <code>emma:start</code>, <code>emma:end</code>, <code>emma:time-ref-uri</code>, <code>emma:time-ref-anchor-point</code>, <code>emma:offset-to-start</code>, <code>emma:duration</code>, <code>emma:medium</code>, <code>emma:mode</code>, <code>emma:function</code>, <code>emma:verbal</code>, <code>emma:cost</code>,<code> emma:endpoint-info-ref</code>, <code>emma:model-ref</code>, <code>emma:dialog-turn</code>,<code> <span>emma:info-ref</span></code><span><strong>, </strong><code>emma:parameter-ref</code>, <code>emma:process-model-ref</code>,<code> </code><code>emma:output-format,</code><code>emma:expressed-through.</code></span></li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:output</code> element is legal only as a
        child of <code>emma:emma</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, or <code>emma:derivation</code>.</td>
    </tr>
  </tbody>
</table>
<p >The <code>emma:output</code> element is used as a container for system output represented in EMMA. As such is the outside twin of <code>emma:interpretation</code>. For example, a dialog or interaction manager might generate an emma:output containing application specific semantic representation markup describing a system action. For example, to convey the availability of flights in a travel application. </p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
&lt;emma:output emma:confidence=&quot;0.9&quot; id=sem1&quot;
         emma:medium=&quot;acoustic&quot;
         emma:mode=&quot;voice&quot;
         emma:verbal=&quot;true&quot;
         emma:function=&quot;dialog&quot;
         emma:media-type=&quot;&quot;
         emma:start=&quot;&quot;
         emma:end=&quot;&quot;
         emma:lang=&quot;en-US&quot;
         emma:process=&quot;http://example.com/dialog_engine&quot;&gt;
             &lt;inform&gt;
               &lt;flights&gt;
                  &lt;src&gt;DEN&lt;/src&gt;
                  &lt;dest&gt;BOS&lt;/dest&gt;
                  &lt;airlines&gt;
                     &lt;airline&gt;United&lt;/airline&gt;
                     &lt;airline&gt;American&lt;/airline&gt;
                     &lt;airline&gt;Delta&lt;/airline&gt;
                  &lt;/airlines&gt;
               &lt;/flights&gt;
             &lt;/inform&gt;
&lt;/emma:output&gt;
&lt;/emma:emma&gt;</pre>

<p >The semantics of annotations on <code>emma:output</code> differs from <code>emma:interpretation</code>, since here we are seeing the stages of the planning of an intended output by the system. Future drafts will address issues of planned vs. actual output.</p>
<p >This representation would then be received by a natural language generation component with generates a text string for the system to speak, here captured in SSML. 
</p>
<pre class="example">&lt;emma:emma version=&quot;2.0&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;
    xmlns=&quot;http://www.w3.org/2001/10/synthesis&gt;
&lt;emma:output emma:confidence=&quot;0.8&quot; id=&quot;tts1&quot;&gt;
         emma:medium=&quot;acoustic&quot;
         emma:mode=&quot;voice&quot;
         emma:verbal=&quot;true&quot;
         emma:function=&quot;dialog&quot;
         emma:output-format=&quot;application/ssml+xml&quot;
         emma:media-type=&quot;&quot;
         emma:start=&quot;&quot;
         emma:end=&quot;&quot;
         emma:lang=&quot;en-US&quot;
         emma:process=&quot;http://example.com/nlg&quot;&gt;
         &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;
                                  xml:lang=&quot;en-US&quot;&gt;
         There are flights to Boston from Denver on United, American, and Delta.
         &lt;/speak&gt;
&lt;/emma:output&gt;
&lt;/emma:emma&gt;</pre>

<p >While <code>emma:medium</code> and <code>emma:mode</code> are
  optional on <code>emma:output</code>, note that all EMMA
  outputs must be annotated for <code>emma:medium</code> and <code>emma:mode</code>, so either these attributes must appear
  directly on <code>emma:output</code> or they must appear on
  an ancestor <code>emma:one-of</code> node or they must appear on an
  earlier stage of the derivation of the output listed in <code>emma:derivation</code>.</p>
<h3 id="s3.4">3.4 Container elements</h3>
<h3 id="s3.4.1">3.4.1 <code>emma:one-of</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:one-of</th>
</tr>
<tr>
<th>Definition</th>
<td>A container element indicating a disjunction among a collection
of mutually exclusive interpretations of the input.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:one-of</code> element MUST immediately contain a
collection of one or more <code>emma:interpretation</code> elements or one or more <code>emma:output</code> elements or container elements: <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code> UNLESS it is annotated with <code>ref</code>. <code>emma:output</code> elements and <code>emma:interpretation</code> elements MAY NOT be mixed under the same <code>emma:one-of element</code>. It MAY also
contain <span>multiple optional</span>
<code>emma:derived-from</code> element<span>s</span> and multiple <code>emma:info</code>
<span>element</span><span>s</span>. <span> It MAY also contain multiple optional<code> emma:annotation</code> elements. It MAY also contain multiple optional<code> emma:parameters</code> elements.  It MAY also contain multiple optional<code> emma:</code> elements. It MAY also contain a single optional <code>emma:grammar-active</code> element. It MAY also contain a single <code>emma:lattice</code> element containing the lattice result for the same input.   It may also contain a single <code>emma:location</code> element.</span></td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li>Attribute <code>id</code> of type <code>xsd:ID</code></li>
<li>The attribute <code>disjunction-type</code> MUST be present if
<code>emma:one-of</code> is embedded within
<code>emma:one-of</code>. <span>The possible values of
<code>disjunction-type</code> are {<code>recognition</code>,
<code>understanding</code>, <code>multi-device</code>, and
<code>multi-process</code>}.</span></li>
</ul>
</li>
<li><b>Optional</b>:
<ul>
<li>On a single non-embedded <code>emma:one-of</code> the attribute
<code>disjunction-type</code> is optional.</li>
<li >A single <code>ref</code> attribute of type <code>xsd:anyURI</code> providing a reference to a location where the content of the element can be retrieved from</li>
<li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from an external document through <code>ref</code></li>
<li>The following annotation attributes are optional:
<code>emma:tokens</code>, <code>emma:process</code>,
<code>emma:lang</code>, <code>emma:signal</code>,
<code><span>emma:signal-size</span></code>,
<code>emma:media-type</code>, <code>emma:confidence</code>,
<code>emma:source</code>, <code>emma:start</code>,
<code>emma:end</code>, <code>emma:time-ref-uri</code>,
<code>emma:time-ref-anchor-point</code>,
<code>emma:offset-to-start</code>, <code>emma:duration</code>,
<code>emma:medium</code>, <code>emma:mode</code>,
<code>emma:function</code>, <code>emma:verbal</code>,
<code>emma:cost</code>, <code>emma:grammar-ref</code>,
<code>emma:endpoint-info-ref</code>, <code>emma:model-ref</code>,
<code>emma:dialog-turn,<span>emma:info-ref</span></code><span><strong>, </strong><code>emma:parameter-ref</code>, <code>emma:process-model-ref</code>, <code>emma:annotated-tokens</code>, <code>emma:result-format</code>, <code>emma:expressed-through, emma:device-type</code>, <code>emma:stream-id</code>, <code>emma:stream-seq-num, emma:stream-status</code>, <code>emma:stream-full-result</code></span></li>
</ul></li></ul></td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:one-of</code> element MAY only appear as a child
of <code>emma:emma</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>, or
<code>emma:derivation</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:one-of</code> element acts as a container for a
collection of one or more interpretation
(<code>emma:interpretation</code>) or container elements
(<code>emma:one-of</code>, <code>emma:group</code>,
<code>emma:sequence</code>), and denotes that these are mutually
exclusive interpretations.</p>
<p>An N-best list of choices in EMMA MUST be represented as a set
of <code>emma:interpretation</code> elements contained within an
<code>emma:one-of</code> element. For instance, a series of
different recognition results in speech recognition might be
represented in this way.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="r1" <span>emma:medium="acoustic" emma:mode="voice"
    ref="http://www.example.com/i156/emma.xml#r1</span>&gt;
    &lt;emma:interpretation id="int1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>The function of the <code>emma:one-of</code> element is to
represent a disjunctive list of possible interpretations of a user
input. A disjunction of possible interpretations of an input can be
the result of different kinds of processing or ambiguity. One
source is multiple results from a recognition technology such as
speech or handwriting recognition. Multiple results can also occur
from parsing or understanding natural language. Another possible
source of ambiguity is from the application of multiple different
kinds of recognition or understanding components to the same input
signal. For example, an single ink input signal might be processed
by both handwriting recognition and gesture recognition. Another is
the use of more than one recording device for the same input
(multiple microphones).</p>
<p >The optional <code>ref</code> attribute indicates a location where a copy of the content within the <code>emma:one-of</code> element can be retrieved from an external document, possibly located on a remote server.</p>
<p>In order to make explicit these different kinds of multiple
interpretations and allow for concise statement of the annotations
associated with each, the <code>emma:one-of</code> element MAY
appear within another <code>emma:one-of</code> element. If
<code>emma:one-of</code> elements are nested then they MUST
indicate the kind of disjunction using the attribute
<code>disjunction-type</code>. The values of
<code>disjunction-type</code> are <code>{recognition,
understanding, multi-device, and multi-process}</code>. For the
most common use case, where there are multiple recognition results
and some of them have multiple interpretations, the top-level
<code>emma:one-of</code> is
<code>disjunction-type="recognition"</code> and the embedded
<code>emma:one-of</code> has the attribute
<code>disjunction-type="understanding"</code>.</p>
<p>As an example, in an interactive flight reservation application,
recognition yielded 'Boston' or 'Austin' and each had a semantic
interpretation as either the assertion of city name or the
specification of a flight query with the city as the destination,
this would be represented as follows in EMMA:</p>
<pre class="example"><span>
&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of disjunction-type="recognition"
      start="12457990" end="12457995"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
     &lt;emma:one-of disjunction-type="understanding"
         emma:tokens="boston"&gt;
       &lt;emma:interpretation&gt;
          &lt;assert&gt;&lt;city&gt;boston&lt;/city&gt;&lt;/assert&gt;
       &lt;/emma:interpretation&gt;
       &lt;emma:interpretation&gt;
          &lt;flight&gt;&lt;dest&gt;&lt;city&gt;boston&lt;/city&gt;&lt;/dest&gt;&lt;/flight&gt;
       &lt;/emma:interpretation&gt;
     &lt;/emma:one-of&gt;
     &lt;emma:one-of disjunction-type="understanding"
         emma:tokens="austin"&gt;
       &lt;emma:interpretation&gt;
          &lt;assert&gt;&lt;city&gt;austin&lt;/city&gt;&lt;/assert&gt;
       &lt;/emma:interpretation&gt;
       &lt;emma:interpretation&gt;
          &lt;flight&gt;&lt;dest&gt;&lt;city&gt;austin&lt;/city&gt;&lt;/dest&gt;&lt;/flight&gt;
       &lt;/emma:interpretation&gt;
     &lt;/emma:one-of&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</span>
</pre>

<p> In the following example, <code>emma:one-of</code> contains multiple <code>emma:output</code> elements containing different alternative spoken system outputs.</p>


<pre class="example">&lt;emma:emma version=&quot;2.0&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
&lt;emma:one-of id=&quot;ooo1&quot;
         emma:medium=&quot;acoustic&quot;
         emma:mode=&quot;voice&quot;
         emma:verbal=&quot;true&quot;
         emma:function=&quot;dialog&quot;
         emma:result-format=&quot;application/ssml+xml&quot;
         emma:lang=&quot;en=US&quot;
         emma:process=&quot;http://example.com/nlg&quot;&gt;
        &lt;emma:output emma:confidence=&quot;0.8&quot; id=&quot;tts1&quot;&gt;
             &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;
                                  xml:lang=&quot;en-US&quot;&gt;
             I found three flights from Boston to Denver.
             &lt;/speak&gt;
        &lt;/emma:output&gt;
        &lt;emma:output emma:confidence=&quot;0.7&quot; id=&quot;tts2&quot;&gt;
             &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;
                                  xml:lang=&quot;en-US&quot;&gt;
             There are flights to Boston from Denver on United, American, and Delta.
             &lt;/speak&gt;
        &lt;/emma:output&gt;
&lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>

<p>EMMA MAY explicitly represent ambiguity resulting from different
processes, devices, or sources using embedded
<code>emma:one-of</code> and the <code>disjunction-type</code>
attribute. Multiple different interpretations resulting from
different factors MAY also be listed within a single unstructured
<code>emma:one-of</code> though in this case it is more complex or
impossible to uncover the sources of the ambiguity if required by
later stages of processing. If there is no embedding in
<code>emma:one-of</code>, then the <code>disjunction-type</code>
attribute is not required. If the <code>disjunction-type</code>
attribute is missing then by default the source of disjunction is
unspecified.</p>
<p>The example case above could also be represented as:</p>
<pre class="example"><span>
&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of  start="12457990" end="12457995"
<span>         emma:medium="acoustic" emma:mode="voice"</span>&gt;
     &lt;emma:interpretation emma:tokens="boston"&gt;
        &lt;assert&gt;&lt;city&gt;boston&lt;/city&gt;&lt;/assert&gt;
     &lt;/emma:interpretation&gt;
     &lt;emma:interpretation &gt;
        &lt;flight&gt;&lt;dest&gt;&lt;city&gt;boston&lt;/city&gt;&lt;/dest&gt;&lt;/flight&gt;
     &lt;/emma:interpretation&gt;
     &lt;emma:interpretation emma:tokens="austin"&gt;
        &lt;assert&gt;&lt;city&gt;austin&lt;/city&gt;&lt;/assert&gt;
     &lt;/emma:interpretation&gt;
     &lt;emma:interpretation emma:tokens="austin"&gt;
        &lt;flight&gt;&lt;dest&gt;&lt;city&gt;austin&lt;/city&gt;&lt;/dest&gt;&lt;/flight&gt;
     &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</span>
</pre>
<p>But in this case information about which interpretations
resulted from speech recognition and which resulted from language
understanding is lost.</p>
<p>A list of <code>emma:interpretation</code> elements within an
<code>emma:one-of</code> MUST be sorted best-first by some measure
of quality. The quality measure is <code>emma:confidence</code> if
present, otherwise, the quality metric is platform-specific.</p>
<p>With embedded <code>emma:one-of</code> structures there is no
requirement for the confidence scores within different
<code>emma:one-of</code> to be on the same scale. For example, the
scores assigned by handwriting recognition might not be comparable
to those assigned by gesture recognition. Similarly, if multiple
recognizers are used there is no guarantee that their confidence
scores will be comparable. For this reason the ordering requirement
on <code>emma:interpretation</code> within <code>emma:one-of</code>
only applies locally to sister <code>emma:interpretation</code>
elements within each <code>emma:one-of</code>. There is no
requirement on the ordering of embedded <code>emma:one-of</code>
elements within a higher <code>emma:one-of</code> element.</p>
<p>While <code>emma:medium</code> and <code>emma:mode</code> are
optional on <code>emma:one-of</code>, note that all EMMA
interpretations must be annotated for <code>emma:medium</code> and
<code>emma:mode</code>, so either these annotations must appear
directly on all of the contained <code>emma:interpretation</code>
elements within the <code>emma:one-of</code>, or they must appear
on the <code>emma:one-of</code> element itself, or they must appear
on an ancestor <code>emma:one-of</code> element, or they must
appear on an earlier stage of the derivation listed in
<code>emma:derivation</code>.</p>
<p >An important use case for <code>ref</code> on <code>emma:one-of</code> is to allow an EMMA processor to return an abbreviated list of container elements such as <code>emma:interpretation</code> within an <code>emma:one-of</code> and use the <code>ref</code> attribute to provide a reference to a more fully specified set. In these cases, the <code>emma:one-of</code> MUST be annotated with the <code>emma:partial-content="true"</code> attribute.</p>
<p >In the following example the EMMA document received has the two interpretations within <code>emma:one-of</code>. The <code>emma:partial-content="true"</code> provides an indication that there are more interpretations and those can be retrieved by accessing the URI  in <code>ref</code> : <code>"http://www.example.com/emma_021210_10.xml#r1"</code>.</p>

<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="r1" <span>emma:medium="acoustic" emma:mode="voice"
    <span >ref="http://www.example.com/emma_021210_10.xml#r1</span><br>    emma:partial-content="true"&gt;
    &lt;emma:interpretation id="int1" 
     emma:tokens="from boston to denver"
     emma:confidence="0.9"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
     emma:tokens="from austin to denver"
     emma:confidence="0.7"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p> Where the document at "http://www.example.com/emma_021210_10.xml" is as follows, and
there are two more interpretations within the<code> emma:one-of</code> with id "r1".</p>

<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="r1" <span>emma:medium="acoustic" emma:mode="voice"<span ></span><br>    emma:partial-content="false"&gt;
    &lt;emma:interpretation id="int1" 
     emma:tokens="from boston to denver"
     emma:confidence="0.9"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
     emma:tokens="from austin to denver"
     emma:confidence="0.7"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3"
     emma:tokens="from tustin to denver"
     emma:confidence="0.3"&gt;
      &lt;origin&gt;Tustin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int4"
     emma:tokens="from tustin to dallas"
     emma:confidence="0.1"&gt;
      &lt;origin&gt;Tustin&lt;/origin&gt;
      &lt;destination&gt;Dallas&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</pre>
<p >It is also possible to specify a lattice of results alongside an N-best list of interpretations in <code>emma:one-of</code>. A single<code> emma:lattice</code> element can appear as a child of <code>emma:one-of</code> and contains a lattice representation of the processing of the same input resulting in the interpretations that appear within the <code>emma:one-of</code>.
In this example, there are two N-best results and the <code>emma:lattice</code> enumerates two more as it includes arcs for "tomorrow" vs "today".</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="r1" emma:medium="acoustic" emma:mode="voice"&gt;
    &lt;emma:interpretation id="int1" emma:tokens="flights from boston to denver tomorrow"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:tokens="flights from austin to denver tomorrow"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
	 &lt;emma:lattice initial="1" final="7"&gt;
      &lt;emma:arc from="1" to="2"&gt;flights&lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;from&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;boston&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;austin&lt;/emma:arc&gt;
      &lt;emma:arc from="4" to="5"&gt;to&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;denver&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="7"&gt;today&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="7"&gt;tomorrow&lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s3.4.2">3.4.2 <code>emma:group</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
<tr>
<th>Annotation</th>
<th>emma:group</th>
</tr>
<tr>
<th>Definition</th>
<td>A container element indicating that a number of interpretations
of distinct user inputs or system outputs are grouped according to some
criteria.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:group</code> element MUST immediately contain a
collection of one or more <code>emma:interpretation</code> elements
or container elements: <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code> . It MAY also
contain an <span>optional single</span>
<code>emma:group-info</code> element. It MAY also contain
<span>multiple optional</span> <code>emma:derived-from</code>
element<span>s</span> and multiple <code>emma:info</code> <span>element</span><span>s</span>. <span> It MAY also contain multiple optional<code> emma:annotation</code> elements. It MAY also contain multiple optional<code> emma:parameters</code> elements. It MAY also contain a single optional <code>emma:grammar-active</code> element.</span> It may also contain a single <code>emma:location</code> element.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>: Attribute <code>id</code> of type
<code>xsd:ID</code></li>
<li><b>Optional</b>: </li>
<li >A single <code>ref</code> attribute of type <code>xsd:anyURI</code> providing a reference to a location where the content of the element can be retrieved from</li>
<li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from  an external document through <code>ref</code></li>
<li>The annotation attributes: <code>emma:tokens</code>, <code>emma:process</code>,
  <code>emma:lang</code>, <code>emma:signal</code>,
  <code><span>emma:signal-size</span></code>,
  <code>emma:media-type</code>, <code>emma:confidence</code>,
  <code>emma:source</code>, <code>emma:start</code>,
  <code>emma:end</code>, <code>emma:time-ref-uri</code>,
  <code>emma:time-ref-anchor-point</code>,
  <code>emma:offset-to-start</code>, <code>emma:duration</code>,
  <code>emma:medium</code>, <code>emma:mode</code>,
  <code>emma:function</code>, <code>emma:verbal</code>,
  <code>emma:cost</code>, <code>emma:grammar-ref</code>,
  <code>emma:endpoint-info-ref</code>, <code>emma:model-ref</code>,
  <code>emma:dialog-turn,</code><code><span>emma:info-ref</span></code><span><strong>, </strong><code>emma:parameter-ref</code>, <code>emma:process-model-ref</code>, <code>emma:annotated-tokens</code>, <code>emma:result-format</code>, <code>emma:expressed-through, emma:device-type</code>.</span></li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:group</code> element is legal only as a child of
<code>emma:emma</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>, or
<code>emma:derivation</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:group</code> element is used to indicate that the
  contained interpretations are from distinct user inputs that are
  related in some manner. <code>emma:group</code> MUST NOT be used
  for containing the multiple stages of processing of a single user
  input. Those MUST be contained in the <code>emma:derivation</code>
  element instead <span>(<a href="#s4.1.2">Section 4.1.2</a>)</span>.
  For groups of inputs in temporal order the more specialized
  container <code>emma:sequence</code> MUST be used <span>(<a href="#s3.3.3">Section 3.3.3</a>)</span>. The following example shows
  three interpretations derived from the speech input "Move this
  ambulance here" and the tactile input related to two consecutive
points on a map.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:group id="grp"
      emma:start="1087995961542"
      emma:end="1087995964542"&gt;
    &lt;emma:interpretation id="int1"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
      &lt;action&gt;move&lt;/action&gt;
      &lt;object&gt;ambulance&lt;/object&gt;
      &lt;destination&gt;here&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
      <span>emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.253&lt;/x&gt;
      &lt;y&gt;0.124&lt;/y&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3"
      <span>emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.866&lt;/x&gt;
      &lt;y&gt;0.724&lt;/y&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:one-of</code> and <code>emma:group</code>
containers MAY be nested arbitrarily.</p>
<p >Like <code>emma:one-of</code> the contents for <code>emma:group</code> may be partial, indicated by <code>emma:partial-content="true"</code> and the full set of group members retrieved by accessing the element referenced in <code>ref</code>.</p>
<p ><code>emma:group</code> may also be used with multiple <code>emma:output</code> as children, for example to represent multimodal output where each <code>emma:output</code> contains content from a particular modality. For example,<code> emma:group</code> can contain a visual table in html grouped with a text-to-speech prompt in SSML, as in the example above (Section 2).</p>
<h4 id="s3.4.2.1">3.4.2.1 Indirect grouping criteria:
<code>emma:group-info</code> element</h4>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:group-info</th>
</tr>
<tr>
<th>Definition</th>
<td>The <code>emma:group-info</code> element contains or references
criteria used in establishing the grouping of interpretations in an
<code>emma:group</code> element.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:group-info</code> element MUST either
immediately contain inline instance data specifying grouping
criteria or have the attribute <code>ref</code> referencing the
criteria.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Optional</b>: <code>ref</code> of type
<code>xsd:anyURI</code> referencing the grouping criteria;
alternatively the criteria MAY be provided inline as the content of
the <code>emma:group-info</code> element.</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:group-info</code> element is legal only as a
child of <code>emma:group</code>.</td>
</tr>
</tbody>
</table>
<p>Sometimes it may be convenient to indirectly associate a given
group with information, such as grouping criteria. The
<code>emma:group-info</code> element might be used to make explicit
the criteria by which members of a group are associated. In the
following example, a group of two points is associated with a
description of grouping criteria based upon a sliding temporal
window of two seconds duration.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    xmlns:ex="http://www.example.com/ns/group"&gt;
  &lt;emma:group id="grp"&gt;
    &lt;emma:group-info&gt;
      &lt;ex:mode&gt;temporal&lt;/ex:mode&gt;
      &lt;ex:duration&gt;2s&lt;/ex:duration&gt;
    &lt;/emma:group-info&gt;
    &lt;emma:interpretation id="int1"
<span>      emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.253&lt;/x&gt;
      &lt;y&gt;0.124&lt;/y&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
      <span>emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.866&lt;/x&gt;
      &lt;y&gt;0.724&lt;/y&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>
<p>You might also use <code>emma:group-info</code> to refer to a
named grouping criterion using external reference, for
instance:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    xmlns:ex="http://www.example.com/ns/group"&gt;
  &lt;emma:group id="grp"&gt;
    &lt;emma:group-info ref="http://www.example.com/criterion42"/&gt;
    &lt;emma:interpretation id="int1"
      <span>emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.253&lt;/x&gt;
      &lt;y&gt;0.124&lt;/y&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
      <span>emma:medium="tactile" emma:mode="ink"</span>&gt;
      &lt;x&gt;0.866&lt;/x&gt;
      &lt;y&gt;0.724&lt;/y&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s3.4.3">3.4.3 <code>emma:sequence</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:sequence</th>
</tr>
<tr>
<th>Definition</th>
<td>A container element indicating that a number of interpretations
of distinct user inputs are in temporal sequence.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:sequence</code> element MUST immediately contain
a collection of one or more <code>emma:interpretation</code>
elements or container elements: <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code> . It MAY also
contain <span>multiple optional</span>
<code>emma:derived-from</code> elements and multiple <code>emma:info</code> <span>element</span><span>s</span>. <span> It MAY also contain multiple optional<code> emma:annotation</code> elements. It MAY also contain multiple optional<code> emma:parameters</code> elements. It MAY also contain a single optional <code>emma:grammar-active</code> element. </span> It may also contain a single <code>emma:location</code> element.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>: Attribute <code>id</code> of type
<code>xsd:ID</code></li>
<li><b>Optional</b>: </li>
<li >A single <code>ref</code> attribute of type <code>xsd:anyURI</code> providing a reference to a location where the content of the element can be retrieved from</li>
<li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from the server through <code>ref</code></li>
<li>The annotation attributes: <code>emma:tokens</code>, <code>emma:process</code>,
  <code>emma:lang</code>, <code>emma:signal</code>,
  <code><span>emma:signal-size</span></code>,
  <code>emma:media-type</code>, <code>emma:confidence</code>,
  <code>emma:source</code>, <code>emma:start</code>,
  <code>emma:end</code>, <code>emma:time-ref-uri</code>,
  <code>emma:time-ref-anchor-point</code>,
  <code>emma:offset-to-start</code>, <code>emma:duration</code>,
  <code>emma:medium</code>, <code>emma:mode</code>,
  <code>emma:function</code>, <code>emma:verbal</code>,
  <code>emma:cost</code>, <code>emma:grammar-ref</code>,
  <code>emma:endpoint-info-ref</code>, <code>emma:model-ref</code>,
  <code>emma:dialog-turn</code>,<code> <span>emma:info-ref</span></code><span><strong>, </strong><code>emma:parameter-ref</code>, <code>emma:process-model-ref</code>, <code>emma:annotated-tokens</code>, <code>emma:result-format</code>, <code>emma:expressed-through</code>, <code>emma:device-type</code></span>.</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:sequence</code> element is legal only as a child
of <code>emma:emma</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>, or
<code>emma:derivation</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:sequence</code> element is used to indicate that
  the contained interpretations are sequential in time, as in the
  following example, which indicates that two points made with a pen
  are in temporal order.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:sequence id="seq1"&gt;
    &lt;emma:interpretation id="int1"
        <span>emma:medium="tactile"</span> emma:mode="ink"&gt;
      &lt;x&gt;0.253&lt;/x&gt;
      &lt;y&gt;0.124&lt;/y&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
        <span>emma:medium="tactile"</span> emma:mode="ink"&gt;
      &lt;x&gt;0.866&lt;/x&gt;
      &lt;y&gt;0.724&lt;/y&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:sequence&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:sequence</code> container MAY be combined with
<code>emma:one-of</code> and <code>emma:group</code> in arbitrary
nesting structures. The order of children in the content of the
<code>emma:sequence</code> element corresponds to a sequence of
interpretations. This ordering does not imply any particular
definition of sequentiality. EMMA processors are expected therefore
to use the <code>emma:sequence</code> element to hold
interpretations which are either strictly sequential in nature
(e.g. the end-time of an interpretation precedes the start-time of
its follower), or which overlap in some manner (e.g. the start-time
of a follower interpretation precedes the end-time of its
precedent). It is possible to use timestamps to provide fine
grained annotation for the sequence of interpretations that are
sequential in time <span>(see <a href="#s4.2.10">Section
4.2.10)</a></span>.</p>
<p>In the following more complex example, a sequence of two pen
gestures in <code>emma:sequence</code> and a speech input in
<code>emma:interpretation</code> <span>is</span> contained in an
<code>emma:group</code>.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:group id="grp"&gt;
     &lt;emma:interpretation id="int1" emma:medium="acoustic"
         emma:mode="voice"&gt;
       &lt;action&gt;move&lt;/action&gt;
       &lt;object&gt;this-battleship&lt;/object&gt;
       &lt;destination&gt;here&lt;/destination&gt;
     &lt;/emma:interpretation&gt;
     &lt;emma:sequence id="seq1"&gt;
       &lt;emma:interpretation id="int2" emma:medium="tactile"
           emma:mode="ink"&gt;
         &lt;x&gt;0.253&lt;/x&gt;
         &lt;y&gt;0.124&lt;/y&gt;
       &lt;/emma:interpretation&gt;
     &lt;emma:interpretation id="int3" emma:medium="tactile"
         emma:mode="ink"&gt;
       &lt;x&gt;0.866&lt;/x&gt;
       &lt;y&gt;0.724&lt;/y&gt;
     &lt;/emma:interpretation&gt;
   &lt;/emma:sequence&gt;
 &lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>

<p>Like <code>emma:one-of</code> the contents for emma:group may be partial, indicated by <code>emma:partial-content="true"</code> and the full set of group members retrieved by accessing the element referenced in <code>ref</code>.</p>
<h3 id="s3.4">3.5 Lattice element</h3>
<p>In addition to providing the ability to represent N-best lists
of interpretations using <code>emma:one-of</code>, EMMA also
provides the capability to represent lattices of words or other
symbols using the <code>emma:lattice</code> element. Lattices
provide a compact representation of large lists of possible
recognition results or interpretations for speech, pen, or
multimodal inputs.</p>
<p>In addition to providing a representation for lattice output
from speech recognition, another important use case for lattices is
for representation of the results of gesture and handwriting
recognition from a pen modality component. Lattices can also be
used to compactly represent multiple possible meaning
representations. Another use case for the lattice representation is
for associating confidence scores and other annotations with
individual words within a speech recognition result string.</p>
<p>Lattices are compactly described by a list of transitions
between nodes. For each transition the start and end nodes MUST be
defined, along with the label for the transition. Initial and final
nodes MUST also be indicated. The following figure provides a
graphical representation of a speech recognition lattice which
compactly represents eight different sequences of words.</p>
<p><img alt="speech lattice" src="lattice.png"></p>
<p>which expands to:</p>
<pre>a. flights to boston from portland today please
b. flights to austin from portland today please
c. flights to boston from oakland today please
d. flights to austin from oakland today please
e. flights to boston from portland tomorrow
f. flights to austin from portland tomorrow
g. flights to boston from oakland tomorrow
h. flights to austin from oakland tomorrow
</pre>
<h3 id="s3.5.1">3.5.1 Lattice markup: <code>emma:lattice</code>,
<code>emma:arc</code>, <code>emma:node</code> elements</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:lattice</th>
</tr>
<tr>
<th>Definition</th>
<td>An element which encodes a lattice representation of user
input.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:lattice</code> element MUST immediately contain
one or more <code>emma:arc</code> elements and zero or more
<code>emma:node</code> elements.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
  <ul>
    <li><code>initial</code> <span>of type
      <code>xsd:nonNegativeInteger</code></span> indicating the number of
      the initial node of the lattice.</li>
    <li><code>final</code> contains a space-separated list of
      <code>xsd:nonNegativeInteger</code> indicating the numbers of the
      final nodes in the lattice.</li>
  </ul>
</li>
<li><b>Optional</b>: </li> 
<ul>
<li ><code>id</code>of type
      <code>xsd:id</code></li>
<li >A single <code>ref</code> attribute of type <code>xsd:anyURI</code> providing a reference to a location where the content of the lattice element can be retrieved from</li>
<li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from an external document  through <code>ref</code></li>
<li><code>emma:time-ref-uri</code>,
  <code>emma:time-ref-anchor-point</code>.</li></ul>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:lattice</code> element is legal only as a child
of the <code>emma:interpretation</code> and <code>emma:one-of</code> elements.</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:arc</th>
</tr>
<tr>
<th>Definition</th>
<td>An element which encodes a transition between two nodes in a
lattice. The label associated with the arc in the lattice is
represented in the content of <code>emma:arc</code>.</td>
</tr>
<tr>
<th>Children</th>
<td>The <code>emma:arc</code> element MUST immediately contain
either character data or a single application namespace element or
be empty, in the case of epsilon transitions. It MAY contain an
<code>emma:info</code> element containing application or vendor
specific annotations. <span>It MAY contain zero or more optional <code>emma:annotation</code> elements containing annotations made by a human annotator.</span></td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>from</code> <span>of type
<code>xsd:nonNegativeInteger</code></span> indicating the number of
the starting node for the arc.</li>
<li><code>to</code> <span>of type
<code>xsd:nonNegativeInteger</code></span> indicating the number of
the ending node for the arc.</li>
</ul>
</li>
<li><b>Optional</b>: <code>emma:start</code>,
<code>emma:end</code>, <code>emma:offset-to-start</code>,
<code>emma:duration</code>, <code>emma:confidence</code>,
<code>emma:cost</code>, <code>emma:lang</code>,
<code>emma:medium</code>, <code>emma:mode</code>,
<code>emma:source</code>, <code>emma:annotated-tokens</code>.</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:arc</code> element is legal only as a child of
the <code>emma:lattice</code> element.</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:node</th>
</tr>
<tr>
<th>Definition</th>
<td>An element which represents a node in the lattice. The
<code>emma:node</code> elements are not required to describe a
lattice but might be added to provide a location for annotations on
nodes in a lattice. There MUST be at most one
<code>emma:node</code> specification for each numbered node in the
lattice.</td>
</tr>
<tr>
<th>Children</th>
<td>An OPTIONAL <code>emma:info</code> element for application or
vendor specific annotations on the node. <span>It MAY contain zero or more optional <code>emma:annotation</code> elements containing annotations made by a human annotator.</span></td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>node-number</code> <span>of type
<code>xsd:nonNegativeInteger</code></span> indicating the
<span>node number</span> in the lattice.</li>
</ul>
</li>
<li><b>Optional</b>: <code>emma:confidence</code>,
<code>emma:cost</code>.</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:node</code> element is legal only as a child of
the <code>emma:lattice</code> element.</td>
</tr>
</tbody>
</table>
<p>In EMMA, a lattice is represented using an element
<code>emma:lattice</code>, which has attributes
<code>initial</code> and <code>final</code> for indicating the
initial and final nodes of the lattice. For the lattice
<span>below</span>, this will be: <code>&lt;emma:lattice
initial="1" final="8"/&gt;</code>. The nodes are numbered with
integers. If there is more than one distinct final node in the
lattice the nodes MUST be represented as a space separated list in
the value of the <code>final</code> attribute e.g.
<code>&lt;emma:lattice initial="1" final="9 10 23"/&gt;</code>.
There MUST only be one initial node in an EMMA lattice. Each
transition in the lattice is represented as an element
<code>emma:arc</code> with attributes <code>from</code> and
<code>to</code> which indicate the nodes where the transition
starts and ends. The arc's label is represented as the content of
the <code>emma:arc</code> element and MUST be any well-formed
character or XML content. In the example here the contents are
words. Empty (epsilon) transitions in a lattice MUST be represented
in the <code>emma:lattice</code> representation as
<code>emma:arc</code> <span>empty</span> elements, e.g.
<code>&lt;emma:arc from="1" to="8"/&gt;</code>.</p>
<p>The example speech lattice above would be represented in EMMA
markup as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice initial="1" final="8"&gt;
      &lt;emma:arc from="1" to="2"&gt;flights&lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;to&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;boston&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;austin&lt;/emma:arc&gt;
      &lt;emma:arc from="4" to="5"&gt;from&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;portland&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;oakland&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="7"&gt;today&lt;/emma:arc&gt;
      &lt;emma:arc from="7" to="8"&gt;please&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="8"&gt;tomorrow&lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Alternatively, if we wish to represent the same information as
an N-best list using <code>emma:one-of,</code> we would have the
more verbose representation:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="nbest1" <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="interp1"&gt;
      &lt;text&gt;flights to boston from portland today please&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretationid="interp2"&gt;
      &lt;text&gt;flights to boston from portland tomorrow&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp3"&gt;
      &lt;text&gt;flights to austin from portland today please&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp4"&gt;
      &lt;text&gt;flights to austin from portland tomorrow&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp5"&gt;
      &lt;text&gt;flights to boston from oakland today please&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp6"&gt;
      &lt;text&gt;flights to boston from oakland tomorrow&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp7"&gt;
      &lt;text&gt;flights to austin from oakland today please&lt;/text&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp8"&gt;
      &lt;text&gt;flights to austin from oakland tomorrow&lt;/text&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>The lattice representation avoids the need to enumerate all of
the possible word sequences. Also, as detailed below, the
<code>emma:lattice</code> representation enables placement of
annotations on individual words in the input.</p>
<p>For use cases involving the representation of gesture/ink
lattices and use cases involving lattices of semantic
interpretations, EMMA allows for application namespace elements to
appear within <code>emma:arc</code>.</p>
<p>For example a sequence of two gestures, each of which is
recognized as either a line or a circle<span>,</span> might be
represented as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice initial="1" final="3"&gt;
      &lt;emma:arc from="1" to="2"&gt;
        &lt;circle radius="100"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;
        &lt;line length="628"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="1" to="2"&gt;
        &lt;circle radius="200"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;
        &lt;line length="1256"/&gt;
      &lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>As an example of a lattice of semantic interpretations, in a
travel application where the source is either "Boston" or
"Austin"and the destination is either "Newark" or "New York", the
possibilities might be represented in a lattice as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice initial="1" final="3"&gt;
      &lt;emma:arc from="1" to="2"&gt;
        &lt;source city="boston"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;
        &lt;destination city="newark"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="1" to="2"&gt;
        &lt;source city="austin"/&gt;
      &lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;
        &lt;destination city="new york"/&gt;
      &lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:arc</code> element MAY contain either an
application namespace element or character data. It MUST NOT
contain combinations of application namespace elements and
character data. However, an <code>emma:info</code> element MAY
appear within an <code>emma:arc</code> element alongside character
data, in order to allow for the association of vendor or
application specific annotations on a single word or symbol in a
lattice. Also an<code> emma:annotation</code> element may appear as a child of <code>emma:arc</code> or <code>emma:node</code> indicating human annotations on the arc or node. </p>
<p>So, in summary, there are four groupings of content that can
appear within <code>emma:arc</code>:</p>
<ul>
<li>Character Data e.g. a recognized word in a speech lattice.</li>
<li>Character Data and a single <code>emma:info</code> element
providing vendor or application specific annotations that apply to
the character data.</li>
<li>An application namespace element e.g. the gesture and
<span>semantic interpretation</span> lattice examples above.</li>
<li>An application namespace element and a single
  <code>emma:info</code> element providing vendor or application
  specific annotations that apply to the character data.</li>
</ul>
<p>The <code>ref</code> attribute on <code>emma:lattice</code> can be used for cases where the lattice is not returned in the document, but is made accessible through <code>ref</code>, or for cases where the lattice is partial and a full lattice is available on the server.</p>
<p>For example the following<code> emma:lattice</code> does not contain any <code>emma:arc</code> elements but <code>ref</code> indicates where the lattice can retrieved from.</p>

<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    emma:medium="acoustic" emma:mode="voice"
    emma:tokens="flights to boston from oakland tomorrow"&gt;
    &lt;emma:lattice id="l1" initial="1" final="8"
      emma:partial-content="true" 
      ref="http://www.example.com/ex1/lattice.xml#l1"/&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>


The document on the server in this case could for example be as follows. 


<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    emma:medium="acoustic" emma:mode="voice"
    emma:tokens="flights to boston from oakland tomorrow"&gt;
    &lt;emma:lattice id="l1" initial="1" final="8"
      emma:partial-content="false"&gt;
      &lt;emma:arc from="1" to="2"&gt;flights&lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;to&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;boston&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;austin&lt;/emma:arc&gt;
      &lt;emma:arc from="4" to="5"&gt;from&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;portland&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;oakland&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="7"&gt;today&lt;/emma:arc&gt;
      &lt;emma:arc from="7" to="8"&gt;please&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="8"&gt;tomorrow&lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>


<p>Similarly the <code>emma:lattice</code> could have some arcs but not all and point to through <code>ref</code> to the full lattice. In this case the EMMA document received is a pruned lattice and the full lattice can be retrieved by accessing the external document indicated in <code>ref</code>.</p>


<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    emma:medium="acoustic" emma:mode="voice"&gt;
    &lt;emma:lattice id="l1" initial="1" final="8"
      emma:partial-content="true"
      ref="http://www.example.com/ex1/lattice.xml#l1"&gt;
      &lt;emma:arc from="1" to="2"&gt;flights&lt;/emma:arc&gt;
      &lt;emma:arc from="2" to="3"&gt;to&lt;/emma:arc&gt;
      &lt;emma:arc from="3" to="4"&gt;boston&lt;/emma:arc&gt;
      &lt;emma:arc from="4" to="5"&gt;from&lt;/emma:arc&gt;
      &lt;emma:arc from="5" to="6"&gt;portland&lt;/emma:arc&gt;
      &lt;emma:arc from="6" to="8"&gt;tomorrow&lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>


<h3 id="s3.4.2">3.5.2 Annotations on lattices</h3>
<p>The encoding of lattice arcs as XML elements
(<code>emma:arc</code>) enables arcs to be annotated with metadata
such as timestamps, costs, or confidence scores:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice initial="1" final="8"&gt;
      &lt;emma:arc
       from="1"
       to="2"
       emma:start="1087995961542"
       emma:end="1087995962042"
       emma:cost="30"&gt;
         flights
<strong>       </strong><span>&lt;emma:annotation id="label3"
       	annotator="john_smith"
      		time="2011-11-10T09:00:21"
	    	type="emotion"
      		confidence="1.0"
      		reference="false"&gt;
      		&lt;emotionml xmlns="http://www.w3.org/2009/10/emotionml"&gt;
        		&lt;emotion&gt;
           		&lt;category set="everyday" name="angry"/&gt;<br>           		&lt;modality medium="acoustic" mode="voice"/&gt;
        	 	&lt;/emotion&gt;
      		&lt;/emotionml&gt;
        &lt;/emma:annotation&gt;</span>
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="2"
       to="3"
       emma:start="1087995962042"
       emma:end="1087995962542"
       emma:cost="20"&gt;
         to
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="3"
       to="4"
       emma:start="1087995962542"
       emma:end="1087995963042"
       emma:cost="50"&gt;
         boston
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="3"
       to="4"
       emma:start="1087995963042"
       emma:end="1087995963742"
       emma:cost="60"&gt;
         austin
      &lt;/emma:arc&gt;
      ...
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The following EMMA attributes MAY be placed on
<code>emma:arc</code> elements: absolute timestamps
(<code>emma:start</code>, <code>emma:end</code>), relative
timestamps ( <code>emma:offset-to-start</code>,
<code>emma:duration</code>), <code>emma:confidence</code>,
<code>emma:cost</code>, the human language of the input
(<code>emma:lang</code>), <code>emma:medium</code>,
<code>emma:mode</code>,  <code>emma:source</code>, <span>and <code>emma:annotated-tokens</code></span>. The use case
  for <code>emma:medium</code>, <code>emma:mode</code>, and
  <code>emma:source</code> is for lattices which contains content
  from different input modes. The <code>emma:arc</code> element MAY
  also contain an <code>emma:info</code> element for specification of
  vendor and application specific annotations on the arc. <span>The<code> emma:arc</code> and <code>emma:node</code> elements can also contain optional <code>emma:annotation</code> elements containing annotations mae by human annotators. For example, in the example above <code>emma:annotation</code> is used to indicate manual annotation of emotion on the word 'flights'.</span></p>
<p>The timestamps that appear on <code>emma:arc</code> elements do
not necessarily indicate the start and end of the arc itself. They
MAY indicate the start and end of the signal corresponding to the
label on the arc. As a result there is no requirement that the
<code>emma:end</code> timestamp on an arc going into a node should
be equivalent to the <code>emma:start</code> of all arcs going out
of that node. Furthermore there is no guarantee that the left to
right order of arcs in a lattice will correspond to the temporal
order of the input signal. The lattice representation is an
abstraction that represents a range of possible interpretations of
a user's input and is not intended to necessarily be a
representation of temporal order.</p>
<p>Costs are typically application and device dependent. There are
a variety of ways that individual arc costs might be combined to
produce costs for specific paths through the lattice. This
specification does not standardize the way for these costs to be
combined; it is up to the applications and devices to determine how
such derived costs would be computed and used.</p>
<p>For some lattice formats, it is also desirable to annotate the
nodes in the lattice themselves with information such as costs. For
example in speech recognition, costs might be placed on nodes as a
result of word penalties or redistribution of costs. For this
purpose EMMA also provides an <code>emma:node</code> element which
can host annotations such as <code>emma:cost</code>. The
<code>emma:node</code> element MUST have an attribute
<code>node-number</code> which indicates the number of the node.
There MUST be at most one <code>emma:node</code> specification for
a given numbered node in the lattice. In our example, if there was
a cost of <b>100</b> on the final state this could be represented
as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1" 
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice initial="1" final="8"&gt;
      &lt;emma:arc
       from="1"
       to="2"
       emma:start="1087995961542"
       emma:end="1087995962042"
       emma:cost="30"&gt;
         flights
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="2"
       to="3"
       emma:start="1087995962042"
       emma:end="1087995962542"
       emma:cost="20"&gt;
         to
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="3"
       to="4"
       emma:start="1087995962542"
       emma:end="1087995963042"
       emma:cost="50"&gt;
         boston
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="3"
       to="4"
       emma:start="1087995963042"
       emma:end="1087995963742"
       emma:cost="60"&gt;
         austin
      &lt;/emma:arc&gt;
        ...
      &lt;emma:node node-number="8" emma:cost="100"/&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s3.4.3">3.5.3 Relative timestamps on lattices</h3>
<p>The relative timestamp mechanism in EMMA is intended to provide
temporal information about arcs in a lattice in relative terms
using offsets in milliseconds. In order to do this the absolute
time MAY be specified on <code>emma:interpretation</code>; both
<code>emma:time-ref-uri</code> and
<code>emma:time-ref-anchor-point</code> apply to
<code>emma:lattice</code> and MAY be used there to set the anchor
point for offsets to the start of the absolute time specified on
<code>emma:interpretation</code>. The offset in milliseconds to the
beginning of each arc MAY then be indicated on each
<code>emma:arc</code> in the <code>emma:offset-to-start</code>
attribute.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;

  &lt;emma:interpretation id="interp1"
          emma:start="1087995961542" emma:end="1087995963042"
          <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:lattice emma:time-ref-uri="#interp1"
        emma:time-ref-anchor-point="start"
        initial="1" final="4"&gt;
      &lt;emma:arc
       from="1"
       to="2"
       emma:offset-to-start="0"&gt;
         flights
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="2"
       to="3"
       emma:offset-to-start="500"&gt;
         to
      &lt;/emma:arc&gt;
      &lt;emma:arc
       from="3"
       to="4"
       emma:offset-to-start="1000"&gt;
         boston
      &lt;/emma:arc&gt;
    &lt;/emma:lattice&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Note that the offset for the first <code>emma:arc</code> MUST
always be zero since the EMMA attribute
<code>emma:offset-to-start</code> indicates the number of
milliseconds from the anchor point to the <i>start</i> of the piece
of input associated with the <code>emma:arc</code>, in this case
the word "flights".</p>
<h3 id="s3.5">3.6 Literal semantics: <code>emma:literal</code>
element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:literal</th>
</tr>
<tr>
<th>Definition</th>
<td>An element that contains string literal output.</td>
</tr>
<tr>
<th>Children</th>
<td>String literal</td>
</tr>
<tr>
<th>Attributes</th>
<td>An optional <code>emma:result-format</code> attribute.</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:literal</code> is a child of
<code>emma:interpretation</code>.</td>
</tr>
</tbody>
</table>
<p>Certain EMMA processing components produce semantic results in
the form of string literals without any surrounding application
namespace markup. These MUST be placed with the EMMA element
<code>emma:literal</code> within <code>emma:interpretation</code>.
For example, if a semantic interpreter simply returned "boston"
this could be represented in EMMA as:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation <span>id="r1" 
     emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:literal&gt;boston&lt;/emma:literal&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Note that a raw recognition result of a sequence of words from
speech recognition is also a kind of string literal and can be
contained within <code>emma:literal</code>. For example,
recognition of the string "flights to san francisco" can be
represented in EMMA as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation <span>id="r1" 
     emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:literal&gt;flights to san francisco&lt;/emma:literal&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<h2 id="s4">4. EMMA annotations</h2>
<p>This section defines annotations in the EMMA namespace including
both attributes and elements. The values are specified in terms of
the data types defined by XML Schema Part 2: Datatypes <span>Second
Edition</span> [<a href="#XSD2"><span>XML Schema
Datatypes</span></a>].</p>
<h3 id="s4.1">4.1 EMMA annotation elements</h3>
<h3 id="s4.1.1">4.1.1 Data model: <code>emma:model</code>
element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:model</th>
</tr>
<tr>
<th>Definition</th>
<td>The <code>emma:model</code> either references or provides
inline the data model for the instance data.</td>
</tr>
<tr>
<th>Children</th>
<td>If a <code>ref</code> attribute is not specified then this
element contains the data model inline.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>id</code> of type <code>xsd:ID</code>.</li>
</ul>
</li>
<li><b>Optional</b>:
<ul>
<li><code>ref</code> of type <code>xsd:anyURI</code> that
references the data model. Note that either an <code>ref</code>
attribute or in-line data model (but not both) MUST be
specified.</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:model</code> element MAY appear only as a child
of <code>emma:emma</code>.</td>
</tr>
</tbody>
</table>
<p>The data model that may be used to express constraints on the
structure and content of instance data is specified as one of the
annotations of the instance. Specifying the data model is OPTIONAL,
in which case the data model can be said to be implicit. Typically
the data model is pre-established by the application.</p>
<p>The data model is specified with the <code>emma:model</code>
annotation defined as an element in the EMMA namespace. If the data
model for the contents of a <code>emma:interpretation</code>,
container elements, or application namespace element is to be
specified in EMMA, the attribute <code>emma:model-ref</code> MUST
be specified on the <code>emma:interpretation</code>, container
element, or application namespace element. Note that since multiple
<code>emma:model</code> elements might be specified under the
<code>emma:emma</code> it is possible to refer to multiple data
models within a single EMMA document. For example, different
alternative interpretations under an <code>emma:one-of</code> might
have different data models. In this case, an
<code>emma:model-ref</code> attribute would appear on each
<code>emma:interpretation</code> element in the N-best list with
its value being the <code>id</code> of the <code>emma:model</code>
element for that particular interpretation.</p>
<p>The data model is closely related to the interpretation data,
  and is typically specified as the annotation related to the
  <code>emma:interpretation</code> or <code>emma:one-of</code>
elements.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:model id="model1" ref="http://example.com/models/city.xml"/&gt;
  &lt;emma:interpretation id="int1" emma:model-ref="model1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;city&gt; London &lt;/city&gt;
    &lt;country&gt; UK &lt;/country&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:model</code> annotation MAY reference any element
or attribute in the application instance data, as well as any EMMA
container element (<code>emma:one-of</code>,
<code>emma:group</code>, or <code>emma:sequence</code>).</p>
<p>The data model annotation MAY be used to either reference an
external data model with the <code>ref</code> attribute or provide
a data model as in-line content. Either a <code>ref</code>
attribute or in-line data model (but not both) MUST be
specified.</p>
<p >Note that unlike the use of <code>ref</code> on e.g. <code>emma:one-of</code> it is not possible in EMMA to provide a partial specification of the data model inline and use <code>emma:partial-content="true"</code> to indicate that the full data model is available from the URI in <code>ref</code>.</p>
<h3 id="s4.1.2">4.1.2 Interpretation derivation:
<code>emma:derived-from</code> element and
<code>emma:derivation</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:derived-from</th>
</tr>
<tr>
<th>Definition</th>
<td>An empty element which provides a reference to the
interpretation which the element it appears on was derived
from.</td>
</tr>
<tr>
<th>Children</th>
<td>None</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>resource</code> of type <code>xsd:anyURI</code> that
references the interpretation from which the current interpretation
is derived.</li>
</ul>
</li>
<li><b>Optional</b>:
<ul>
<li><code>composite</code> of type <code>xsd:boolean</code> that is
<code>"true"</code> if the derivation step combines multiple inputs
and <code>"false"</code> if not. If <code>composite</code> is not
specified the value is <code>"false"</code> by default.</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:derived-from</code> element is legal only as a
child of <code>emma:interpretation</code>,
<code>emma:output, emma:one-of</code>, <code>emma:group</code>, or
<code>emma:sequence</code>.</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:derivation</th>
</tr>
<tr>
<th>Definition</th>
<td>An element which contains interpretation and container elements
representing earlier stages in the processing of the input.</td>
</tr>
<tr>
<th>Children</th>
<td>One or more <code>emma:interpretation</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, or
<code>emma:group</code> elements.</td>
</tr>
<tr>
<th>Attributes</th>
<td>None</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:derivation</code> MAY appear only as a child of
the <code>emma:emma</code>, <code>emma:interpretation</code>, <code>emma:output</code>, <code>emma:one-of</code>, <code>emma:group</code>, and <code>emma:sequence</code> elements.</td>
</tr>
</tbody>
</table>
<p>Instances of interpretations are in general derived from other
instances of interpretation in a process that goes from raw data to
increasingly refined representations of the input. The derivation
annotation is used to link any two interpretations that are related
by representing the source and the outcome of an interpretation
process. For instance, a speech recognition process can return the
following result in the form of raw text:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="raw"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>A first interpretation process will produce:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="better"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;tomorrow&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>A second interpretation process, aware of the current date, will
be able to produce a more refined instance, such as:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="best"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;20030315&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The interaction manager might need to have access to the three
levels of interpretation. The <code>emma:derived-from</code>
annotation element can be used to establish a chain of derivation
relationships as in the following example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:interpretation id="raw"
<span>      emma:medium="acoustic" emma:mode="voice"</span>&gt;
      &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="better"&gt;
      &lt;emma:derived-from resource="#raw" composite="false"/&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="best"&gt;
    &lt;emma:derived-from resource="#better" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;20030315&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:derivation</code> element MAY be used as a
container for representations of the earlier stages in the
interpretation of the input. The <code>emma:derivation</code> element MAY appear only as a child of the <code>emma:emma</code>, <code>emma:interpretation</code>, <code>emma:one-of</code>, <code>emma:group</code>, <code>emma:sequence </code>elements. That is, it can be a child of <code>emma:emma</code>, or any container element except literal or lattice. If <code>emma:derivation</code> appears within a container it MUST apply to that specific element, or to a descendant of that element. The latest stage of processing MUST be
a direct child of <code>emma:emma</code>. </p>
<p>The resource attribute on <code>emma:derived-from</code> is a
URI which can reference IDs in the current or other EMMA
documents. Since <code>emma:derivation</code> elements can appear in multiple different places, EMMA processors MUST use the <code>emma:derived-from</code> element to identify earlier stages of the processing of an input, rather than the document structure. The option to have <code>emma:derivation</code> in  locations other than directly under <code>emma:emma</code> is provided to make the document more transparent and improve human readability.</p>
<p>In the following example,<code> emma:sequence</code> is used to represent a sequence of two spoken inputs and each has its own <code>emma:derivation </code>element containing the previous stage of processing.</p>

<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:sequence&gt;
    &lt;emma:interpretation id="nlu1"&gt;
      &lt;emma:derived-from resource="#raw1" composite="false"/&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;emma:derivation&gt;
         &lt;emma:interpretation id="raw1"<br>          <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
            &lt;emma:literal&gt;flights from boston&lt;/emma:literal&gt;
         &lt;/emma:interpretation&gt;
      &lt;/emma:derivation&gt;
  &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="nlu2"&gt;
      &lt;emma:derived-from resource="#raw2" composite="false"/&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;emma:derivation&gt;
         &lt;emma:interpretation id="raw2"<br>          <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
            &lt;emma:literal&gt;to denver&lt;/emma:literal&gt;
         &lt;/emma:interpretation&gt;
      &lt;/emma:derivation&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:sequence&gt;
&lt;/emma:emma&gt;</pre>
<p>In addition to representing sequential derivations, the EMMA
  <code>emma:derived-from</code> element can also be used to capture
  composite derivations. Composite derivations involve combination of
inputs from different modes.</p>
<p>In order to indicate whether an <code>emma:derived-from</code>
element describes a sequential derivation step or a composite
derivation step, the <code>emma:derived-from</code> element has an
attribute <code>composite</code> which has a boolean value. A
composite <code>emma:derived-from</code> MUST be marked as
<code>composite="true"</code> while a sequential
<code>emma:derived-from</code> element is marked as
<code>composite="false"</code>. If this attribute is not specified
the value is <code>false</code> by default.</p>
<p>In the following composite derivation example the user said
"destination" using the voice mode and circled Boston on a map
using the ink mode:</p>
<div>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:interpretation id="voice1"
        emma:start="1087995961500"
        emma:end="1087995962542"
        emma:process="http://example.com/myasr.xml"
        emma:source="http://example.com/microphone/NC-61"
        emma:signal="http://example.com/signals/sg23.wav"
        emma:confidence="0.6"
        emma:medium="acoustic"
        emma:mode="voice"
        emma:function="dialog"
        emma:verbal="true"
        emma:lang="en-US"
        emma:tokens="destination"&gt;
      &lt;rawinput&gt;destination&lt;/rawinput&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="ink1"
        emma:start="1087995961600"
        emma:end="1087995964000"
        emma:process="http://example.com/mygesturereco.xml"
        emma:source="http://example.com/pen/wacom123"
        emma:signal="http://example.com/signals/ink5.inkml"
        emma:confidence="0.5"
        emma:medium="tactile"
        emma:mode="ink"
        emma:function="dialog"
        emma:verbal="false"&gt;
      &lt;rawinput&gt;Boston&lt;/rawinput&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="multimodal1"
      emma:confidence="0.3"
      <span>emma:start="1087995961500"</span>
      <span>emma:end="1087995964000"</span>
      emma:medium="<span>acoustic tactile</span>"
      emma:mode="<span>voice ink</span>"
      emma:function="dialog"
      emma:verbal="true"
      emma:lang="en-US"
      emma:tokens="destination"&gt;
    &lt;emma:derived-from resource="#voice1" composite="true"
    &lt;emma:derived-from resource="#ink1" composite="true"
    &lt;destination&gt;Boston&lt;/destination&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre></div>
<p>In this example, annotations on the multimodal interpretation
indicate the process used for the integration and there are two
<code>emma:derived-from</code> elements, one pointing to the speech
and one pointing to the pen gesture.</p>
<p>The only constraints the EMMA specification places on the
annotations that appear on a composite input are that the
<code>emma:medium</code> attribute MUST contain the union of the
<code>emma:medium</code> attributes on the combining inputs,
represented as a space delimited set of <code>nmtokens</code> as
defined in <a href="#s4.2.11">Section 4.2.11</a>, and that the
<code>emma:mode</code> attribute MUST contain the union of the
<code>emma:mode</code> attributes on the combining inputs,
represented as a space delimited set of <span><code>nmtokens</code>
as defined in <a href="#s4.2.11">Section 4.2.11</a></span>. In the
example above this meanings that the <code>emma:medium</code> value
is <code>"acoustic tactile"</code> and the <code>emma:mode</code>
attribute is <code>"voice ink"</code>. How all other annotations
are handled is author defined. In the following paragraph,
informative examples on how specific annotations might be handled
are given.</p>
<p>With reference to the illustrative example above, this paragraph
provides informative guidance regarding the determination of
annotations (beyond <code>emma:medium</code> and
<code>emma:mode</code> on a composite multimodal interpretation).
Generally the timestamp on a combined input should contain the
intervals indicated by the combining inputs. For the absolute
timestamps <code>emma:start</code> and <code>emma:end</code> this
can be achieved by taking the earlier of the
<code>emma:start</code> values
(<code>emma:start="1087995961500"</code> in our example) and the
later of the <code>emma:end</code> values
(<code>emma:end="1087995964000"</code> in the example). The
determination of relative timestamps for composite is more complex,
informative guidance is given in <a href="#s4.2.10.4">Section
4.2.10.4</a>. Generally speaking the <code>emma:confidence</code>
value will be some numerical combination of the confidence scores
assigned to the combining inputs. In our example, it is the result
of multiplying the voice and ink confidence scores
(<code>0.3</code>). In other cases there may not be a confidence
score for one of the combining inputs and the author may choose to
copy the confidence score from the input which does have one.
Generally, for <code>emma:verbal</code>, if either of the inputs
has the value <code>true</code> then the multimodal interpretation
will also be <code>emma:verbal="true"</code> as in the example. In
other words the annotation for the composite input is the result of
an inclusive OR of the boolean values of the annotations on the
inputs. If an annotation is only specified on one of the combining
inputs then it may in some cases be assumed to apply to the
multimodal interpretation of the composite input. In the example,
<code>emma:lang="en-US"</code> is only specified for the speech
input, and this annotation appears on the composite result also.
Similarly in our example, only the voice has
<code>emma:tokens</code> and the author has chosen to annotate the
combined input with the same <code>emma:tokens</code> value. In
this example, the <code>emma:function</code> is the same on both
combining input and the author has chosen to use the same
annotation on the composite interpretation.</p>
<p>In annotating derivations of the processing of the input, EMMA
provides the flexibility of both course-grained or fine-grained
annotation of relations among interpretations. For example, when
relating two N-best lists, within <code>emma:one-of</code> elements
either there can be a single <code>emma:derived-from</code> element
under <code>emma:one-of</code> referring to the ID of the
<code>emma:one-of</code> for the earlier processing stage:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:one-of id="nbest1"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
      &lt;emma:interpretation id="int1"&gt;
       &lt;res&gt;from boston to denver on march eleven two thousand three&lt;/res&gt;
      &lt;/emma:interpretation&gt;
      &lt;emma:interpretation id="int2"&gt;
       &lt;res&gt;from austin to denver on march eleven two thousand three&lt;/res&gt;
      &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:derivation&gt;
&lt;emma:one-of id="nbest2"&gt;
  &lt;emma:derived-from resource="#nbest1" composite="false"/&gt;
  &lt;emma:interpretation id="int1b"&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03112003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
  &lt;emma:interpretation id="int2b"&gt;
    &lt;origin&gt;Austin&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03112003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>Or there can be a separate <code>emma:derived-from</code>
element on each <code>emma:interpretation</code> element referring
to the specific <code>emma:interpretation</code> element it was
derived from.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="nbest2"&gt;
    &lt;emma:interpretation id="int1b"&gt;
     &lt;emma:derived-from resource="#int1" composite="false"/&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2b"&gt;
     &lt;emma:derived-from resource="#int2" composite="false"/&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
  &lt;emma:derivation&gt;
    &lt;emma:one-of id="nbest1"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
      &lt;emma:interpretation id="int1"&gt;
       &lt;res&gt;from boston to denver on march eleven two thousand three&lt;/res&gt;
      &lt;/emma:interpretation&gt;
      &lt;emma:interpretation id="int2"&gt;
       &lt;res&gt;from austin to denver on march eleven two thousand three&lt;/res&gt;
      &lt;/emma:interpretation&gt;
    &lt;/emma:one-of&gt;
  &lt;/emma:derivation&gt;
&lt;/emma:emma&gt;
</pre>
<p><a href="#s4.3">Section 4.3</a> provides further examples of the
use of <code>emma:derived-from</code> to represent sequential
derivations and addresses the issue of the scope of EMMA
annotations across derivations of user input.</p>
<h3 id="s4.1.3">4.1.3 Reference to grammar used:
<code>emma:grammar</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:grammar</th>
</tr>
<tr>
<th>Definition</th>
<td>An element used indicate the grammar used in
processing the input. <span>The grammar MUST either be specified inline OR referenced using the <code>ref </code>attribute.</span></td>
</tr>
<tr>
<th>Children</th>
<td>In the case of inline specification of the grammar, this element contains an element with the specification of the grammar.</td>
</tr>
<tr>
<th>Attributes</th>
<td><ul>
<li><b>Optional</b>:
<ul>
    <li><code><span>grammar-type</span></code> of type <code>xsd:string</code>
      that indicate the MIME type of the grammar</li>
    <li><code><span>ref</span></code> of type <code>xsd:anyURI</code> that references a grammar used in processing the input.</li>
    </ul>
    </li>
<li><b>Required</b>:
  <ul>
    <li><code>id</code> of type <code>xsd:ID</code>.</li>
    </ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:grammar</code> is legal only as a child of the
<code>emma:emma</code> element.</td>
</tr>
</tbody>
</table>
<p>The grammar that was used to derive the EMMA result MAY be
specified with the <code>emma:grammar</code> annotation defined as
an element in the EMMA namespace. The <code>emma:grammar-ref</code> attribute appears on the specific interpretation and references the appropriate <code>emma:grammar</code> element. <span>The <code>emma:grammar</code> element MUST either contain a representation of the grammar inline OR have a <code>ref</code> attribute which contains a URI referencing the grammar used in processing the input. The optional attribute <code>grammar-type</code> on <code>emma:grammar</code> contains a MIME type indicating the format of the specified grammar. For example an SRGS grammar in the XML format SHOULD be annotated as <code>grammar-type="application/srgs-xml"</code>. The namespace of an inline grammar MUST be specified. </span></p>
<p>In the following example, there are three interpretations. Each interpretation is annotated with <code>emma:grammar-ref </code>to indicate the grammar that resulted in that interpretation. The two <code>emma:grammar</code> elements indicate the URI for the grammar using the <code>ref</code> attribute. Both grammars are SRGS XML grammars and so are annotated as <code>grammar-type="application/srgs-xml"</code>. </p>
<span>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:grammar id="gram1" grammar-type="application/srgs-xml"<span> ref</span>="someURI"/&gt;
  &lt;emma:grammar id="gram2" <span>grammar-type="application/srgs-xml" ref</span>="anotherURI"/&gt;
  &lt;emma:one-of id="r1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="int1" emma:grammar-ref="gram1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:grammar-ref="gram1"&gt;
        &lt;origin&gt;Austin&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3" emma:grammar-ref="gram2"&gt;
        &lt;command&gt;help&lt;/command&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
</span>
<p>In the following example, there are two interpretations, each from a different grammar, and the SRGS grammars used to derive the interpretations are specified inline each as a child of an <code>emma:grammar</code> element. The namespace of the inline grammars is indicated explicitly on each. </p>

<span>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:grammar id="gram1" grammar-type="application/srgs-xml"<span></span>&gt;<br>   &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xsi:schemaLocation="http://www.w3.org/2001/06/grammar 
    http://www.w3.org/TR/speech-grammar/grammar.xsd"
    xml:lang="en" version="1.1" root="state" mode="voice"
    tag-format="semantics/1.0"&gt;<br>      &lt;rule id="state" scope="public"&gt;
       &lt;one-of&gt;
         &lt;item&gt;California&lt;tag&gt;out="CA";&lt;/tag&gt;&lt;/item&gt;
         &lt;item&gt;New Jersey&lt;tag&gt;out="NJ";&lt;/tag&gt;&lt;/item&gt;
         &lt;item&gt;New York&lt;tag&gt;out="NY";&lt;/tag&gt;&lt;/item&gt;
       &lt;/one-of&gt;
      &lt;/rule&gt;<br>    &lt;/grammar&gt;
  &lt;/emma:grammar&gt;
  &lt;emma:grammar id="gram2" grammar-type="application/srgs-xml"<span></span>&gt;<br>   &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xsi:schemaLocation="http://www.w3.org/2001/06/grammar 
    http://www.w3.org/TR/speech-grammar/grammar.xsd"
    xml:lang="en" version="1.1" root="city" mode="voice"
    tag-format="semantics/1.0"&gt;<br>      &lt;rule id="city" scope="public"&gt;
       &lt;one-of&gt;
         &lt;item&gt;Calgary&lt;tag&gt;out="YYC";&lt;/tag&gt;&lt;/item&gt;
         &lt;item&gt;San Francisco&lt;tag&gt;out="SFO";&lt;/tag&gt;&lt;/item&gt;
         &lt;item&gt;Boston&lt;tag&gt;out="BOS";&lt;/tag&gt;&lt;/item&gt;
       &lt;/one-of&gt;
      &lt;/rule&gt;<br>    &lt;/grammar&gt;
  &lt;/emma:grammar&gt;
  &lt;emma:one-of id="r1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="int1" emma:tokens="California" 
     emma:grammar-ref="gram1"&gt;
      &lt;emma:literal&gt;CA&lt;/emma:literal&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:tokens="Calgary"
     emma:grammar-ref="gram2"&gt;
      &lt;emma:literal&gt;YYC&lt;/emma:literal&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</pre>
</span>

<p>Non-XML grammar formats, such as the SRGS ABNF format, MUST be contained within <code>&lt;!-[CDATA[ ...]]&gt;</code>. Care should be taken in platforms generating EMMA to avoid conflicts between<code> id</code> values in the EMMA markup and those in any inline grammars. Authors should be aware that there could be conflicts between <code>id</code> values used in different embedded inline grammars within an EMMA document.</p>
<p >Note that unlike the use of <code>ref</code> on e.g. <code>emma:one-of</code> it is not possible in EMMA to provide a partial specification of the grammar inline and use <code>emma:partial-content="true"</code> to indicate that the full grammar is available from the URI in <code>ref</code>.</p>


<h3 id="s4.1.4">4.1.4 Reference to grammars active: <code>emma:grammar-active</code> element</h3>


<span>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>    </tr>
  </tbody>
</table>
</span>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:grammar-active</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An element used to indicate the grammars active during the processing of an input.</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>A list of <code>emma:active</code> elements, one for each grammar currently active.</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><span><b>Required</b>:
          </span>
          <ul>
            <li><code>id</code> of type <code>xsd:ID</code>.</li>
          </ul>
        </li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:one-of</code>, <code>emma:group</code>, <code>emma:sequence</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:active</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An element specifying a particular grammar active during the processing of an input.</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>None</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><span><b>Required</b>:
          </span>
          <ul>
            <li><code>grammar-ref</code> of type <code>xsd:ID</code>.</li>
          </ul>
        </li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:grammar-active</code></td>
    </tr>
  </tbody>
</table>
<span>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr> </tr>
  </tbody>
</table>
</span>

<p>The default when multiple <code>emma:grammar</code> elements are specified under <code>emma:emma</code> is to assume that all grammars are active for all of the interpretations specified in the top level of the current EMMA document. In certain use cases, such as documents containing results from different microphones or different modalities, this may not be the case and the set of grammars active for a specific interpretation or set of interpretations should be annotated explicitly using <code>emma:grammar-active</code>. Each grammar which is active is indicated by an active element which must have an <code>emma:grammar-ref</code> annotation pointing to the specific grammar. For example, to make explicit the fact that both grammars, <code>gram1</code> and <code>gram2</code> are active for all of the three N-best interpretations in the following example, an emma:grammar-active element appears as a child of the <code>emma:one-of</code>.</p>

<span>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:grammar id="gram1" grammar-type="application/srgs-xml"<span> ref</span>="someURI"/&gt;
  &lt;emma:grammar id="gram2" <span>grammar-type="application/srgs-xml" ref</span>="anotherURI"/&gt;
  &lt;emma:one-of id="r1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
	 &lt;emma:grammar-active&gt;
		&lt;emma:active emma:grammar-ref="gram1"/&gt;
      &lt;emma:active emma:grammar-ref="gram2"/&gt;
    &lt;/emma:grammar-active&gt;
    &lt;emma:interpretation id="int1" emma:grammar-ref="gram1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:grammar-ref="gram1"&gt;
        &lt;origin&gt;Austin&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3" emma:grammar-ref="gram2"&gt;
        &lt;command&gt;help&lt;/command&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
</span>

<p>The use of an element for each active grammar, allows for more complex use cases where specific metadata is associated with each active grammar. For example, a weighting of other parameters associated with each active grammar could be specified within an <code>emma:info</code> within <code>emma:active</code>.</p>
<h3 id="s4.1.5">4.1.5 Extensibility to application/vendor specific
  annotations: <code>emma:info</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:info</th>
</tr>
<tr>
<th>Definition</th>
<td>The <code>emma:info</code> element acts as a container for
vendor and/or application specific metadata regarding a user's
input.</td>
</tr>
<tr>
<th>Children</th>
<td><span>One of more</span> elements in the application namespace
providing metadata about the input.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Optional</b>:
<ul>
<li><code>id</code> of type <code>xsd:ID</code></li>
<li ><code><span>ref</span></code> of type <code>xsd:anyURI</code> that references a remote document containing a specification of application/vendor specific annotations</li>
<li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from an external document  through <code>ref</code></li>
<li><code>indexed </code>of type<code> xsd:boolean</code> indicating whether it has index scope</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:info</code> element is legal only as a child of
the EMMA elements <code>emma:emma</code>,
<code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:arc</code>,  <code>emma:node</code>, <code>emma:output</code>, <span>or<code> emma:annotation</code>.</span></td>
</tr>
</tbody>
</table>
<p>In <a href="#s4.2">Section 4.2</a>, a series of attributes are
defined for representation of metadata about user inputs in a
standardized form. EMMA also provides an extensibility mechanism
for annotation of user inputs with vendor or application specific
metadata not covered by the standard set of EMMA annotations. The
element <code>emma:info</code> MUST be used as a container for
these annotations, UNLESS they are explicitly covered by
<code>emma:endpoint-info</code>. For example, if an input to a
dialog system needed to be annotated with the number that the call
originated from, their state, some indication of the type of
customer, and the name of the service, these pieces of information
could be represented within <code>emma:info</code> as in the
following example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:info id="info_details"&gt;
    &lt;caller_id&gt;
      &lt;phone_number&gt;2121234567&lt;/phone_number&gt;
      &lt;state&gt;NY&lt;/state&gt;
    &lt;/caller_id&gt;
    &lt;customer_type&gt;residential&lt;/customer_type&gt;
    &lt;service_name&gt;acme_travel_service&lt;/service_name&gt;
  &lt;/emma:info&gt;
  &lt;emma:one-of id="r1" <br>      emma:start="1087995961542"
      emma:end="1087995963542"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:confidence="0.68"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>It is important to have an EMMA container element for
application/vendor specific annotations since EMMA elements provide
a structure for representation of multiple possible interpretations
of the input. As a result it is cumbersome to state
application/vendor specific metadata as part of the application
data within each <code>emma:interpretation</code>. An element is
used rather than an attribute so that internal structure can be
given to the annotations within <code>emma:info</code>.</p>
<p>In addition to <code>emma:emma</code>, <code>emma:info</code>
MAY also appear as a child of other structural elements such as
<code>emma:interpretation</code>, <code>emma:one-of</code> and so on.
When <code>emma:info</code> appears as a child of one of these
elements the application/vendor specific annotations contained
within <code>emma:info</code> are assumed to apply to all of the
<code>emma:interpretation</code> elements within the containing
element. The semantics of conflicting annotations in
<code>emma:info</code>, for example when different values are found
within <code>emma:emma</code> and <code>emma:interpretation</code>,
are left to the developer of the vendor/application specific
annotations.</p>
<p>There may be more than one <code>emma:info</code> element. One of the functions of this is to enable specification interpretations to indicate which <code>emma:info</code> applies to them using <code>emma:info-ref</code><var>. </var>If <code>emma:info</code> has the optional <code>id</code> attribute then the <code>emma:info-ref</code> attribute (<a href="#s4.2.19">Section 4.2.19</a>) can be used on <code>emma:interpretation</code> and other container elements to indicate that a particular set of application/vendor specific annotations apply to a particular interpretation. </p>
<p>The <code>emma:info</code>
element can therefore have either position scope (applies to the element it appears in and the interpretations within in), or index scope where  <code>emma:info-ref </code>attributes are used to show which interpretations a particular <code>emma:info</code> applies to. In order to distinguish emma:info elements that have positional vs. index scope the indexed attribute must be used. The attribute<code> indexed=true</code> indicates that the <code>emma:info</code> it appears on does not have positional scope and instead is referenced using <code>emma:info-ref</code>. The attribute<code> indexed=false</code> indicates than an <code>emma:info</code> has positional scope. The default value if <code>indexed</code> is not specified is <code>false</code>. The <code>indexed</code> attribute is required if and only if there is an <code>emma:info-ref </code>that refers to the <code>id</code> of the <code>emma:info</code>.</p>
<p >The <code>ref</code> attribute can also be used on <code>emma:info</code> instead of placing the application/vendor specific annotations inline. For example, assuming the example above was available at <code>http://example.com/examples/123/emma.xml</code>, the EMMA document delivered to an EMMA consumer could be:</p>
<pre >&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:info ref="http://example.com/examples/123/emma.xml#info_details"/&gt;
  &lt;emma:one-of id="r1" <br>      emma:start="1087995961542"
      emma:end="1087995963542"
      emma:medium="acoustic" emma:mode="voice"&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:confidence="0.68"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;03112003&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</pre>
<p >A <code>ref</code> on <code>emma:info</code> can also be used to point to an external document, not necessarily an EMMA document, containing additional annotations on the interpretation. For example, it could be used to point to an XML document providing a list of the specifications of the input device.</p>

<h3 class="notoc">4.1.6 Endpoint reference:
  <code>emma:endpoint-info</code> element and
<code>emma:endpoint</code> element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:endpoint-info</th>
</tr>
<tr>
<th>Definition</th>
<td>The <code>emma:endpoint-info</code> element acts as a container
for all application specific annotation regarding the communication
environment.</td>
</tr>
<tr>
<th>Children</th>
<td>One or more <code>emma:endpoint</code> elements.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li><b>Required</b>:
<ul>
<li><code>id</code> of type <code>xsd:ID</code>.</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td>The <code>emma:endpoint-info</code> elements is legal only as a
child of <code>emma:emma</code>.</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:endpoint</th>
</tr>
<tr>
<th>Definition</th>
<td>The element acts as a container for application specific
endpoint information.</td>
</tr>
<tr>
<th>Children</th>
<td>Elements in the application namespace providing metadata about
the input.</td>
</tr>
<tr>
<th>Attributes</th>
<td>
<ul>
<li>Required:
<ul>
<li><code>id</code> of type <code>xsd:ID</code></li>
</ul>
</li>
<li>Optional: <code>emma:endpoint-role</code>,
<code>emma:endpoint-address</code>, <code>emma:message-id</code>,
<code>emma:port-num</code>, <code>emma:port-type</code>,
<code>emma:endpoint-pair-ref</code>,
<code>emma:service-name</code>, <code>emma:media-type</code>,
<code>emma:medium</code>, <code>emma:mode</code>.</li>
</ul>
</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint-info</code></td>
</tr>
</tbody>
</table>
<p>In order to conduct multimodal interaction, there is a need in
EMMA to specify the properties of the endpoint that receives the
input which leads to the EMMA annotation. This allows subsequent
components to utilize the endpoint properties as well as the
annotated inputs to conduct meaningful multimodal interaction. EMMA
element <code>emma:endpoint</code> can be used for this purpose. It
can specify the endpoint properties based on a set of common
endpoint property attributes in EMMA, such as
<code>emma:endpoint-address</code>, <code>emma:port-num</code>,
<code>emma:port-type</code>, etc. (<a href="#s4.2.14">Section
4.2.14</a>). Moreover, it provides an extensible annotation
structure that allows the inclusion of application and vendor
specific endpoint properties.</p>
<p>Note that the usage of the term "endpoint" in this context is
different from the way that the term is used in speech processing,
where it refers to the end of a speech input. As used here,
"endpoint" refers to a network location which is the source or
recipient of an EMMA document.</p>
<p>In multimodal interaction, multiple devices can be used and each
device can open multiple communication endpoints at the same time.
These endpoints are used to transmit and receive data, such as raw
input, EMMA documents, etc. The EMMA element
<code>emma:endpoint</code> provides a generic representation of
endpoint information which is relevant to multimodal interaction.
It allows the annotation to be interoperable, and it eliminates the
need for EMMA processors to create their own specialized
annotations for existing protocols, potential protocols or yet
undefined private protocols that they may use.</p>
<p>Moreover, <code>emma:endpoint-info</code> provides a container
to hold all annotations regarding the endpoint information,
including <code>emma:endpoint</code> and other application and
vendor specific annotations that are related to the communication,
allowing the same communication environment to be referenced and
used in multiple interpretations.</p>
<p>Note that EMMA provides two locations (i.e.
<code>emma:info</code> and <code>emma:endpoint-info</code>) for
specifying vendor/application specific annotations. If the
annotation is specifically related to the description of the
endpoint, then the vendor/application specific annotation SHOULD be
placed within <code>emma:endpoint-info</code>, otherwise it SHOULD
be placed within <code>emma:info</code>.</p>
<p>The following example illustrates the annotation of endpoint
reference properties in EMMA.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    xmlns:ex="http://www.example.com/emma/port"&gt;
  &lt;emma:endpoint-info id="audio-channel-1"&gt;
    &lt;emma:endpoint id="endpoint1"
        emma:endpoint-role="sink"
        emma:endpoint-address="135.61.71.103"
        emma:port-num="50204"
        emma:port-type="rtp"
        emma:endpoint-pair-ref="endpoint2"
        emma:media-type="audio/dsr-202212; rate:8000; maxptime:40"
        emma:service-name="travel"
        emma:mode="voice"&gt;
      &lt;ex:app-protocol&gt;SIP&lt;/ex:app-protocol&gt;
    &lt;/emma:endpoint&gt;
    &lt;emma:endpoint id="endpoint2"
        emma:endpoint-role="source"
        emma:endpoint-address="136.62.72.104"
        emma:port-num="50204"
        emma:port-type="rtp"
        emma:endpoint-pair-ref="endpoint1"
        emma:media-type="audio/dsr-202212; rate:8000; maxptime:40"
        emma:service-name="travel"
        emma:mode="voice"&gt;
      &lt;ex:app-protocol&gt;SIP&lt;/ex:app-protocol&gt;
    &lt;/emma:endpoint&gt;
  &lt;/emma:endpoint-info&gt;
  &lt;emma:interpretation id="int1"
      emma:start="1087995961542" emma:end="1087995963542"
      emma:endpoint-info-ref="audio-channel-1"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>ex:app-protocol</code> is provided by the application
or the vendor specification. It specifies that the application
layer protocol used to establish the speech transmission from the
"source" port to the "sink" port is Session Initiation Protocol
(SIP). This is specific to SIP based VoIP communication, in which
the actual media transmission and the call signaling that controls
the communication sessions, are separated and typically based on
different protocols. In the above example, the Real-time
Transmission Protocol (RTP) is used in the media transmission
between the source port and the sink port.</p>
<h3 id="s4.1.7">4.1.7 Reference to process model used: <code>emma:process-model </code>element</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:process-model</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An element used indicate the model used in
        processing the input. The model must be  referenced using the <code>ref </code>attribute which is URI valued.</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>None.</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><span><b>Required</b>:
          </span>
          <ul>
            <li><code>id</code> of type <code>xsd:ID</code>.</li>
            <li><code>ref</code> of type <code>xsd:anyURI</code> that references a model used in processing the input.</li>
            <li><code>type</code> of type <code>xsd:string</code> that indicates the type of model</li>
            </ul>
        </li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:process-model</code> is legal only as a child of the <code>emma:emma</code> element.</td>
    </tr>
  </tbody>
</table>
<p>The model that was used to derive the EMMA result MAY be
  specified with the <code>emma:process-model</code> annotation defined as
  an element in the EMMA namespace. The <code>emma:process-model-ref</code> attribute appears on the specific interpretation and references the appropriate <code>emma:process-model</code> element. The <code>emma:process-model</code> element MUST  have a <code>ref</code> attribute which contains a URI referencing the model used in processing the input. Unlike <code>emma:grammar</code>, <code>emma:process-model</code> does not allow for inline specification of a model. For each  <code>emma:process-model </code>element there MUST be an <code>emma:process-model-ref</code> in the document those value is the <code>id</code> of that <code>emma:process-model</code>. The<code> emma:process-model</code> element cannot have positional scope.</p>
<p>The <code>emma:process-model</code> element MUST have an attribute <strong><code>type</code></strong> containing a string indicating the type of model referenced. The value of type is drawn from an open set including <code>{svm,crf,neural_network,hmm...}</code>.</p>
<p>Examples of potential uses of <code>emma:process-model</code> include referencing the model used for handwriting recognition or a text classification model used for natural language understanding. The <code>emma:process-model</code> annotation SHOULD be used for input processing models that are not grammars. Grammars SHOULD be referenced or specified inline using <code>emma:grammar</code>. Some input processing modules may utilize both a recognition model and a grammar. For example, for handwriting recognition of electronic ink a neural network might be used for character recognition while a language model or grammar is used to constrain the word or character sequences recognized. In this case, the neural network SHOULD be referenced using <code>emma:process-model</code> and the grammar or language model using <code>emma:grammar</code>.</p>
<p>The <code>emma:process-model</code> element can also be used with <code>emma:output.</code></p>
<p>In the following example, there are two interpretations. The EMMA document in this example is produced by a computer vision system doing object recognition. The first interpretation is generated by a process model for vehicle recognition and second competing interpretation is generated by a process model for person recognition.</p>
<pre class="example"><span>&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:process-model id="pm1"
    type="neural_network"
    ref="http://example.com/vision/vehicle"/&gt;
  &lt;emma:process-model id="pm2"
    type="neural_network"
    ref="http://example.com/vision/people"/&gt;
  &lt;emma:one-of id="r1"
    emma:start="1087995961542"
    emma:end="1087995961542"
    emma:medium="visual" 
    emma:mode="image"
    emma:process="http://example.com/mycompvision1.xml"&gt;&gt;
    &lt;emma:interpretation id="int1"
      emma:confidence="0.9"
      emma:process-model-ref="pm1"&gt;
      &lt;object&gt;aircraft&lt;/object&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" 
      emma:confidence="0.1"
      emma:process-model-ref="pm2"&gt;
      &lt;object&gt;person&lt;/object&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</span>
</pre>

<h3 id="s4.1.8">4.1.8 Reference to parameters used by a process: <code>emma:parameters
</code>and <code>emma:parameter</code> elements</h3>

<table class="defn" summary="property definition" cellpadding="5" cellspacing="0" width="98%">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:parameters</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An element used indicate a set of parameters used to configure a processor used  in producing an EMMA result.&nbsp;</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>Any number of <code>emma:parameter</code> elements</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td>
      <ul>
        <li><span><b>Required</b>:
          </span>
          <ul>
            <li><code>id</code> of type <code>xsd:ID</code>.</li>
          </ul>
        </li>
         <li><b>Optional</b>:
           <ul>
             <li><code>api-ref</code> of type <code>xsd:string</code>.</li>
             <li ><code>ref</code> of type <code>xsd:anyURI</code> that references a document containing a list of parameters</li>
             <li >An <code>emma:partial-content</code> attribute of type <code>xsd:boolean</code> indicating whether the content inside the element is partial and more can be retrieved from an external document  through <code>ref</code></li>
           </ul>
         </li>
      </ul>
      </td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:parameters</code> MAY appear only as a child of
the <code>emma:emma</code>, <code>emma:interpretation</code>, <code>emma:one-of</code>, <code>emma:group</code>, <code>emma:output</code>, and <code>emma:sequence</code> elements.</td>
    </tr>
    <tr>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:parameter</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An element used indicate a specific parameter in the configuration of a processor used in producing an EMMA result.&nbsp;</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>None</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td>
      <ul>
        <li><span><b>Required</b>:
          </span>
          <ul>
            <li><code>name</code> of type <code>xsd:string</code>.</li>
            <li><code>value</code> of type <code>xsd:string</code>.</li>
          </ul>
        </li>
        <li><span><b>Optional</b>:
          </span>
          <ul>
            <li><code>api-ref</code> of type <code>xsd:string</code>.</li>
          </ul>
        </li>
      </ul>
      </td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:parameter </code>is legal only as a
child
of
the <code>emma:parameters</code> element.</td>
    </tr>
  </tbody>
</table>
<p>A set of parameters that were used to configure the EMMA processor that produces an EMMA result MAY be
specified with the <code>emma:parameters</code> annotation defined as
an element in the EMMA namespace. The <code>emma:parameter-ref</code> attribute 
(Section <a href="#s4.2.21">4.2.21</a>) appears on the specific <code>emma:interpretation</code> or other container element and references the
appropriate <code>emma:parameters</code> element.&nbsp;For example, typical parameters for speech recognition such as confidence thresholds, speed vs. accuracy, timeouts, settings for endpointing etc can be included in <code>emma:parameters</code>.</p>
<p>For each <code>emma:parameters </code>element there MUST be an <code>emma:parameter-ref</code> in the document those value is the <code>id</code> of that <code>emma:parameters</code>. The<code> emma:parameters</code> element cannot have positional scope.</p>
<p>The optional attribute  <code>api-ref </code>on<code> emma:parameter</code> and <code>emma:parameters</code>, specifies the specific API that the name and value of a parameter is drawn from or names and values of the set of parameters are drawn from. It's value is a string from an open set including: <strong>{vxml2.1, vxml2.0, MRCPv2, MRCPv1, html+speech, OpenCV....}</strong>. A parameters <code>name</code> and <code>value</code> are from the API specified in <code>api-ref</code> on the <code>emma:parameter</code> element if present. Otherwise, they are from the API specified in <code>api-ref</code>, if present, on the surrounding <code>emma:parameters</code> element. If the <code>api-ref</code> is not defined on either <code>emma:parameter</code> or <code>emma:parameters</code> the API that the name(s) and value(s) are drawn from is undefined.</p>
<p>In the following example, the
  interpretation is annotated with <code>emma:parameter-ref </code>to
  indicate the set of processing parameters that resulted in that
interpretation. These are contained within an <code>emma:parameters</code> under <code>emma:emma</code>. The API for the first two parameters is inherited from <code>emma:parameters</code> and is <code>"vxml2.1"</code>. The API for the third parameter is vendor specific and specified directly in <code>api-ref</code> on that <code>emma:parameter </code>element.</p>

<span>
<pre class="example">&lt;emma:emma version="1.1"<br>    xmlns:emma="http://www.w3.org/2003/04/emma"<br>    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"<br>    xsi:schemaLocation="http://www.w3.org/2003/04/emma<br>     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"<br>    xmlns="http://www.example.com/example"&gt;<br>    &lt;emma:parameters id="parameters1" api-ref="vxml2.1"&gt;<br>	   &lt;emma:parameter name="confidencelevel" value=".9"/&gt;<br>	   &lt;emma:parameter name="completetimeout" value=".3s"/&gt;
      &lt;emma:parameter name="word_confusion_network_confidence" value="YES" 
       api-ref="x-acme-recognizer"/&gt;<br>    &lt;/emma:parameters&gt;<br>    &lt;emma:interpretation id="int1" emma:parameter-ref="parameters1" 
       emma:medium="acoustic" emma:mode="voice"
       emma:process="http://example.com/asr&gt;<br>      &lt;origin&gt;Boston&lt;/origin&gt;<br>    &lt;/emma:interpretation&gt;<br>&lt;/emma:emma&gt;<br>
</pre>
</span>

<p>
Note that in an EMMA document describing a multimodal input or a derivation with multiple steps there may be multiple different<code> emma:parameters</code> elements specifying the parameters used for each specific mode or processing stage. 
The relationship between a <code>emma:parameters</code> element and the container element it applies 
to is captured by the<code> emma:parameter-ref</code> attribute. </p>
<p >Instead of specifying parameters inline the <code>ref</code> attribute can be used to provide a URI reference to an external document containing the parameters. <span class="note"></span>This could be either a pointer to an <code>emma:parameters</code> element within an EMMA document, or it can be a reference to a non-EMMA document containing a  specification of the parameters. In the following example, the <code>emma:parameters</code> element contains a reference to an separate parameters document.</p>
<pre class="example">&lt;emma:emma version="1.1"<br>    xmlns:emma="http://www.w3.org/2003/04/emma"<br>    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"<br>    xsi:schemaLocation="http://www.w3.org/2003/04/emma<br>     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"<br>    xmlns="http://www.example.com/example"&gt;<br>    &lt;emma:parameters id="parameters1" api-ref="vxml2.1" ref="http://example.com/mobile/asr/params.xml"<br>    &lt;/emma:parameters&gt;<br>    &lt;emma:interpretation id="int1" emma:parameter-ref="parameters1" 
       emma:medium="acoustic" emma:mode="voice"
       emma:process="http://example.com/asr&gt;<br>      &lt;origin&gt;Boston&lt;/origin&gt;<br>    &lt;/emma:interpretation&gt;<br>&lt;/emma:emma&gt;<br></pre>
<h3 id="s4.1.9">4.1.9 Human annotation: <code>emma:annotation</code> element
</h3>

<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:annotation</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>The <code>emma:annotation</code> element acts as a container for annotations of user inputs made by human labellers</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>One or more elements 
        providing annotations of the input. May also contain a single <code>emma:info</code> element.</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><span><b>Optional</b>:
          </span>
          <ul>
            <li><code>id</code> of type <code>xsd:ID</code>.</li>
            <li><code>annotator</code> of type <code>xsd:string</code> indicating the name or other identifier of the annotator</li>
            <li><code>type</code> of type <code>xsd:string</code> from the open set {transcription,semantics,emotion ...}</li>
            <li><code>time</code> of type <code>xsd:dateTime</code> indicating the time at which the annotation label was made</li>
            <li><code>reference</code> of type <code>xsd:boolean</code> indicating if this annotation is the reference for the current interpretation</li>
            <li><code>emma:confidence</code> an attribute of type <code>xsd:decimal</code> in range 0.0 to
1.0, indicating the annotators confidence in their annotation.</li>
            <li><code>ref</code> an attribute of type <code>xsd:anyURI</code> used to refer to an annotation outside of the document</li>
          </ul>
        </li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:annotation</code> element is legal only as a child of
        the EMMA elements <code>emma:emma</code>,<code> emma:interpretation</code>,<code> emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:arc</code>, or <code>emma:node</code>.</td>
    </tr>
  </tbody>
</table>

<span>

<p>In many spoken and multimodal applications, at some time after user interactions have taken place, human labellers are used to provide annotation of the input. For example, for speech input the most common annotation is to transcribe the actual words spoken by the user by listening to the audio. The correct semantic interpretation of the input may also be annotated. Labellers may also annotate other aspects of the input such as the emotional state of the user.</p>
<p>To provide support for augmenting logged EMMA documents with human annotations, the EMMA markup provides the<code> emma:annotation</code> element. Multiple instances of this element can appear as a children of the various EMMA containers. In examples with <code>emma:one-of</code> and multiple <code>emma:interpretation</code> elements, <code>emma:annotation</code> will generally appear as a child of <code>emma:one-of </code>as it is an annotation of the signal rather than of the specific interpretation hypotheses encoded in the individual interpretations. The <code>emma:annotation</code> element can also be used to annotated arcs and states in lattices by including it in <code>emma:arc</code> and <code>emma:node</code>.</p>
<p>In addition to <code>id</code>, the <code>emma:annotation</code> element provides a series of optional attributes that MAY be used to provide metadata regarding the annotation. The <code>annotator</code> attribute contains a string indicating the name or other idenitifier of the annotator.  The <code>type</code> attribute indicates the kind of annotation and has an open set of values<code> {transcription, semantics, emotion ...}</code>.  The <code>time</code> attribute on <code>emma:annotation</code> does not have any relation to the time of the input itself, rather it indicates the date and time that the annotation was made. The <code>emma:confidence</code> attribute is a value between 0 and 1 indicating the annotators confidence in their annotation. The <code>reference</code> attribute is a boolean which indicates whether the annotation is appears on is the reference annotation for the interpretation as opposed to some other annotation of the input. For example, if the interpretation in the EMMA document is a speech recognition result, annotation of the reference string SHOULD have <code>reference="true"</code>, while an annotation of the emotional state of the user should be annotated as <code>reference="false"</code> Further metadata regarding the annotation can be captured by using <code>emma:info</code> within <code>emma:annotation</code>.</p>
</span>
<p>In addition to specifying annotations inline the ref attribute on the <code>emma:annotation</code> element can be used to refer to an external document containing the annotation content.</p>
<span>
<p>In the following example, the EMMA document contains an N-best list with two recognition hypotheses and their semantic representations. Under <code>emma:one-of </code>there are three different annotations all made by different annotators on different days and times. The first is the transcription, this indicates that in fact neither of the N-best results was correct and actual utterance spoken was "flights from austin to denver tomorrow". The second annotation (<code>label2</code>) contains the annotated semantic intepretation of the reference string. The third annotation contains an additional piece of metadata captured by a human labeller, specifically it captures the fact that based on the audio, the user's emotional state was angry. Here as an illustration we utilize <a href="#emotionml">Emotion ML</a> markup.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="int1" emma:start="1087995961542"
      emma:end="1087995963542"
      <span>emma:medium="acoustic" 
      emma:mode="voice"</span>
      emma:function="dialog"
      emma:verbal="true"
      emma:signal="http://example.com/signals/audio457.wav"&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"
      emma:tokens="flights from boston to denver tomorrow"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:confidence="0.68"
      emma:tokens="flights from austin to denver today"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;today&lt;/date&gt;
    &lt;/emma:interpretation&gt;
    <strong>&lt;emma:annotation id="label1"
      annotator="joe_bloggs"
      time="2011-10-26T21:32:52"
	   type="transcription"
      emma:confidence="0.9"
      reference="false"&gt;
      &lt;emma:literal&gt;flights from austin to denver tomorrow&lt;/emma:literal&gt;
    &lt;/emma:annotation&gt;
    &lt;emma:annotation id="label2"
      annotator="mary_smith"
      time="2011-10-27T12:00:21"
	    type="semantics"
      emma:confidence="1.0"
      reference="true"&gt;
	   &lt;origin&gt;Austin&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:annotation&gt;
    &lt;emma:annotation id="label3"
      annotator="tim_black"
      time="2011-11-10T09:00:21"
	   type="emotion"
      emma:confidence="1.0"
      reference="false"&gt;
      &lt;emotionml xmlns="http://www.w3.org/2009/10/emotionml"&gt;
        &lt;emotion&gt;
           &lt;category set="everyday" name="angry"/&gt;<br>           &lt;modality medium="acoustic" mode="voice"/&gt;
        &lt;/emotion&gt;
      &lt;/emotionml&gt;
    &lt;/emma:annotation&gt;</strong>
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p> In addition to this more powerful mechanism for adding human annotation to a document, 
  EMMA also provides a shorthand <code>emma:annotated-tokens</code> attribute for the common use case of 
adding reference transcriptions to an EMMA document (<a href="#s.4.2.22">Section 4.2.22</a>) .</p>
<p>Note that 'annotation' as used in the <code>emma:annotation</code> element and the <code>emma:annotated-tokens</code> attribute refers only to annotations made in a post process by human labellers to indicate what the correct processing (reference) of an input should have been or to annotate other aspects of the input. This differs from the general sense of annotation as used more broadly in the specification as in the title "Extensible MultiModal Annotation", which refers in general to metadata provided about an input either by an EMMA processor or by a human labeller. The many annotation elements and attributes in EMMA are used to indicate metadata captured regarding an input. The<code> emma:annotation </code>element and <code>emma:annotated-tokens</code> attribute are specifically for the addition of information provided by human labellers.</p>
</span>
<p >Annotations such the  <a href="#emotionml">Emotion ML</a> in the example above can also be stored in separate files and referenced on an <code>emma:annotation</code> element using <code>ref</code>. Like <code>emma:parameters</code>, a partial specification of the annotation can be provided inline and <code>emma:partial-content="true"</code> provides an indication that the full annotation can be accessed at <code>ref</code>.</p>

<pre >&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="int1" emma:start="1087995961542"
      emma:end="1087995963542"
      emma:medium="acoustic" 
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:signal="http://example.com/signals/audio457.wav"
      emma:confidence="0.75"&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"
      emma:tokens="flights from boston to denver tomorrow"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;<strong>
    &lt;emma:annotation id="label3"
      annotator="tim_black"
      time="2011-11-10T09:00:21"
	    type="emotion"
      confidence="1.0"
      reference="false"
      ref="http://example.com/2011/11/10/emotion123.xml"&gt;
    &lt;/emma:annotation&gt;</strong>
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</pre>
<h3 id="s4.1.10">4.1.10 Location: <code>emma:location</code> element </h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:location</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>The <code>emma:location</code> element acts as a container for information about the location of a user input, more precisely, information about the location of a capture device such as a mobile device.</td>
    </tr>
    <tr>
      <th>Children</th>
      <td>none</td>
    </tr>
    <tr>
      <th>Attributes</th>
      <td><ul>
        <li><span><b>Required</b>: </span><code>id</code> of type <code>xsd:ID</code>.</li>
        <li><b>Optional</b>:
          <ul>
            <li><code>emma:latitude</code> of type <code>xsd:float </code>in the range -90 to 90, indicating the latitude of the capture device</li>
            <li><code>emma:longitude</code> of type <code>xsd:float </code>in the range -180 to 180, indicating the longitude of the capture device</li>
            <li><code>emma:accuracy</code> of type <code>xsd:float</code>, indicating the accuracy of the position in meters, it MUST be non-negative</li>
            <li><code>emma:altitude </code>of type <code>xsd:float</code>, indicating the height of the capture device in meters</li>
            <li><code>emma:altitudeAccuracy</code> of type <code>xsd:float</code>, indicating the accuracy of the altitude information. This value MUST be non-negative.</li>
            <li><code>emma:heading</code> of type <code>xsd:float</code>, in  the range 0   ≤ heading &lt; 360, indicating the direction in which the device is moving. The value is empty if the capture device is stationary.</li>
            <li><code>emma:speed</code> of type <code>xsd:float </code>in meters/second, indicating the speed at which the capture device is moving. This value MUST be non-negative. The value is the empty string if the device is stationary.</li>
            <li><code>emma:description</code> of type <code>xsd:string</code>, providing a description of the location of the device at the beginning of capture of the signal</li>
            <li><code>emma:address</code> of type <code>xsd:string</code>, providing the address of the decice at the beginning of capture</li>
          </ul>
        </li>
      </ul></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td>The <code>emma:location</code> element is legal only as a child of
        the EMMA elements <code>emma:emma</code>,<code> emma:interpretation</code>,<code> emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>.</td>
    </tr>
  </tbody>
</table>
<p >Many mobile devices and sensors are equiped with geolocation capabilities and information about where a unimodal or multimodal event occurred can be very useful both for interpretation and logging. Annotating interpretations with location information in EMMA is achieved with the <code>emma:location</code> element. The <code>emma:location</code> element indicates the location of the capture device. In many cases the device location and the user location will be identical, as in the case where the user is carrying a mobile device. In other use cases (e.g. cameras capturing distant motion, far field microphone arrays) the user may be distant from from the device location. Capturing the location of the user or other source of signal is beyond the scope of the <code>emma:location</code> annotation. Note that <code>emma:location</code> is not intended as a general semantic representation for location information, e.g. a gesture made a location on a map or a spoken location, these rather are part of the interpretation and should be contained within <code>emma:interpretation</code> rather than the <code>emma:location</code> annotation element. The location information in <code>emma:location</code> represents a point in space. Since a device or sensor may be moving during the capture of an input, the location may not be same at the beginning and end of an input. For this reason, the <code>emma:location</code> information is defined to be relative to the beginning of the capture.  Note though that the bearing of the sensor can be annotated using the <code>emma:heading</code> and <code>emma:speed</code> attributes on <code>emma:location</code>. The <code>emma:location</code> element represents the location of single capture device. Uses cases where multiple input devices or sensors are involved in the capture of the input can be represented as composite inputs with an <code>emma:location</code> element annotation on each of the interpretations that are composed. Multimodal Interaction Working Group invites comments on use cases that may require a finer-grained representation of location metadata.</p>
<p > The <code>emma:location</code> attributes are based on the W3C Geolocation API <a href="#geolocation">[Geolocation]</a> specification, with the addition of attributes for a description of the location and address information. The formats of the attributes from the Geolocation API are as defined in that specification. Specifically, they are: </p>
<p >The geographic coordinate reference system used by the attributes is the World Geodetic System (2d) <a href="#ref-wgs">[WGS84]</a>. No   other reference system is supported. </p>
<p >The <code>emma:latitude</code> and <code>emma:longitude</code> attributes are geographic coordinates of the capture device at the beginning of the capture. They MUST be specified in decimal degrees. </p>
<p >The <code>emma:altitude</code> attribute denotes the height of the position at the beginning of the capture. It MUST be specified in meters above the <a href="#ref-wgs">[WGS84]</a> ellipsoid, or as provided by the device's geolocation implementation. If the implementation cannot provide altitude information, the value of this attribute MUST be the empty string.</p>
<p >The <code>emma:accuracy</code> attribute denotes the accuracy of the latitude and longitude coordinates. It MUST be specified in meters. The value of the <code>emma:accuracy</code> attribute MUST be a non-negative real number. </p>
<p >The <code>emma:altitudeAccuracy</code> attribute is specified in meters. If the implementation cannot provide altitude information, the value of this attribute MUST be the empty string. Otherwise, the value of the <code>emma:altitudeAccuracy</code> attribute MUST be a non-negative real number. </p>
<p >The <code>emma:accuracy</code> and <code>emma:altitudeAccuracy</code> values in a EMMA document SHOULD correspond to a 95% confidence level. </p>
<p >The <code>emma:heading</code> attribute denotes the direction of travel of the capture device at the beginning of the capture, and is specified in degrees, where 0°   ≤ heading &lt; 360°, counting clockwise relative to the true north. If the implementation cannot provide heading information, the value of this attribute MUST be the empty string. If the capture device is stationary (i.e. the value of the speed attribute is 0), then the value of the <code>emma:heading</code> attribute MUST be the empty string. </p>
<p >The <code>emma:speed</code> attribute denotes the magnitude of the horizontal component of the capture device's velocity at the beginning of the capture, and MUST be specified in meters per second. If the implementation cannot provide speed information, the value of this attribute MUST be the empty string. Otherwise, the value of the <code>emma:speed</code> attribute MUST be a non-negative real number. </p>
<p >The <code>emma:description</code> attribute is an arbitrary string describing the location of the capture device at the beginning of the capture. </p>
<p >The <code>emma:address</code> attribute is an arbitrary string describing the address of the capture device at the beginning of the capture. </p>
<p >The internal formats of the <code>emma:description</code> and the <code>emma:address</code> attributes are not defined in this specification. </p>
<p >The following example shows the location information for an input spoken at the W3C MIT office.</p>

<pre class="example">&lt;emma:emma version="1.1"
	xmlns:emma="http://www.w3.org/2003/04/emma"      
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.w3.org/2003/04/emma
	http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
	xmlns="http://www.example.com/example"&gt;
   &lt;emma:location
      latitude="42.361860"
	   longitude="-71.091840"
	   altitude="6.706"
	   accuracy="20.5"
	   altitudeAccuracy="1.6"
	   heading=""
	   speed=""
	   description="W3C MIT office"
	   address="32 Vassar Street, Cambridge, MA 02139 USA"/&gt;
   &lt;/emma:location&gt;
   &lt;emma:interpretation id="nlu1"
      emma:medium="acoustic"
      emma:mode="voice" 
      emma:tokens="flights from boston to denver"&gt;
         &lt;origin&gt;Boston&lt;/origin&gt;
         &lt;destination&gt;Denver&lt;/destination&gt;
   &lt;/emma:interpretation&gt;
 &lt;/emma:emma&gt;</pre>

<h2>4.2 EMMA annotation attributes</h2>

<h3 id="s4.2.1">4.2.1 Tokens of input: <code>emma:tokens</code>, <code>emma:token-type</code>, and <code>emma:token-score</code>
attributes</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:tokens</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> holding a sequence
of input tokens.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, and
application instance data.</td>
</tr>
<tr>
<th>Annotation</th>
<th >emma:token-type</th>
</tr>
<tr>
<th>Definition</th>
<td >An attribute of type <code>xsd:string</code> indicating the type of the tokens that appear within <code>emma:tokens</code>, e.g. 'word', 'syllable', 'character', 'phonemes', 'gestures' of input tokens.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, and
application instance data.</td>
</tr>
<tr>
<th>Annotation</th>
<th >emma:token-score</th>
</tr>
<tr>
<th>Definition</th>
<td >An attribute of type <code>xsd:string</code> holding a sequence
of numerical scores between 0 and 1 for each of the tokens in <code>emma:tokens</code>.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:tokens</code> annotation holds a list of input
  tokens. In the following description, the term <i>tokens</i> is
  used in the computational and syntactic sense of <i>units of
    input</i>, and not in the sense of <i>XML tokens</i>. The value
  held in <code>emma:tokens</code> is the list of the tokens of input
  as produced by the processor which generated the EMMA document;
there is no language associated with this value.</p>
<p>In the case where a grammar is used to constrain input, the
value will correspond to tokens as defined by the grammar. So for
an EMMA document produced by input to a SRGS grammar [<a href="#SRGS">SRGS</a>], the value of <code>emma:tokens</code> will be
the list of words and/or phrases that are defined as tokens in SRGS
(<span>see</span> Section 2.1 <span>of [<a href="#SRGS">SRGS</a>]</span>). Items in the <code>emma:tokens</code>
list are delimited by white space and/or quotation marks for
phrases containing white space. For example:</p>
<pre class="example">emma:tokens="arriving at 'Liverpool Street'"
</pre>
<p>where the three tokens of input are <i>arriving</i>, <i>at</i>
and <i>Liverpool Street</i>.</p>
<p>The <code>emma:tokens</code> annotation MAY be applied not just
to the lexical words and phrases of language but to any level of
input processing. Other examples of tokenization include phonemes,
ink strokes, gestures and any other discrete units of input at any
level.</p>
<p >The <code>emma:token-type</code> annotation MAY be used on an element with an <code>emma:tokens</code> attribute in order to indicate the type of the space separated tokens that appear in <code>emma:tokens</code>. The value of <code>emma:token-type</code> is drawn from the open set: {word, character, phoneme, syllable, morpheme, logogram, gesture ....}. </p>
<p >The <code>emma:token-score</code> annotation MAY be used on an element with an <code>emma:tokens</code> attribute in order to provide individual confidence scores for each of the corresponding tokens in <code>emma:tokens</code>. The <code>emma:token-score</code> attribute MUST contain a space separated list of numerical scores between 0 and 1, where there is one numerical score for each of the tokens in <code>emma:tokens</code>.</p>
<p>Examples:</p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
  &lt;emma:interpretation id=&quot;int1&quot;
      emma:tokens=&quot;From Cambridge to London tomorrow&quot;
      emma:token-type=&quot;word&quot;
      emma:token-score=&quot;0.9 0.7 0.7 0.9 0.8&quot;
      <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>&gt;
    &lt;origin emma:tokens=&quot;From Cambridge&quot;&gt;Cambridge&lt;/origin&gt;
    &lt;destination emma:tokens=&quot;to London&quot;&gt;London&lt;/destination&gt;
    &lt;date emma:tokens=&quot;tomorrow&quot;&gt;20030315&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</pre>
<h3>4.2.2 Reference to processing:
  <code>emma:process</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:process</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> referencing the
process used to generate the interpretation.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>, <code>emma:output</code> </td>
</tr>
</tbody>
</table>
<p>A reference to the information concerning the processing that
was used for generating an interpretation or output MAY be made using the
<code>emma:process</code> attribute. For example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:interpretation id="raw"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
      &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="better"
        emma:process="http://example.com/mysemproc1.xml"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
      &lt;emma:derived-from resource="#raw"/&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="best"
      emma:process="http://example.com/mysemproc2.xml"&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
    &lt;emma:derived-from resource="#better"/&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The process description document, referenced by the
<code>emma:process</code> annotation MAY include information on the
process itself, such as grammar, type of parser, etc. EMMA is not
normative about the format of the process description document.</p>
<p>Note that while the <code>emma:process</code> attribute may refer to a document that describes the process, the URI syntax itself can be used to briefly describe the process within the EMMA document without actually referring to an external document. For example, the results of a natural language understanding component could be annotated as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="nlu1"
    emma:medium="acoustic" 
    emma:mode="voice"
    emma:tokens="flights from boston to denver tomorrow please"
    emma:process="http://nlu/classifier=svm&amp;model=travel&amp;output=xml"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</pre>
<p>In this case the <code>emma:process</code> attribute indicates that the process is natural language understanding (<code>nlu</code>) that the classifier used is a support vector machine (<code>svm</code>), that the specific model is the '<code>travel</code>' model and the required output was '<code>xml</code>'. Note that none of the specific values used within the URI here are standardized. This simply illustrates how a URI can be used to provide a detailed process description.</p>
<p>Similarly,  the <code>emma:process</code> attribute can be used with <code>emma:output</code> to refer to a generation process e.g. (refer to example).</p>
<h3 id="s4.2.3">4.2.3 Lack of input: <code>emma:no-input</code>
attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:no-input</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute holding <code>xsd:boolean</code> value that is true
if there was no input.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code></td>
</tr>
</tbody>
</table>
<p>The case of lack of input MUST be annotated as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1" emma:no-input="true"<br>
   <span>emma:medium="acoustic" emma:mode="voice"</span>/&gt;
&lt;/emma:emma&gt;
</pre>
<p>If the <code>emma:interpretation</code> is annotated with
<code>emma:no-input="true"</code> then the
<code>emma:interpretation</code> MUST be empty.</p>
<h3 id="s4.2.4">4.2.4 Uninterpreted input :
<code>emma:uninterpreted</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:uninterpreted</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute holding <code>xsd:boolean</code> value that is true
if <span>no interpretation was produced in response to the
input</span></td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code></td>
</tr>
</tbody>
</table>
<p>An <code>emma:interpretation</code> element representing input
<span>for which no interpretation was produced</span> MUST be
annotated with <code>emma:uninterpreted="true"</code>. For
example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="interp1" emma:uninterpreted="true"
   <span>emma:medium="acoustic" emma:mode="voice"</span>/&gt;
&lt;/emma:emma&gt;
</pre>
<p>The notation for uninterpreted input MAY refer to any possible
stage of interpretation processing, including raw transcriptions.
For instance, no interpretation would be produced for stages
performing pure signal capture such as audio recordings. Likewise,
if a spoken input was recognized but cannot be parsed by a language
understanding component, it can be tagged as
<code>emma:uninterpreted</code> as in the following example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="understanding"
      emma:process="http://example.com/mynlu.xml"
      emma:uninterpreted="true"
      emma:tokens="From Cambridge to London tomorrow"
      <span>emma:medium="acoustic" emma:mode="voice"</span>/&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:interpretation</code> MUST be empty <span class="add">if</span> the <code>emma:interpretation</code> element is
annotated with <code>emma:uninterpreted="true"</code>.</p>
<h3 id="s4.2.5">4.2.5 Human language of input or output:
<code>emma:lang</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:lang</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:language</code> indicating the
language for the input.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:lang</code> annotation is used to indicate the
human language for the input that it annotates. The values of the
<code>emma:lang</code> attribute are language identifiers as
defined by <span>IETF Best Current Practice 47 [<a href="#BCP47">BCP47</a>]</span>. For example,
<code>emma:lang="fr"</code> denotes French, and
<code>emma:lang="en-US"</code> denotes US English.
<code>emma:lang</code> MAY be applied to any
<code>emma:interpretation</code> element. Its annotative scope
follows the annotative scope of these elements. Unlike the
<code>xml:lang</code> attribute in XML, <code>emma:lang</code> does
not specify the language used by element contents or attribute
values.</p>
<p>The following example shows the use of <code>emma:lang</code>
for annotating an input interpretation.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1" emma:lang="fr"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;answer&gt;arretez&lt;/answer&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Many kinds of input including some inputs made through pen,
computer vision, and other kinds of sensors are inherently
non-linguistic. Examples include drawing areas, arrows etc. using a
pen and music input for tune recognition. If these non-linguistic
inputs are annotated with <code>emma:lang</code> then they MUST be
annotated as <code>emma:lang="zxx"</code>. For example, pen input
where a user circles an area on map display could be represented as
follows where <code>emma:lang="zxx"</code> indicates that the ink
input is not in any human language.</p>
<pre class="example"><span>&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="pen1"
      emma:medium="tactile"
      emma:mode="ink"
      emma:lang="zxx"&gt;
    &lt;location&gt;
      &lt;type&gt;area&lt;/type&gt;
      &lt;points&gt;42.1345 -37.128 42.1346 -37.120 ... &lt;/points&gt;
    &lt;/location&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</span>
</pre>
<p>If inputs for which there is no information about whether the
source input is in a particular human language, and if so which
language, are annotated with <code>emma:lang,</code> then they MUST
be annotated as <code>emma:lang=""</code>. Furthermore, in cases
where there is not explicit <code>emma:lang</code> annotation, and
none is inherited from a higher element in the document, the
default value for <code>emma:lang</code> is <code>""</code> meaning
that there is no information about whether the source input is in a
language and if so which language.</p>
<p>The <code>xml:lang</code> and <code>emma:lang</code> attributes
  serve uniquely different and equally important purposes. The role
  of the <code>xml:lang</code> attribute in XML 1.0 is to indicate
  the language used for character data content in an XML element or
  document. In contrast, the <code>emma:lang</code> attribute is used
  to indicate the language employed by a user when entering an input.
  Critically, <code>emma:lang</code> annotates the language of the
  signal originating from the user rather than the specific tokens
  used at a particular stage of processing. This is most clearly
  illustrated through consideration of an example involving multiple
  stages of processing of a user input. Consider the following
  scenario: EMMA is being used to represent three stages in the
  processing of a spoken input to an system for ordering products.
  The user input is in Italian, after speech recognition, the user
  input is first translated into English, then a natural language
  understanding system converts the English translation into a
  product ID (which is not in any particular language). Since the
  input signal is a user speaking Italian, the <code>emma:lang</code>
  will be <code>emma:lang="it"</code> on all of these three stages of
  processing. The <code>xml:lang</code> attribute, in contrast, will
  initially be <code>"it"</code>, after translation the
  <code>xml:lang</code> will be <code>"en-US"</code>, and after
  language understanding it will be <code>"zxx"</code> since the
  product ID is non-linguistic content. The following are examples of
  EMMA documents corresponding to these three processing stages,
  abbreviated to show the critical attributes for discussion here.
  Note that <code>&lt;transcription&gt;</code>,
  <code>&lt;translation&gt;</code>, and
  <code>&lt;understanding&gt;</code> are application namespace
attributes, not part of the EMMA markup.</p>
<pre class="example"><span>&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
   &lt;emma:interpretation emma:lang="it" emma:mode="voice" emma:medium="acoustic"&gt;
     &lt;transcription xml:lang="it"&gt;condizionatore&lt;/transcription&gt;
   &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</span>
</pre>
<pre class="example"><span>&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
    &lt;emma:interpretation emma:lang="it" emma:mode="voice" emma:medium="acoustic"&gt; 
       &lt;translation xml:lang="en-US"&gt;air conditioner&lt;/translation&gt;
    &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</span>
</pre>
<pre class="example"><span>&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
    &lt;emma:interpretation emma:lang="it" emma:mode="voice" emma:medium="acoustic"&gt; 
       &lt;understanding xml:lang="zxx"&gt;id1456&lt;/understanding&gt;
    &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</span>
</pre>
<p>In order <span>to</span> handle inputs involving multiple
languages, such as through code switching, the
<code>emma:lang</code> tag MAY contain several language identifiers
separated by spaces.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1"
      emma:tokens="please stop arretez s'il vous plait"
      emma:lang="en fr"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;command&gt; CANCEL &lt;/command&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>A future Working Draft will include a discussion and examples of <code>emma:lang</code> as it applies to system output.
<h3 id="s4.2.6">4.2.6 Reference to signal: <code>emma:signal</code>
<span>and <code>emma:signal-size</code></span> attributes</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:signal</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> referencing the
input signal.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>,
<span>and</span> application instance data.</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:signal-size</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute <span>of type <code>xsd:nonNegativeInteger</code>
specifying</span> the size in eight bit octets of the referenced
source.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>,
<span>and</span> application instance data.</td>
</tr>
</tbody>
</table>
<p>A URI reference to the signal that originated the input
recognition process MAY be represented in EMMA using the
<code>emma:signal</code> annotation. <span>For example, in the case of speech recognition, the <code>emma:signal</code> attribute is the annotation used to reference the audio that was recognized. The MIME type of the audio can be indicated using <a href="#s4.2.7"><code>emma:media-type</code></a>.</span></p>
<p>Here is an example where the reference to a speech signal is
represented using the <code>emma:signal</code> annotation on the
<code>emma:interpretation</code> element:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="intp1"
      emma:signal="http://example.com/signals/sg23.bin"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:signal-size</code> annotation can be used to
declare the exact size of the associated signal in 8-bit octets. An
example of the use of an EMMA document to represent a recording,
with <code>emma:signal-size</code> indicating the size is as
follows:</p>
<pre class="example"><span>
&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="intp1"
      emma:medium="acoustic"
      emma:mode="voice"
      emma:function="recording"
      emma:uninterpreted="true"
      emma:signal="http://example.com/signals/recording.mpg"
      emma:signal-size="82102" 
      emma:duration="10000"&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</span>
</pre>
<p> A later Working Draft will discuss the use of <code>emma:signal</code> for output, for example for the audio generated by a TTS system.
<h3>4.2.7 Media type: <code>emma:media-type</code>
  attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:media-type</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> holding the MIME
type associated with the signal's data format.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>,
<code>emma:endpoint</code>, <span>and</span> application instance
data.</td>
</tr>
</tbody>
</table>
<p>The data format of the signal that originated the input MAY be
represented in EMMA using the <code>emma:media-type</code>
annotation. An initial set of MIME media types is defined by
[<a href="#RFC2046">RFC2046</a>].</p>
<p>Here is an example where the media type for the ETSI ES 202 212
audio codec for Distributed Speech Recognition (DSR) is applied to
the <code>emma:interpretation</code> element. The example also
specifies an optional sampling rate of 8 kHz and maxptime of 40
milliseconds.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="intp1"<span>
        emma:signal="http://example.com/signals/signal.dsr"</span>
        emma:media-type="audio/dsr-<span>es</span>202212; rate:8000; maxptime:40"
        <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</pre>
<p>For output, this could be the planned MIME, for example, what a TTS should generate. A later draft will clarify the semantics of <code>emma:mime-type</code> for output in more detail.</p>
<h3>4.2.8 Confidence scores:
  <code>emma:confidence</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:confidence</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:decimal</code> in range 0.0 to
1.0, indicating the processor's confidence in the result.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code>, <code>emma:sequence</code>,<code> emma:annotation</code>, and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The confidence score in EMMA is used to indicate the processor or annotator's confidence in the assignment of the interpretation to the input, and if confidence is annotated on an input it MUST be
given as the value of <code>emma:confidence</code>. The confidence
score MUST be a number in the range from 0.0 to 1.0 inclusive. A
value of 0.0 indicates minimum confidence, and a value of 1.0
indicates maximum confidence. Note that
<code>emma:confidence</code> represents not only the confidence of
the speech recognizer, but more generally the confidence of the whatever
processor was responsible for creating the EMMA result, based on
whatever evidence it has. For a natural language interpretation,
for example, this might include semantic heuristics in addition to
speech recognition scores. Moreover, the confidence score values do
not have to be interpreted as probabilities. In fact confidence
score values are platform-dependent, since their computation is
likely to differ between platforms and different EMMA processors.
Confidence scores are annotated explicitly in EMMA in order to
provide this information to the subsequent processes for multimodal
interaction. The example below illustrates how confidence scores
are annotated in EMMA.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="nbest1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="meaning1" emma:confidence="0.6"&gt;
      &lt;location&gt;Boston&lt;/location&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="meaning2" emma:confidence="0.4"&gt;
      &lt;location&gt; Austin &lt;/location&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>In addition to its use as an attribute on the EMMA
interpretation and container elements, the
<code>emma:confidence</code> attribute MAY also be used to assign
confidences to elements in instance data in the application
namespace. This can be seen in the following example, where the
<code>&lt;destination&gt;</code> and <code>&lt;origin&gt;</code>
elements have confidences.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="meaning1" emma:confidence="0.6"
     <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
     &lt;destination emma:confidence="0.8"&gt; Boston&lt;/destination&gt;
     &lt;origin emma:confidence="0.6"&gt; Austin &lt;/origin&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Although in general instance data can be represented in XML
using a combination of elements and attributes in the application
namespace, EMMA does not provide a standard way to annotate
processors' confidences in attributes. Consequently, instance data
that is expected to be assigned confidences SHOULD be represented
using elements, as in the above example.</p>
<p>Similarly, emma:confidence can apply to system output; for example, if the system has several alternative outputs, as illustrated in the earlier <a href="#fullOutputExample">full output example</a>.</p>
<h3 id="s4.2.9">4.2.9 Input source: <code>emma:source</code>
attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:source</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> referencing the
source of input.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:one-of</code>,
<code>emma:group</code> , <code>emma:sequence</code>, and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The source of an interpreted input MAY be represented in EMMA as
a URI resource using the <code>emma:source</code> annotation. Here is an example that shows different input sources for
different input interpretations.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    xmlns:myapp="http://www.example.com/myapp"&gt;
  &lt;emma:one-of id="nbest1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="intp1"
        emma:source="http://example.com/microphone/NC-61"&gt;
      &lt;myapp:destination&gt;Boston&lt;/myapp:destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="intp2"
        emma:source="http://example.com/microphone/NC-4024"&gt;
      &lt;myapp:destination&gt;Austin&lt;/myapp:destination&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
A later Working Draft will discuss the applicability of <code>emma:source</code> for output.
<h3 id="s4.2.10">4.2.10 Timestamps</h3>
<p>The start and end times for input or output MAY be indicated using either
absolute timestamps or relative timestamps. Both are in
milliseconds for ease in processing timestamps. Note that the
ECMAScript Date object's <code>getTime()</code> function is a
convenient way to determine the absolute time.</p>
<p >With regard to output timestamps, the actual time of an output may differ from from the planned time. The attributes in this section refer to the actual time of the output as opposed to the planned time, and are the same as the timestamps for inputs. The start and end times for output MAY be indicated using either absolute 
timestamps or relative timestamps.</p>
<p> Actual output times only make sense for an output has already taken place; consequently EMMA implementations SHOULD NOT include actual timestamps for output times in the future. Actual output timestamps that are in the future MUST be ignored by consumers of an EMMA document with such timestamps (although they MAY be passed on to downstream EMMA consumers. Once the time denoted by the actual timestamp has passed, the relevant attributes (<code>&quot;emma:start&quot;, &quot;emma:end&quot;, &quot;emma:duration&quot;)</code> MUST (if present) either be deleted or the actual time of the output must replace their value. </p>
<h4 id="s4.2.10.1">4.2.10.1 Absolute timestamps:
<code>emma:start</code>, <code>emma:end</code> attributes</h4>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:start, emma:end</th>
</tr>
<tr>
<th>Definition</th>
<td>Attributes <span>of type
<code>xsd:nonNegativeInteger</code></span> indicating the absolute
starting and ending times of an input or output in terms of the number of
milliseconds since 1 January 1970 00:00:00 GMT</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:arc</code>, <span><code>emma:output</code> and</span> application instance
data</td>
</tr>
</tbody>
</table>
<p>Here is an example of a timestamp for an absolute time of an input.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1"
       emma:start="1087995961542"
       emma:end="1087995963542"
       <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Here is an example of a timestamp for an absolute time of output.</p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
  &lt;emma:output id=&quot;out1&quot;
       emma:start=&quot;1087995961542&quot;
       emma:end=&quot;1087995963542&quot;
       <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
  &lt;/emma:output&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:start</code> and <code>emma:end</code>
  annotations on an input or output MAY be identical, however the <code>emma:end</code> value MUST NOT be less than the
  <code>emma:start</code> value.</p>
<h4 id="s4.2.10.2">4.2.10.2 Relative timestamps:
<code>emma:time-ref-uri</code>,
<code>emma:time-ref-anchor-point</code>,
<code>emma:offset-to-start</code> attributes</h4>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:time-ref-uri</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute of type <code>xsd:anyURI</code> indicating the URI
used to anchor the relative timestamp.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:lattice</code>, <code>emma:output</code> <span>and</span> application instance
data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:time-ref-anchor-point</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute with a value of <code>start</code> or
<code>end</code>, defaulting to <code>start</code>. It indicates
whether to measure the time from the start or end of the interval
designated with <code>emma:time-ref-uri</code>.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:lattice</code>, <span><code>emma:output</code> and</span> application instance
data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:offset-to-start</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute <span>of type <code>xsd:integer</code></span>,
defaulting to zero. It specifies the offset in milliseconds for the
start of input from the anchor point designated with
<span><code>emma:time-ref-uri</code></span> and
<span><code>emma:time-ref-anchor-point</code></span></td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:arc</code>, <code>emma:output</code> <span>and</span> application instance
data</td>
</tr>
</tbody>
</table>
<p>Relative timestamps define the start of an input relative to the
start or end of a reference interval such as another input.</p>
<p><img src="relativetimestamps.png" width="535" height="265" alt="relative timestamps" /></p>
<p>The reference interval is designated with
<code>emma:time-ref-uri</code> attribute. This MAY be combined with
<code>emma:time-ref-anchor-point</code> attribute to specify
whether the anchor point is the start or end of this interval. The
start of an input relative to this anchor point is then specified
with <code>emma:offset-to-start</code> attribute.</p>
<p>Here is an example where the referenced input is in the same
document:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:sequence&gt;
    &lt;emma:interpretation id="int1"
     <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Denver&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2"
        <span>emma:medium="acoustic" emma:mode="voice"</span>
        emma:time-ref-uri="#int1"
        emma:time-ref-anchor-point="start"
        emma:offset-to-start="5000"&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:sequence&gt;
&lt;/emma:emma&gt;
</pre>
<p>Note that the reference point refers to an input, but not
necessarily to a complete input. For example, if a speech
recognizer timestamps each word in an utterance, the anchor point
might refer to the timestamp for just one word.</p>
<p>The absolute and relative timestamps are not mutually exclusive;
that is, it is possible to have both relative and absolute
timestamp attributes on the same EMMA container element.</p>
<p>Timestamps of inputs collected by different devices and outputs presented by different devices will be
subject to variation if the times maintained by the devices are not
synchronized. This concern is outside of the scope of the EMMA
specification.</p>
<h4 id="s4.2.10.3">4.2.10.3 Duration of input and output: <code>emma:duration</code> attribute</h4>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:duration</th>
</tr>
<tr>
<th>Definition</th>
<td>Attribute <span>of type
<code>xsd:nonNegativeInteger</code></span>, defaulting to zero. It
specifies the duration of the input in milliseconds.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:arc</code>, <span><code>emma:output </code>and</span> application instance
data</td>
</tr>
</tbody>
</table>
<p>The duration of an input or output in milliseconds MAY be specified with
the <code>emma:duration</code> attribute. The
<code>emma:duration</code> attribute MAY be used either in
combination with timestamps or independently, for example in the
annotation of speech corpora.</p>
<p>In the following example, the duration of the signal that gave
rise to the interpretation is indicated using
<code>emma:duration</code>.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
    &lt;emma:interpretation id="int1" emma:duration="2300"
        <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;origin&gt;Denver&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<h4 id="s4.2.10.4">4.2.10.4 Composite Input and Output and Relative
Timestamps</h4>
<p>This section is informative.</p>
<p>The following table provides guidance on how to determine the
values of relative timestamps on a composite input and output.</p>
<div>
<table summary="3 columns" border="1" cellpadding="3" cellspacing="0">
<caption>Informative Guidance on Relative Timestamps in Composite
Derivations</caption>
<tbody>
<tr>
<td><code>emma:time-ref-uri</code></td>
<td>If the reference interval URI is the same for both inputs or outputs then
it should be the same for the composite input. If it is not the
same then relative timestamps will have to be resolved to absolute
timestamps in order to determine the combined timestamp. .</td>
</tr>
<tr>
<td><code>emma:time-ref-anchor-point</code></td>
<td>If the anchor value is the same for both inputs or outputs then it should
be the same for the composite input or output. If it is not the same then
relative timestamps will have to be resolved to absolute timestamps
in order to determine the combined timestamp.</td>
</tr>
<tr>
<td><code>emma:offset-to-start</code></td>
<td>Given that the <code>emma:time-ref-uri</code> and
<code>emma:time-ref-anchor-point</code> are the same for both
combining inputs or outputs, then the <code>emma:offset-to-start</code> for
the combination should be the lesser of the two. If they are not
the same then relative timestamps will have to be resolved to
absolute timestamps in order to determine the combined
timestamp.</td>
</tr>
<tr>
<td><code>emma:duration</code></td>
<td>Given that the <code>emma:time-ref-uri</code> and
<code>emma:time-ref-anchor-point</code> are the same for both
combining inputs or outputs, then the <code>emma:duration</code> is calculated
as follows. Add together the <code>emma:offset-to-start</code> and
<code>emma:duration</code> for each of the inputs or outputs. Take whichever
of these is greater and subtract from it the lesser of the <code>emma:offset-to-start</code> values in order to determine the
combined duration. If <code>emma:time-ref-uri</code> and
<code>emma:time-ref-anchor-point</code> are not the same then
relative timestamps will have to be resolved to absolute timestamps
in order to determine the combined timestamp.</td>
</tr>
</tbody>
</table>
</div>
<h3  id="s4.2.11">4.2.10.5 Planned Output Timestamps</h3>
<p >There are two types of start and end times for output. One is an intended time for the system to present output to the user and the other is the actual time that the output was presented. It is necessary to differentiate these because some external event may interfere with a planned output, cause it to be postponed, or cause it to be presented earlier than planned. For example, an incoming phone call may cause the system to pause an ongoing dialog with the user, thus delaying the time of the planned system output for that dialog. Both types of output time (planned and actual) MAY be indicated using either absolute 
  timestamps or relative timestamps. Actual output times are designated with the same attributes that are used for timestamping inputs.  When planned output timestamps are omitted, the EMMA consumer MUST produce its output as soon as possible. </p>
<p >Both planned and actual times are in milliseconds for ease in 
  processing timestamps. Note that the ECMAScript Date object's <code>getTime()</code> function is a convenient way to determine the absolute 
  time.</p>
<h5  id="s4.2.10.6">4.2.10.5.1 Absolute timestamps for planned output: <code>emma:start-plan</code>, <code>emma:end-plan</code> attributes</h5>
<table width="98%" class="defn" cellspacing="0" cellpadding="5" summary="property definition">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:start-plan, emma:end-plan</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>Attributes <span>of type <code>xsd:nonNegativeInteger</code></span> indicating the planned absolute starting and ending times of an output in terms of 
        the number of milliseconds since 1 January 1970 00:00:00 GMT</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:output</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:arc</code>, <span>and</span> application instance
        data</td>
    </tr>
  </tbody>
</table>
<p >Here is an example of a timestamp for an absolute planned time.</p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
  &lt;emma:output id=&quot;out1&quot;
       emma:start-plan=&quot;1087995961542&quot;
       emma:end-plan=&quot;1087995963542&quot;
       <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
  &lt;/emma:output&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:start-plan</code> and <code>emma:end</code>-plan annotations on an output 
  MAY be identical, however the <code>emma:end-plan</code> value MUST NOT be less than 
  the <code>emma:start-plan</code> value. Absolute planned times in the past are allowed. In an output document  prepared by the system for an interactive dialog and sent to the user, if the emma:start-plan or emma:end-plan attribute is in the past, it MUST be ignored. In logging and archiving, emma:start-plan or emma:end-plan attributes in the past simply serve as records of when the output was planned to occur.</p>
<h4 id="s4.2.10.7">4.2.10.2 Relative timestamps: <code>emma:time-ref-uri</code>, <code>emma:time-ref-anchor-point</code>, <code>emma:offset-to-start-plan</code> attributes</h4>
<table width="98%" class="defn" cellspacing="0" cellpadding="5" summary="property definition">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:time-ref-uri</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>Attribute of type <code>xsd:anyURI</code> indicating the URI used to 
        anchor the relative timestamp.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:output</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:lattice</code>, <span>and</span> application instance
        data</td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:time-ref-anchor-point</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>Attribute with a value of <code>start</code> or <code>end</code>, 
        defaulting to <code>start</code>. It indicates whether to measure the time 
        from the start or end of the interval designated with <code>emma:time-ref-uri</code>.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:output</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:lattice</code>, <span>and</span> application instance
        data</td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:offset-to-start-plan</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>Attribute <span>of type <code>xsd:integer</code></span>, defaulting to 
        zero. It specifies the offset in milliseconds for the start of output from 
        the anchor point designated with <span><code>emma:time-ref-uri</code></span> and <span><code>emma:time-ref-anchor-point</code></span></td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:output</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:arc</code>, <span>and</span> application instance
        data</td>
    </tr>
  </tbody>
</table>
<p >Relative timestamps define the start of an output relative to the start or end 
  of a reference interval such as another output. The figure shows how planned output times can vary from the actual output times, relative to a reference interval.</p>
<p ><img src="timing.png" width="658" height="322" alt="planned TimeStamps" /></p>
<p >The reference interval is designated with <code>emma:time-ref-uri</code> attribute. This MAY be combined with <code>emma:time-ref-anchor-point</code>attribute to specify whether the anchor point is the start or end of this 
  interval. The start of an output relative to this anchor point is then specified
  with <code>emma:offset-to-start-plan</code> attribute. The examples in the graphic all show the actual output occuring after the planned output. This is expected to be the most frequent case, but in general there may be application-specific situations where the actual output is earlier than the planned output. </p>
<p >Here is an example where the referenced output is in the same document:</p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
  &lt;emma:sequence&gt;
    &lt;emma:output id=&quot;out1&quot;
     <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>&gt;
    &lt;origin&gt;Denver&lt;/origin&gt;
    &lt;/emma:output&gt;
    &lt;emma:output id=&quot;out2&quot;
        <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>
        emma:time-ref-uri=&quot;#int1&quot;
        emma:time-ref-anchor-point=&quot;start&quot;
        emma:offset-to-start-plan=&quot;5000&quot;&gt;
    &lt;destination&gt;Chicago&lt;/destination&gt;
    &lt;/emma:output&gt;
  &lt;/emma:sequence&gt;
&lt;/emma:emma&gt;
</pre>
<p>Note that the reference point refers to an output, but not necessarily to a 
  complete output. For example, if a speech synthesizer timestamps each word in an 
  utterance, the anchor point might refer to the timestamp for just one word.</p>
<p>The absolute and relative timestamps are not mutually exclusive; that is, it 
  is possible to have both relative and absolute timestamp attributes on the same 
  EMMA container element.</p>
<p>Timestamps of outputs presented by different devices will be subject to 
  variation if the times maintained by the devices are not synchronized. This 
  concern is outside of the scope of the EMMA specification.</p>
<h4 id="s4.2.10.8">4.2.10.3 Duration of output: <code>emma:duration-plan</code> attribute</h4>
<table width="98%" class="defn" cellspacing="0" cellpadding="5" summary="property definition">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:duration-plan</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>Attribute <span>of type <code>xsd:nonNegativeInteger</code></span>, 
        defaulting to zero. It specifies the planned duration of the output in 
        milliseconds.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:output</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:arc</code>, <span>and</span> application instance
        data</td>
    </tr>
  </tbody>
</table>
<p>The planned duration of an output in milliseconds MAY be specified with the <code>emma:duration-plan</code> attribute. The <code>emma:duration-plan</code> attribute 
  MAY be used either in combination with timestamps or independently, for example 
  in the annotation of speech corpora. </p>
<p>In the following example, the planned duration of the signal produced as the 
  output is indicated using <code>emma:duration-plan</code>.</p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;
    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
    xmlns=&quot;http://www.example.com/example&quot;&gt;
    &lt;emma:output id=&quot;out1&quot; emma:duration-plan=&quot;2300&quot;
        <span>emma:medium=&quot;acoustic&quot; emma:mode=&quot;voice&quot;</span>&gt;
    &lt;origin&gt;Denver&lt;/origin&gt;
    &lt;/emma:output&gt;
&lt;/emma:emma&gt;
</pre>
<p>&nbsp;</p>
<h3>4.2.11 Medium, mode, and function of user inputs and outputs: <code>emma:medium</code>, <code>emma:mode</code>,
  <code>emma:function</code>, <code>emma:verbal</code>
  attributes</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:medium</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <span><code>xsd:nmtokens</code></span>
<span>which contains a space delimited set of values from the
set</span> {<code>acoustic</code>, <code>tactile</code>,
<code>visual</code>}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:endpoint</code>, and application instance data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:mode</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <span><code>xsd:nmtokens</code></span>
<span>which contains a space delimited set of values from</span> an
open set of values including: {<span><code>voice</code>,
<code>dtmf</code></span>, <code>ink</code>, <code>gui</code>,
<code>keys</code>, <code>video</code>, <code>photograph</code>,
...}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:endpoint</code>, <code>emma:output,</code> and application instance data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:function</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> constrained to
values in the open set {<code>recording</code>,
<code>transcription</code>, <code>dialog</code>,
<code>verification</code>, ...}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,  <code>emma:output, </code>and
application instance data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:verbal</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:boolean</code>.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,  <code>emma:output</code>, and
application instance data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:device-type</th>
</tr>
<tr>
<th>Definition</th>
<td>The type of device, or list of types of
device through which the input is captured. An attribute of type <code>xsd:nmtokens</code> which
        contains a space delimited set of values from an open set of values
      including: {<code>microphone</code>, <code>touchscreen</code>, <code>mouse</code>, <code>keypad</code>, <code>keyboard</code>, <code>pen</code>, <code>joystick</code>, <code>touchpad</code>, <code>scanner</code>, <code>camera_2d</code>, <code>camera_3d</code>, <code>thumbwheel</code>...}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
    <code>emma:one-of</code>, <code>emma:sequence</code>,  <code>emma:output</code>, and
application instance data</td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:expressed-through</th>
</tr>
<tr>
<th>Definition</th>
<td>The modality, or list of modalities, through which the interpretation or output is
        expressed. An attribute of type <code>xsd:nmtokens</code> which
        contains a space delimited set of values from an open set of values
      including: {<code>gaze</code>, <code>face</code>, <code>head</code>, <code>torso</code>, <code>hands</code>, <code>leg</code>, <code>locomotion</code>, <code>posture</code>, <code>physiology</code>, ...}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
    <code>emma:one-of</code>, <code>emma:sequence</code>,  <code>emma:output</code>, and
application instance data</td>
</tr>
</tbody>
</table>
<p>EMMA provides two properties for the annotation of input
  or output modality. One indicating the broader medium or channel
(<code>emma:medium</code>) and another indicating the specific mode
of communication used on that channel (<code>emma:mode</code>). The
input or output medium is defined from the user's perspective and indicates
whether they use their voice (<code>acoustic</code>), touch
(<code>tactile</code>), or visual appearance/motion
(<code>visual</code>) as input or whether the system uses  its voice (<code>acoustic</code>), touch
(<code>tactile</code>), or visual appearance/motion
(<code>visual</code>) for output . Tactile includes most <i>hand-on</i> input device types such as pen, mouse, keyboard, and
touch screen or vibration for output. Visual is used for camera input. Visual is also used for output to a display..</p>
<pre class="example">emma:medium = <span>space delimited sequence of values from the set: </span>
            [acoustic|tactile|visual]</pre>
<p>The mode property provides the ability to distinguish between
different modes of communication that may be within a particular
medium. For example, in the tactile medium, modes include
electronic ink (<code>ink</code>), and pointing and clicking on a
graphical user interface (<code>gui</code>).</p>
<pre class="example">emma:mode = <span>space delimited sequence of values from the set: </span> 
            [<span>voice|dtmf</span>|ink|gui|keys|video|photograph| ... ]
</pre>
<p>The <code>emma:medium</code> classification is based on the
boundary between the user and the device that they use. For
<code>emma:medium="tactile"</code> the user physically touches the
device in order to provide input. For
<code>emma:medium="visual"</code> the user's movement is captured
by sensors (cameras, infrared) resulting in an input to the system.
In the case where <code>emma:medium="acoustic"</code> the user
provides input to the system by producing an acoustic signal or the system provides an acoustic signal as output. Note
then that DTMF input will be classified as <code>emma:medium="tactile"</code> since in order to provide DTMF
input the user physically presses keys on a keypad.</p>
<p>In order to clarify the difference between <code>emma:medium</code> and <code>emma:mode</code> consider the following examples of different ways to capture drawn input. If the user input consists of drawing it will be classified as <code>emma:mode="ink"</code>. If the user physically draws on a touch sensitive screen then the input is classifed as  <code>emma:medium ="tactile"</code> since the user interacts with the system by direct contact. If instead the user draws on a tabletop and their input is captured by a camera mounted above (or below) the surface then the input is <code>emma:medium ="visual"</code>. Similarly, drawing on a large screen display using hand gestures made in space and sensed with a camera will be classified as <code>emma:mode="ink"</code> and <code>emma:medium ="visual"</code>.</p>
<p>While <code>emma:medium</code> and <code>emma:mode</code> are
  optional on specific elements such as
  <code>emma:interpretation</code> and <code>emma:one-of</code>, note
  that all EMMA interpretations must be annotated for
  <code>emma:medium</code> and <code>emma:mode</code>, so either
  these attributes must appear directly on
  <code>emma:interpretation</code> or they must appear on an ancestor
  <code>emma:one-of</code> node or they must appear on an earlier
  stage of the derivation listed in <code>emma:derivation</code>.</p>
<p>The <code>emma:device-type</code> annotation can be used to indicate the specific type of device used to capture the input. This allow for differentiation of, multiple different <code>tactile</code> inputs within the <code>ink</code> mode, such as touchscreen input, pen, and mouse. </p>
<pre class="example">emma:device-type = space delimited sequence of values from the set:
					 [microphone|keypad|keyboard|touchscreen|touchpad|
                    mouse|pen|joystick|thumbwheel|
                    camera_2d|camera_3d|scanner... ]</pre>
<p>The <code>emma:device-type</code> attribute SHOULD be used to indicate the general category of the sensor used to captured the input. The specific model number or characteristics SHOULD be captured instead using <code>emma:process</code> (<a href="#4.2.2">Section 4.2.2</a>).</p>
<p>Orthogonal to the mode, user inputs can also be classified with
  respect to their communicative function. This enables a simpler
  mode classification.</p>
<pre class="example">emma:function = [recording|transcription|dialog|verification| ... ]
</pre>
<p>For example, speech can be used for recording (e.g. voicemail),
transcription (e.g. dictation), dialog (e.g. interactive spoken
dialog systems), and verification (e.g. identifying users through
their voiceprints).</p>
<p>EMMA also supports an additional property
<code>emma:verbal</code> which distinguishes verbal use of an input
mode from non-verbal. This MAY be used to distinguish the use of
electronic ink to convey handwritten commands from the user of
electronic ink for symbolic gestures such as circles and arrows.
Handwritten commands, such as writing <i>downtown</i> in order to
change a map display to show the downtown are classified as verbal
(<code>emma:function="dialog" emma:verbal="true"</code>). Pen
gestures (arrows, lines, circles, etc), such as circling a
building, are classified as non-verbal dialog
(<code>emma:function="dialog" emma:verbal="false"</code>). The use
of handwritten words to transcribe an email message is classified
as transcription (<code>emma:function="transcription"
emma:verbal="true"</code>).</p>
<pre class="example">emma:verbal = [true|false]
</pre>
<p>Handwritten words and ink gestures are typically recognized
using different kinds of recognition components (handwriting
recognizer vs. gesture recognizer) and the verbal annotation will
be added by the recognition component which classifies the input.
The original input source, a pen in this case, will not be aware of
this difference. The input source identifier will tell you that the
input was from a pen of some kind but will not tell you if the mode
of input was handwriting (<i>show downtown</i>) or gesture (e.g.
circling an object or area).</p>
<p>Here is an example of the EMMA annotation for a pen input where
the user's ink is recognized as either a word ("Boston") or as an
arrow:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of id="nbest1"&gt;
    &lt;emma:interpretation id="interp1"
     emma:confidence="0.6"
     emma:medium="tactile"
     emma:mode="ink"
     <span>emma:device-type="pen"</span>
     emma:function="dialog"
     emma:verbal="true"&gt;
       &lt;location&gt;Boston&lt;/location&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp2"
     emma:confidence="0.4"
     emma:medium="tactile"
     emma:mode="ink"
     <span>emma:device-type="pen"</span>
     emma:function="dialog"
     emma:verbal="false"&gt;
       &lt;direction&gt;45&lt;/direction&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>Here is an example of the EMMA annotation for a spoken command
which is recognized as either "Boston" or "Austin":</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of&gt;
    &lt;emma:interpretation id="interp1"
     emma:confidence="0.6"
     emma:medium="acoustic"
     emma:mode="voice"
	   <span>emma:device-type="microphone"</span>
     emma:function="dialog"
     emma:verbal="true"&gt;
       &lt;location&gt;Boston&lt;/location&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="interp2"
     emma:confidence="0.4"
     emma:medium="acoustic"
     emma:mode="voice"
     <span>emma:device-type="microphone"</span>
     emma:function="dialog"
     emma:verbal="true"&gt;
       &lt;location&gt;Austin&lt;/location&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<p>The following table shows the relationship between the medium,
mode, and function properties and serves as an aid for classifying
inputs. For the dialog function it also shows some examples of the
classification of inputs as verbal vs. non-verbal.</p>
<table class="modes" summary="7 columns" border="1" cellpadding="3" cellspacing="0">
<tbody>
<tr>
<th rowspan="2">Medium</th>
<th rowspan="2">Device-type</th>
<th rowspan="2">Mode</th>
<th colspan="4">Function</th>
</tr>
<tr>
<th>recording</th>
<th>dialog</th>
<th>transcription</th>
<th>verification</th>
</tr>
<tr>
<td rowspan="2">acoustic</td>
<td rowspan="2">microphone</td>
<td rowspan="2">voice</td>
<td rowspan="2">audiofile (e.g. voicemail)</td>
<td>spoken command / query / response (verbal = true)</td>
<td rowspan="2">dictation</td>
<td rowspan="2">speaker recognition</td>
</tr>
<tr>
<td>singing a note (verbal = false)</td>
</tr>
<tr>
<td rowspan="18">tactile</td>
<td rowspan="2">keypad</td>
<td rowspan="2">dtmf</td>
<td rowspan="2">audiofile / character stream</td>
<td>typed command / query / response (verbal = true)</td>
<td rowspan="2">text entry (T9-tegic, word completion, or word
grammar)</td>
<td rowspan="2">password / pin entry</td>
</tr>
<tr>
<td>command key "Press 9 for sales" (verbal = false)</td>
</tr>
<tr>
<td rowspan="2">keyboard</td>
<td rowspan="2">dtmf</td>
<td rowspan="2">character / key-code stream</td>
<td>typed command / query / response (verbal = true)</td>
<td rowspan="2">typing</td>
<td rowspan="2">password / pin entry</td>
</tr>
<tr>
<td>command key "Press S for sales" (verbal = false)</td>
</tr>
<tr>
<td rowspan="4">pen</td>
<td rowspan="2">ink</td>
<td rowspan="2">trace, sketch</td>
<td>handwritten command / query / response (verbal = true)</td>
<td rowspan="2">handwritten text entry</td>
<td rowspan="2">signature, handwriting recognition</td>
</tr>
<tr>
<td>gesture (e.g. circling building) (verbal = false)</td>
</tr>
<tr>
<td rowspan="2">gui</td>
<td rowspan="2">N/A</td>
<td>tapping on named button (verbal = true)</td>
<td rowspan="2">soft keyboard</td>
<td rowspan="2">password / pin entry</td>
</tr>
<tr>
<td>drag and drop, tapping on map (verbal = false)</td>
</tr>

<tr>
<td rowspan="4">touchscreen</td>
<td rowspan="2">ink</td>
<td rowspan="2">trace, sketch</td>
<td>handwritten command / query / response (verbal = true)</td>
<td rowspan="2">handwritten text entry</td>
<td rowspan="2">signature, handwriting recognition</td>
</tr>
<tr>
<td>gesture (e.g. circling building) (verbal = false)</td>
</tr>
<tr>
<td rowspan="2">gui</td>
<td rowspan="2">N/A</td>
<td>tapping on named button (verbal = true)</td>
<td rowspan="2">soft keyboard</td>
<td rowspan="2">password / pin entry</td>
</tr>
<tr>
<td>drag and drop, tapping on map (verbal = false)</td>
</tr>
<tr>
<td rowspan="4">mouse</td>
<td rowspan="2">ink</td>
<td rowspan="2">trace, sketch</td>
<td>handwritten command / query / response (verbal = true)</td>
<td rowspan="2">handwritten text entry</td>
<td rowspan="2">N/A</td>
</tr>
<tr>
<td>gesture (e.g. circling building) (verbal = false)</td>
</tr>
<tr>
<td rowspan="2">gui</td>
<td rowspan="2">N/A</td>
<td>clicking named button (verbal = true)</td>
<td rowspan="2">soft keyboard</td>
<td rowspan="2">password / pin entry</td>
</tr>
<tr>
<td>drag and drop, clicking on map (verbal = false)</td>
</tr>
<tr>
<td rowspan="2">joystick</td>
<td>ink</td>
<td>trace,sketch</td>
<td>gesture (e.g. circling building) (verbal = false)</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>gui</td>
<td>N/A</td>
<td>pointing, clicking button / menu (verbal = false)</td>
<td>soft keyboard</td>
<td>password / pin entry</td>
</tr>
<tr>
<td rowspan="5">visual</td>
<td rowspan="2"> scanner</td>
<td rowspan="2">photograph</td>
<td rowspan="2">image</td>
<td>handwritten command / query / response (verbal = true)</td>
<td rowspan="2">optical character recognition, object/scene
recognition (markup, e.g. SVG)</td>
<td rowspan="2">N/A</td>
</tr>
<tr>
<td>drawings and images (verbal = false)</td>
</tr>
<tr>
<td>camera_2d</td>
<td>photograph</td>
<td>image</td>
<td>objects (verbal = false)</td>
<td>visual object/scene recognition</td>
<td>face id, retinal scan</td>
</tr>
<tr>
<td rowspan="2">camera_2d</td>
<td rowspan="2">video</td>
<td rowspan="2">movie</td>
<td>sign language (verbal = true)</td>
<td rowspan="2">audio/visual recognition</td>
<td rowspan="2">face id, gait id, retinal scan</td>
</tr>
<tr>
<td>face / hand / arm / body gesture (e.g. pointing, facing)
(verbal = false)</td>
</tr>
</tbody>
</table>
<p>The <code>emma:expressed-through</code> attribute describes the modality through
  which an input is produced, usually by a human being. This differs from the specific mode of communication (<code>emma:mode</code>) and the broader channel or medium (<code>emma:medium</code>). For example in the case where a user provides ink input on a touchscreen using their hands the input would be classified as <code>emma:medium="tactile"</code>, <code> emma:mode="ink"</code>, and <code>emma:expressed-through="hands"</code>. The <code>emma:expressed-through</code> attribute is not specific about the
  sensors used for observing the modality. These can be specified using <code>emma:medium</code> and <code>emma:mode</code> attributes.</p>
<p>This mechanism allows for more fine grained annotation of the specific body part that is analyzed in the assignment of an EMMA result. For example, in an emotion recognition task using computer vision techniques on video camera input, <code>emma:medium="visual"</code> and <code>emma:mode="video"</code>. If the face is being analyzed to determine the result then <code>emma:expressed-through="face"</code> while if the body motion is being analyzed then <code>emma:expressed-through="locomotion"</code>.</p>
<p>The list of values provided covers a broad range of modalities through which
  inputs may be expressed. These values SHOULD be used if they are appropriate.
  The list is an open set in order to allow for more fine-grained distinctions
  such as "eyes" vs. "mouth" etc.</p>
<p>The application of the attributes defined in this section to system output will be discussed in a future Working Draft.</p>
<h3>4.2.12 Composite multimodality:
  <code>emma:hook</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:hook</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> constrained to
values in the open set {<code>voice</code>, <code>dtmf</code>,
<code>ink</code>, <code>gui</code>, <code>keys</code>,
<code>video</code>, <code>photograph</code>, ...} or the wildcard
<code>any</code></td>
</tr>
<tr>
<th>Applies to</th>
<td>Application instance data</td>
</tr>
</tbody>
</table>
<p>The attribute <code>emma:hook</code> MAY be used to mark the
elements in the application semantics within an
<code>emma:interpretation</code> which are expected to be
integrated with content from input in another mode to yield a
complete interpretation. The <code>emma:mode</code> to be
integrated at that point in the application semantics is indicated
as the value of the <code>emma:hook</code> attribute. The possible
values of <code>emma:hook</code> are the list of input modes that
can be values of <code>emma:mode</code> <span>(see <a href="#s4.2.11">Section 4.2.11</a>)</span>. In addition to these, the
value of <code>emma:hook</code> can also be the wildcard
<code>any</code> indicating that the other content can come from
any source. The annotation <code>emma:hook</code> differs in
semantics from <code>emma:mode</code> as follows. Annotating an
element in the application semantics with
<code>emma:mode="ink"</code> indicates that that part of the
semantics came from the <code>ink</code> mode. Annotating an
element in the application semantics with
<code>emma:hook="ink"</code> indicates that part of the semantics
needs to be integrated with content from the <code>ink</code>
mode.</p>
<p>To illustrate the use of <code>emma:hook</code> consider an
example composite input in which the user says "zoom in here" in
the speech input mode while drawing an area on a graphical display
in the ink input mode. <span>The fact that the
<code>location</code> element needs to come from the
<code>ink</code> mode is indicated by annotating this application
namespace element using <code>emma:hook</code></span></p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation <span>emma:medium="acoustic"</span> emma:mode="voice"&gt;
    &lt;command&gt;
      &lt;action&gt;zoom&lt;/action&gt;
      &lt;location emma:hook="ink"&gt;
        &lt;type&gt;area&lt;/type&gt;
      &lt;/location&gt;
    &lt;/command&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>For more detailed explanation of this example see <a href="#appC">Appendix C</a>.</p>
<h3 id="s4.2.13">4.2.13 Cost: <code>emma:cost</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:cost</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:decimal</code> in range 0.0 to
10000000, indicating the processor's cost or weight associated with
an input or part of an input.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>,
<code>emma:arc</code>, <code>emma:node</code>, and application
instance data.</td>
</tr>
</tbody>
</table>
<p>The cost annotation in EMMA indicates the weight or cost
associated with an user's input or part of their input. The most
common use of <code>emma:cost</code> is for representing the costs
encoded on a lattice output from speech recognition or other
recognition or understanding processes. <code>emma:cost</code> MAY
also be used to indicate the total cost associated with particular
recognition results or semantic interpretations.</p>
<p>The semantics of <code>emma:cost</code> as used with respect to system output will be discussed in detail in a future draft.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:one-of <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="meaning1" emma:cost="1600"&gt;
      &lt;location&gt;Boston&lt;/location&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="meaning2" emma:cost="400"&gt;
      &lt;location&gt; Austin &lt;/location&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s4.2.14">4.2.14 Endpoint properties:
<code>emma:endpoint-role</code>,
<code>emma:endpoint-address</code>, <code>emma:port-type</code>,
<code>emma:port-num</code>, <code>emma:message-id</code>,
<code>emma:service-name</code>, <code>emma:endpoint-pair-ref</code>,
<code>emma:endpoint-info-ref</code>
attributes</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:endpoint-role</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> constrained to
values in the set {<code>source</code>, <code>sink</code>,
<code>reply-to</code>, <code>router</code>}.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:endpoint-address</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> that uniquely
specifies the network address of the
<code>emma:endpoint</code>.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:port-type</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:QName</code> that specifies the
type of the port.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:port-num</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:nonNegativeInteger</code> that
specifies the port number.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:message-id</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> that specifies the
message ID associated with the data.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:service-name</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> that specifies the
name of the service.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:endpoint-pair-ref</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:anyURI</code> that specifies the
pairing between sink and source endpoints.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:endpoint</code></td>
</tr>
<tr>
<th>Annotation</th>
<th>emma:endpoint-info-ref</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:IDREF</code> referring to the
<code>id</code> attribute of an <code>emma:endpoint-info</code>
element.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:endpoint-role</code> attribute specifies the role
that the particular <code>emma:endpoint</code> performs in
multimodal interaction. The role value <code>sink</code> indicates
that the particular endpoint is the receiver of the input data. The
role value <code>source</code> indicates that the particular
endpoint is the sender of the input data. The role value
<code>reply-to</code> indicates that the particular
<code>emma:endpoint</code> is the intended endpoint for the reply.
The same <code>emma:endpoint-address</code> MAY appear in multiple
<code>emma:endpoint</code> elements, provided that the same
endpoint address is used to serve multiple roles, e.g. sink,
source, reply-to, router, etc., or associated with multiple
interpretations.</p>
<p>The <code>emma:endpoint-address</code> specifies the network
address of the <code>emma:endpoint</code>, and
<code>emma:port-type</code> specifies the port type of the
<code>emma:endpoint</code>. The <code>emma:port-num</code>
annotates the port number of the endpoint (e.g. the typical port
number for an http endpoint is 80). The
<code>emma:message-id</code> annotates the message ID information
associated with the annotated input. This meta information is used
to establish and maintain the communication context for both
inbound processing and outbound operation. The service
specification of the <code>emma:endpoint</code> is annotated by
<code>emma:service-name</code> which contains the definition of the
service that the <code>emma:endpoint</code> performs. The matching
of the <code>sink</code> endpoint and its pairing
<code>source</code> endpoint is annotated by the
<code>emma:endpoint-pair-ref</code> attribute. One sink endpoint
MAY link to multiple source endpoints through
<code>emma:endpoint-pair-ref</code>. Further bounding of the
<code>emma:endpoint</code> is possible by using the annotation of
<code>emma:group</code> (see <a href="#s3.3.2">Section
3.3.2</a>).</p>
<p>The <code>emma:endpoint-info-ref</code> attribute associates the
EMMA result in the container element with an
<code>emma:endpoint-info</code> element.</p>
<p>The following example illustrates the use of these attributes in
multimodal interactions where multiple modalities are used.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"
    xmlns:ex="http://www.example.com/emma/port"&gt;
  &lt;emma:endpoint-info id="audio-channel-1" &gt;
    &lt;emma:endpoint id="endpoint1"
        emma:endpoint-role="sink"
        emma:endpoint-address="135.61.71.103"
        emma:port-num="50204"
        emma:port-type="rtp"
        emma:endpoint-pair-ref="endpoint2"
        emma:media-type="audio/dsr-202212; rate:8000; maxptime:40"
        emma:service-name="travel"
        emma:mode="voice"&gt;
      &lt;ex:app-protocol&gt;SIP&lt;/ex:app-protocol&gt;
    &lt;/emma:endpoint&gt;
    &lt;emma:endpoint id="endpoint2" emma:endpoint-role="source"
        emma:endpoint-address="136.62.72.104"
        emma:port-num="50204"
        emma:port-type="rtp"
        emma:endpoint-pair-ref="endpoint1"
        emma:media-type="audio/dsr-202212; rate:8000; maxptime:40"
        emma:service-name="travel"
        emma:mode="voice"&gt;
      &lt;ex:app-protocol&gt;SIP&lt;/ex:app-protocol&gt;
    &lt;/emma:endpoint&gt;
  &lt;/emma:endpoint-info&gt;
  &lt;emma:endpoint-info id="ink-channel-1"&gt;
     &lt;emma:endpoint id="endpoint3" emma:endpoint-role="sink"
         emma:endpoint-address="http://emma.example/sink"
         emma:endpoint-pair-ref="endpoint4"
         emma:port-num="80" emma:port-type="http"
         emma:message-id="uuid:2e5678"
         emma:service-name="travel"
         emma:mode="ink"/&gt;
     &lt;emma:endpoint id="endpoint4"
         emma:endpoint-role="source"
         emma:port-address="http://emma.example/source"
         emma:endpoint-pair-ref="endpoint3"
         emma:port-num="80"
         emma:port-type="http"
         emma:message-id="uuid:2e5678"
         emma:service-name="travel"
         emma:mode="ink"/&gt;
  &lt;/emma:endpoint-info&gt;
  &lt;emma:group&gt;
    &lt;emma:interpretation id="int1" emma:start="1087995961542"
        emma:end="1087995963542"
        emma:endpoint-info-ref="audio-channel-1"
        emma:medium="acoustic" emma:mode="voice"&gt;
      &lt;destination&gt;Chicago&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:start="1087995961542"
        emma:end="1087995963542"
        emma:endpoint-info-ref="ink-channel-1"
        emma:medium="acoustic" emma:mode="voice"&gt;
      &lt;location&gt;
         &lt;type&gt;area&lt;/type&gt;
         &lt;points&gt;34.13 -37.12 42.13 -37.12 ... &lt;/points&gt;
      &lt;/location&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:group&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s4.2.15">4.2.15 Reference to <code>emma:grammar</code>
element: <code>emma:grammar-ref</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:grammar-ref</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:IDREF</code> referring to the
<code>id</code> attribute of an <code>emma:grammar</code>
element<span>.</span></td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:output </code><span>and <code>emma:active</code></span>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:grammar-ref</code> attribute associates the EMMA
result in the container element with an <code>emma:grammar</code>
element. <span>The <code>emma:grammar-ref</code> attribute is also used on <code>emma:active</code> elements within <code>emma:grammar-active</code> in order to indicate which grammars are active during the processing of an input (<a href="#4.1.4">4.1.4</a>). </span></p>
<p>The following example shows the use of <code>emma:grammar-ref</code> on the container element <code>emma:interpretation</code> and on the <code>emma:active</code> element:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:grammar id="gram1" <span>grammar-type="application/srgs-xml</span><span> ref</span>="someURI"/&gt;
  &lt;emma:grammar id="gram2" <span>grammar-type="application/srgs-xml</span><span> ref</span>="anotherURI"/&gt;
  &lt;emma:one-of id="r1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    <span>&lt;emma:grammar-active&gt;
		&lt;emma:active emma:grammar-ref="gram1"/&gt;
		&lt;emma:active emma:grammar-ref="gram2"/&gt;
    &lt;/emma:grammar-active&gt;</span>
    &lt;emma:interpretation id="int1" emma:grammar-ref="gram1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:grammar-ref="gram1"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3" emma:grammar-ref="gram2"&gt;
      &lt;command&gt;help&lt;/command&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s4.2.16">4.2.16 Reference to <code>emma:model</code>
element: <code>emma:model-ref</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:model-ref</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:IDREF</code> referring to the
<code>id</code> attribute of an <code>emma:model</code>
element<span>.</span></td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:output</code> and
application instance data.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:model-ref</code> annotation associates the EMMA
result in the container element with an <code>emma:model</code>
element.</p>
<p>Example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:model id="model1" ref="someURI"/&gt;
  &lt;emma:model id="model2" ref="anotherURI"/&gt;
  &lt;emma:one-of id="r1"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;emma:interpretation id="int1" emma:model-ref="model1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:model-ref="model1"&gt;
      &lt;origin&gt;Austin&lt;/origin&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3" emma:model-ref="model2"&gt;
      &lt;command&gt;help&lt;/command&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;
</pre>
<h3 id="s4.2.17">4.2.17 Dialog turns: <code>emma:dialog-turn</code>
attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<th>Annotation</th>
<th>emma:dialog-turn</th>
</tr>
<tr>
<th>Definition</th>
<td>An attribute of type <code>xsd:string</code> referring to the
dialog turn associated with a given container element.</td>
</tr>
<tr>
<th>Applies to</th>
<td><code>emma:interpretation</code>, <code>emma:group</code>,
<code>emma:one-of</code>, <code>emma:dialog-turn</code> and <code>emma:sequence</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>emma:dialog-turn</code> annotation associates the EMMA
result in the container element with a dialog turn. The syntax and
semantics of dialog turns is left open to suit the needs of
individual applications. For example, some applications might use
an integer value, where successive turns are represented by
successive integers. Other applications might combine a name of a
dialog participant with an integer value representing the turn
number for that participant. Ordering semantics for comparison of
<code>emma:dialog-turn</code> is deliberately unspecified and left
for applications to define.</p>
<p>Example:</p>
<pre class="example"><span>
&lt;emma:emma version="1.1"
    emma="http://www.w3.org/2003/04/emma"
    xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1" emma:dialog-turn="u8"
    <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;quantity&gt;3&lt;/quantity&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</span>
</pre>
<h3 id="s4.2.18">4.2.18  Semantic representation type: <code>emma:result-format</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:result-format</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code> xsd:string</code> containing a MIME type which indicates the representation used in the application semantics that appears within the contained <code>emma:interpretation</code>.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:literal</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:output</code> and <code>emma:sequence</code>.</td>
    </tr>
  </tbody>
</table>
<p>Typically, the application semantics contained within EMMA is in XML format, as can be seen in examples throughout the specification. The application semantics can be also be a simple string, contained within <code>emma:literal</code>. EMMA also accommodates other semantic representation formats such as JSON  (Javascript Object Notation [<a href="#json">JSON</a>] )using CDATA within <code>emma:literal</code>. The function of the <code>emma:result-format</code> attribute is to make explict the specific format of the semantic representation. The value is a MIME type. The value to generally be used for XML semantic representations is  <code>text/xml</code>. If <code>emma:result-format</code> is not specified, the assumed default is <code>text/xml</code>. If a more specific XML MIME type is being used then this should be indicated explicitly in <code>emma:result-format</code>, e.g. for RDF the <code>emma:result-format</code> would be <code>application/rdf+xml</code>. In the following example, the application semantic representation is JSON and the MIME type <code>application/json</code> appears in <code>emma:result-format</code> indicating to an EMMA processor what to expect within the contained <code>emma:literal</code>.</p>
<pre class="example">&lt;emma:emma<br>  version="1.1"<br>  xmlns:emma="http://www.w3.org/2003/04/emma"<br>  xmlns="http://www.example.com/example"&gt; <br>  &lt;emma:interpretation id=“int1"<br>    emma:confidence="0.75”<br>    emma:medium="acoustic" <br>    emma:mode="voice" <br>    emma:verbal="true"<br>    emma:function="dialog" <br>    emma:result-format="application/json" <br>      &lt;emma:literal&gt; <br>        &lt;![CDATA[<br>              {<br>           drink: {<br>              liquid:"coke",<br>              drinksize:"medium"},<br>           pizza: {<br>              number: "3",<br>              pizzasize: "large",<br>              topping: [ "pepperoni", "mushrooms" ]<br>           }<br>          } <br>          ]]&gt;<br>      &lt;/emma:literal&gt; <br>  &lt;/emma:interpretation&gt; <br>&lt;/emma:emma&gt;</pre>

<p>Note that while many of the examples of semantic representation  in the specification are simple lists of attributes and values, EMMA interpretations can contain arbitrarily complex semantic representations.  XML representation can be used for the payload, so representations can be nested, have attributes, and ID references can be used to capture aspects of the interpretation such as variable binding or co-reference. Also using <code>emma:result-format</code> and <code>emma:literal</code> as above, other kinds of logical representations and notations, not necessarily XML, can also be carried as EMMA payloads.</p>
<h3 id="s4.2.19">4.2.19 Reference to <code>emma:info</code> element: <code>emma:info-ref</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:info-ref</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:IDREF</code> referring to the <code>id</code> attribute of an <code>emma:info</code> element.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:one-of</code> and
        application instance data.</td>
    </tr>
  </tbody>
</table>
<p>The <code>emma:info-ref</code> annotation associates the EMMA
  result in the container element with a particular  <code>emma:info</code> element. This allows a single<code> emma:info</code> block of application and vendor specific annotations to apply to multiple different members of an<code> emma:one-of</code> or <code>emma:group </code>or <code>emma:sequence</code>. Alternatively, <code>emma:info</code> could appear separately as a child of each <code>emma:interpretation</code>. The benefit of using <code>emma:info-ref</code> is it avoids the need to repeat the same block of <code>emma:info</code> for multiple different interpretations.</p>
<p>Example:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:info id="info1"&gt;
    &lt;customer_type&gt;residential&lt;/customer_type&gt;
    &lt;service_name&gt;acme_travel_service&lt;/service_name&gt;
  &lt;/emma:info&gt;
   &lt;emma:info id="info2"&gt;
    &lt;customer_type&gt;residential&lt;/customer_type&gt;
    &lt;service_name&gt;acme_pizza_service&lt;/service_name&gt;
  &lt;/emma:info&gt;
  &lt;emma:one-of id="r1" emma:start="1087995961542"
      emma:end="1087995963542"
      emma:medium="acoustic" emma:mode="voice"&gt;
    &lt;emma:interpretation id="int1" emma:confidence="0.75"
      emma:tokens="flights from boston to denver tomorrow"
      emma:info-ref="info1"&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" emma:confidence="0.68"
       emma:tokens="pizza with pepperoni and onions"
       emma:info-ref="info2"&gt;
      &lt;order&gt;pizza&lt;/order&gt;
      &lt;topping&gt;pepperoni&lt;/topping&gt;
      &lt;topping&gt;onion&lt;/topping&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int3" emma:confidence="0.38"
       emma:tokens="pizza with peppers and cheese"
       emma:info-ref="info2"&gt;
      &lt;order&gt;pizza&lt;/order&gt;
      &lt;topping&gt;pepperoni&lt;/topping&gt;
      &lt;topping&gt;cheese&lt;/topping&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
</pre>
<h3 id="s4.2.20">4.2.20 Reference to <code>emma:process-model</code> element: <code>emma:process-model-ref</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:process-model-ref</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:IDREF</code> referring to the <code>id</code> attribute of an <code>emma:process-model</code> element.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:output</code>, <code>emma:sequence</code>, and
        application instance data.</td>
    </tr>
  </tbody>
</table>
<p>The <code>emma:process-model-ref</code> annotation associates the EMMA
  result in the container element with an <code>emma:process-model</code> element. In the following example the specific model used to produce two different object recognition results based on an image as input are indicated on the interpretations using <code>emma:process-model-ref</code> which references an <code>emma:process-model </code>element under <code>emma:emma</code> whose <code>ref</code> attribute contains URI identifying the particular model used.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:process-model id="pm1"
    type="neural_network"
    ref="http://example.com/vision/vehicle"/&gt;
  &lt;emma:process-model id="pm2"
    type="neural_network"
    ref="http://example.com/vision/people"/&gt;
  &lt;emma:one-of id="r1"
    emma:start="1087995961542"
    emma:end="1087995961542"
    emma:medium="visual" 
    emma:mode="image"
    emma:process="http://example.com/mycompvision1.xml"&gt;&gt;
    &lt;emma:interpretation id="int1"
      emma:confidence="0.9"
      emma:process-model-ref="pm1"&gt;
      &lt;object&gt;aircraft&lt;/object&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="int2" 
      emma:confidence="0.1"
      emma:process-model-ref="pm2"&gt;
      &lt;object&gt;person&lt;/object&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:one-of&gt;
&lt;/emma:emma&gt;</pre>

<h3 id="s4.2.21">4.2.21 Reference to <code>emma:parameters</code>
element: <code>emma:parameter-ref</code> attribute</h3>
<table class="defn" summary="property definition" cellpadding="5" cellspacing="0" width="98%">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:parameter-ref</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:IDREF</code> referring to the
          <code>id</code> attribute of an <code>emma:parameters</code>
element.</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:output</code>,


      and <code>emma:sequence</code>.</td>
    </tr>
  </tbody>
</table>
<p>The <code>emma:parameter-ref</code> annotation associates the
EMMA result(s) in the container element it appears on with an <code>emma:parameters</code>
element that specifies a series of parameters used to configure the processor that produced those result(s). This allows a set of parameters to be specified once in an EMMA document and referred to by multiple different interpretations. Different configurations of parameters can be associated with different interpretations. In the example, below there are two <code>emma:parameters</code> elements and in the N-best list of alternative interpretations within <code>emma:one-of</code> each <code>emma:interpretation </code>references the relevant set of parameters using <code>emma:parameter-ref</code>. </p>
<span>
<pre class="example">&lt;emma:emma version="1.1"<br>    xmlns:emma="http://www.w3.org/2003/04/emma"<br>    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"<br>    xsi:schemaLocation="http://www.w3.org/2003/04/emma<br>     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"<br>    xmlns="http://www.example.com/example"&gt;<br>    &lt;emma:parameters id="parameters1" api-ref="voicexml2.1"&gt;<br>	   &lt;emma:parameter name="speedvsaccuracy" value=".5"/&gt;<br>	   &lt;emma:parameter name="sensitivity" value=".6"/&gt;<br>    &lt;/emma:parameters&gt;
    &lt;emma:parameters id="parameters2" api-ref="voicexml2.1"&gt;<br>	   &lt;emma:parameter name="speedvsaccuracy" value=".7"/&gt;<br>	   &lt;emma:parameter name="sensitivity" value=".3"/&gt;<br>    &lt;/emma:parameters&gt;
   &lt;emma:one-of emma:medium="acoustic" emma:mode="voice" emma:process="http://example.com/myasr1.xml"&gt;<br>    &lt;emma:interpretation id="int1" emma:parameter-ref="parameters1"&gt;<br>      &lt;origin&gt;Boston&lt;/origin&gt;<br>    &lt;/emma:interpretation&gt;
     &lt;emma:interpretation id="int2" emma:parameter-ref="parameters2"&gt;<br>      &lt;origin&gt;Austin&lt;/origin&gt;<br>    &lt;/emma:interpretation&gt;
   &lt;/emma:one-of&gt;<br>&lt;/emma:emma&gt;<br>
</pre>
</span>
<h3 id="s4.2.22">4.2.22 Human transcription: the <code>emma:annotated-tokens</code> attribute</h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:annotated-tokens</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:string</code> holding the reference sequence of tokens determined by a human annotator</td>
    </tr>
    <tr>
      <th>Applies to</th>
      <td><code>emma:interpretation</code>, <code>emma:group</code>, <code>emma:one-of</code>, <code>emma:sequence</code>, <code>emma:arc</code>, and
        application instance data.</td>
    </tr>
  </tbody>
</table>
<p>The <code>emma:annotated-tokens</code> attribute holds a list of input
  tokens. In the following description, the term <i>tokens</i> is
  used in the computational and syntactic sense of <i>units of
    input</i>, and not in the sense of <i>XML tokens</i>. The value
  held in <code>emma:annotated-tokens</code> is the list of the tokens of input
  as determined by a human annotator. For example, in case of speech recognition this will contain the reference string. The <code>emma:annotated-tokens</code> annotation MAY be applied not just
  to the lexical words and phrases of language but to any level of
  input processing. Other examples of tokenization include phonemes,
  ink strokes, gestures and any other discrete units of input at any
  level.</p>
<p>In the following example, a speech recognizer has processed an audio input signal and the hypothesized string is "from cambridge to london tomorrow" contained in <code>emma:tokens</code>. A human labeller has listened to the audio and added the reference string "from canterbury to london today" in the <code>emma:annotated-tokens</code> attribute.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="int1"
      emma:medium="acoustic" 
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:signal="http://example.com/audio/input678.amr"
      emma:process="http://example.com/asr/params.xml"
      emma:tokens="from cambridge to london tomorrow"<br>      emma:annotated-tokens="from canterbury to london today"&gt;
    &lt;origin&gt;Cambridge&lt;/origin&gt;
    &lt;destination&gt;London&lt;/destination&gt;
    &lt;date&gt;tomorrow&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>In order to provide metadata on the annotation such as the name of the annotator or time of annotation, the more powerful <a href="#s4.1.9"><code>emma:annotation</code></a> element mechanism should be used. This also allows for structured annotations such as labelling of a semantic interpretation in XML.</p>

<h3 id="s4.2.23">4.2.23 Partial Content: <code>emma:partial-content</code></h3>
<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:partial-content</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:Boolean</code> indicating whether the content of an element is partial and the full element can be retrieved by retrieving the URI indicated in the <code>ref</code> attribute on the same element</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:one-of</code>, <code>emma:group</code>, <code>emma:sequence</code>, <code>emma:lattice</code>, <code>emma:info</code>, <code>emma:annotation</code>, <code>emma:parameters</code> and
        application instance data.</td>
    </tr>
  </tbody>
</table>


<p >The <code>emma:partial-content</code> attribute is required on the element it applies to when the content contained within the element is a subset of the content contained within the element referred to through the <code>ref</code> attribute on the same element. If the local element is empty, but a full document can be retrieved from the server, then in that case <code>emma:partial-content</code> must be <code>true</code>. If the element is empty and the element on the server is also empty then <code>emma:partial-content</code> must be <code>false</code>. The default value in <code>emma:partial-content</code> is not specified is <code>false</code>.</p>

<h3 id="s4.2.24">4.2.24 Incremental results: <code>emma:stream-id</code>, <code>emma:stream-seq-num, emma:stream-status</code>, <code>emma:stream-full-result</code>, <code>emma:stream-token-span</code>, <code>emma:stream-token-span-full, emma:stream-token-immortals</code>, <code>emma:stream-immortal-vertex</code></h3>

<table class="defn" summary="property definition" width="98%" cellpadding="5" cellspacing="0">
  <tbody>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-id</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:ID</code> identifying the stream to which this incremental result belongs </td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code>,<code> emma:one-of</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-seq-num</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:integer</code> used to indicate the position of a result in a sequence of partial results in a given stream of incremental results</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code>,<code> emma:one-of</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-status</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:string</code> constrained to
values in the  set {<code>begin</code>, <code>in-progress</code>, <code>end</code><code></code>} indicating whether this is the first message in a stream of incremental results, an intermediate result, or the last result</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code>,<code> emma:one-of</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-full-result</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:Boolean</code> indicating whether the  incremental result received represents the overall interpretation of that stream so far</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code>,<code> emma:one-of</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-token-span</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:string</code> indicating the start and end vertices that the current result (and <code>emma:tokens</code> within that) spans within the series of tokens being populated by a stream of partial results</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-token-span-full</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:string</code> indicating the start and end of the overall result for the stream so far</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-token-immortals</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <span><code>xsd:nmtokens</code></span> <span>which contains a space delimited set of values from the
set</span> {<code>true</code>, <code>false</code>}.  This signals to the EMMA consumer which of the tokens are final and which may be subject to change in future partial results in the stream</td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code></td>
    </tr>
    <tr>
      <th>Annotation</th>
      <th>emma:stream-immortal-vertex</th>
    </tr>
    <tr>
      <th>Definition</th>
      <td>An attribute of type <code>xsd:Integer</code> indicating the vertex number in a sequence of tokens before which all tokens are considered final. This signals to the EMMA consumer that future partial results in the stream will not update tokens before the <code>stream-immortal-vertex</code></td>
    </tr>
    <tr>
      <th >Applies to</th>
      <td><code>emma:interpretation</code></td>
    </tr>
  </tbody>
</table>

<p >Incremental processing of inputs enables interactive applications to provide users with direct feedback on recognition, understanding and other levels of processing, potentially resulting in a more dynamic and engaging user experience. EMMA provides a series of attributes that support streaming incremental results from an EMMA producer to an EMMA consumer. These attributes capture the relationship between a series of partial results, how they relate to the whole and can also indicate whether the tokens in a partial result are final or subject to change. The specifics of the transport medium for communication of incremental, partial results are out of scope for EMMA.</p>
<p >Note that this section only discusses incremental inputs. Incremental system outputs will be addressed in a future Working Draft.</p>
<p >One common use case for incremental results is giving immediate feedback as a user dictates spoken input. For example, if a user is dictating a message, incrementality enables them to see the words recognized as they spea, rather than having to wait until recognition of the whole input is complete.</p>
<pre class="example">
1. Hi Joe ...
2. Hi Joe the tweeting ...
3. Hi Joe the meeting has remove two...
4. Hi Joe the meeting has now moved to...
5. Hi Joe the meeting has now moved downstairs.
</pre>

<p >In this example, as the user  dictates the message, the user interface shows them the current best hypothesis as speech recognition proceeds. In order to support this use case, a speech recognition component producing EMMA needs to be able to produce a series of partial results and indicate how they relate to each other. Below we show how this series of incremental results can be handled in EMMA using the various <code>emma:stream-*</code> attributes.</p>
<p >The <code>emma:stream-id</code> MUST appear on each member of series of EMMA documents capturing incremental results and serves to identify the stream to which they all belong, i.e. all members of a given stream have the same  <code>emma:stream-id</code> . Presence of an <code>emma:stream-id</code> is the mechanism through which an EMMA result is marked as being incremental. </p>
<p >The <code>emma:stream-status</code> attribute MUST appear on each member of a series of partial results. <code>emma:stream-status</code> takes values from the set {<code>begin</code>, <code>in-progress</code>, <code>end</code>} and is used to indicate whether this is a new stream ('<code>begin</code>'), an intermediate result in an ongoing stream ('<code>in-progress</code>') or the final result in a given stream ('<code>end</code>'). </p>
<p >The <code>emma:stream-seq-num</code> attribute MUST appear on each member of a series of partial results and contains an integer indicating the position in sequence of this result within the stream. Note that this position index does not relate to position in the actual result, e.g. a token span in a string, rather it indicates the position of the result in a series of incremental results from an EMMA producer.</p>
<p >The <code>emma:stream-full-result</code> attribute is an optional attribute taking a boolean value which indicates whether the incremental result received contains a result for the whole input signal received so far. This indicates whether the result is for the whole stream so far, or only for the last chunk of the signal. One use of <code>emma:stream-full-result</code> is to cover a common use case in incremental processing where the final result in the sequence includes the final interpretation for the whole input. In this case that final result is marked as <code>emma:stream-status=&quot;end&quot;</code> and <code>emma:stream-full-result=&quot;true&quot;</code>. If instead the final result just gives the token and interpretation for the final chunk of the incremental input, it would be annotated as <code>emma:stream-status=&quot;end&quot;</code> and <code>emma:stream-full-result=&quot;false&quot;</code>.</p>
<p >For incremental results which involve a sequence of tokens, such as dictation of sequence of words or handwritten input of a sequence of characters. EMMA provides a series of attributes that can be used to indicate how a specific token relates to the overall sequence of tokens (<code>emma:stream-token-span</code>, <code>emma:stream-token-span-full</code>). These mechanisms allow for incremental results to provide revisions of previous tokens as more of the signal is processed, e.g. 'tweeting' becoming 'meeting' in the example above. Further attributes enable specification of whether tokens in the result are now 'immortal' that is, they will not be changed in future results within the stream (<code>emma:stream-token-immortals</code>, <code>emma:stream-immortal-vertex</code>).</p>
<p >For incremental results with tokens. The tokens themselves are specified using the <code>emma:tokens</code>, <code>emma:token-type</code>, and <code>emma:token-score</code> (defined in <a href="#s4.2.1">Section 4.2.1</a>). The<code> emma:tokens</code> attribute contains a space delimited sequence of tokens. What the tokens are, e.g. <code>word</code>, <code>phoneme</code>, <code>character</code> is specified with a string value in the <code>emma:token-type</code> attribute. Per token scores may be specified using the <code>emma:token-score</code> attribute which contains a space delimited sequence of numerical scores between 0 and 1. In order to indicate the how the tokens in an incremental result map to the overall sequence of tokens, the <code>emma:stream-token-span</code> indicates the start and end vertices in the token stream that the result specifies. For example, if a result contains the first two words in a stream, the <code>emma:stream-token-span</code> would be <code>&quot;0-2&quot;</code>. The next word in the sequence would be<code> emma:stream-token-span=&quot;2-3&quot;</code>. The <code>emma:stream-token-span-full</code> is an optional attribute, also a vertex range, which indicates the overall start and end vertices for the whole stream so far.</p>
<p >EMMA also provides attributes for indicating whether a token within an incremental result is final ('immortal') or subject to change in future results. The <code>emma:stream-token-immortals</code> contains a space delimited sequence of boolean values (true/false), indicating on a per token basis whether the token is final and will not change, or subject to change in a future result. For example, if <code>emma:tokens=&quot;Hi Joe the&quot;</code> and <code>emma:token-score=&quot;0.9 0.7 0.5&quot;</code> and <code>emma:stream-token-immortals=&quot;true true false&quot;</code> then first two words have scores <code>0.9</code> and <code>0.7</code> and those words will not change in future results. While, the word &quot;the&quot; has score <code>0.5</code> and &quot;false&quot; in the <code>emma:stream-token-immortals</code> indicates that the word &quot;the&quot; may be subject to change. One use of <code>emma:stream-token-immortals</code> is to drive the appearance of words in the user interface in a client. For example, immortal words might appear in bold dark font, while not non immortal tokens are shown in grey. EMMA provides an additional mechanism for indicating how many of the tokens are immortal. The attribute emma:stream-immortal-vertex indicates which vertex (as in the emma:token-span) is the point up to which all tokens are immortal. For example, if <code>emma:tokens=&quot;Hi Joe the tweeting&quot;</code> and <code>emma:token-span=&quot;0-4&quot;</code> then if <code>emma:stream-immortal-vertex=&quot;2&quot;</code> then the words &quot;Hi&quot; and &quot;Joe&quot; are final and the word &quot;the&quot; and &quot;tweeting&quot; are subject to further potential revision in the result.</p>


<p >The following illustration shows the progress of incremental results for the utterance &quot;Hi Joe the meeting has now moved downstairs&quot; as the user speaks and the recognizer incrementally updates the result.</p>
<p ><img src="incremental.png" width="996" height="728" alt="progress of an incremental input" /></p>
<p >In order to exemplify the use of the <code>emma:stream-*</code> attributes in the following subsections we provide examples of their use in a spoken dictation scenario, interactive voice search, and incremental handwriting recognition. </p>

<h4 id="s4.2.24.1" >4.2.24.1 Example use case of incremental results in dictation</h4>

<p >The example below shows how EMMA attributes can be used for streaming incremental results in the case of dictation of a spoken message. Before the EMMA markup, square brackets [] are used to indicate which words are contained in each following partial result.</p>
<p>1. [Hi Joe] ...</p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int11&quot; <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.75&quot;
       emma:tokens=&quot;Hi Joe&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.90 0.70&quot;<br />       emma:stream-id=&quot;s1&quot;<br />       emma:stream-seq-num=&quot;0&quot;<br />       emma:stream-status=&quot;begin&quot;
       emma:stream-full-result=&quot;true&quot;<br />       emma:stream-token-span=&quot;0-2&quot;<br />       emma:stream-token-immortals=&quot;true false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;1&quot;&gt;<br />      &lt;emma:literal&gt;Hi Joe&lt;/emma:literal&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre>

<p >The <code>emma:stream-id</code> value '<code>s1</code>' is appears on all of the results in the stream. emma:token-type=&quot;word&quot; indicates that we can expect the space separated values in <code>emma:tokens</code> to be words. <span class="example"><code>emma:stream-status=&quot;begin&quot;</code></span> indicates that this is the beginning of the stream. The annotation <span class="example"><code>emma:stream-token-span=&quot;0-2&quot;</code></span> indicates that this is an partial result for  the first two words in the stream of of tokens. </p>
<p>2. Hi [Joe the tweeting]...</p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int12&quot;  <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.8&quot;
       emma:tokens=&quot;Joe the tweeting&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.9 0.77 0.91&quot;<br />       emma:stream-id=&quot;s1&quot;<br />       emma:stream-seq-num=&quot;1&quot;<br />       emma:stream-status=&quot;in-progress&quot;
       emma:stream-full-result=&quot;false&quot;<br />       emma:stream-token-span=&quot;1-4&quot;<br />       emma:stream-token-immortals=&quot;true true false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;3&quot;&gt;<br />      &lt;emma:literal&gt;Joe the tweeting&lt;/emma:literal&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre>

<p>3. Hi Joe the [meeting has remove two]...</p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int13&quot;  <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.77&quot;
       emma:tokens=&quot;meeting has remove two&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.95 0.91 0.60 0.78&quot;<br />       emma:stream-id=&quot;s1&quot;<br />       emma:stream-seq-num=&quot;2&quot;<br />       emma:stream-status=&quot;in-progress&quot;
       emma:stream-full-result=&quot;false&quot;<br />       emma:stream-token-span=&quot;3-7&quot;<br />       emma:stream-token-immortals=&quot;true true false false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;5&quot;&gt;<br />      &lt;emma:literal&gt;meeting has remove two&lt;/emma:literal&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre> 

<p>4. Hi Joe the meeting has [now moved to]...</p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int14&quot;  <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.77&quot;
       emma:tokens=&quot;now moved to&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.95 0.91 0.5&quot;<br />       emma:stream-id=&quot;s1&quot;<br />       emma:stream-seq-num=&quot;3&quot;<br />       emma:stream-status=&quot;in-progress&quot;
       emma:stream-full-result=&quot;false&quot;<br />       emma:stream-token-span=&quot;5-8&quot;<br />       emma:stream-token-immortals=&quot;true true false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;7&quot;&gt;<br />      &lt;emma:literal&gt;now moved to&lt;/emma:literal&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre> 

<p>5. [Hi Joe the meeting has now moved downstairs]</p>

<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int15&quot;  <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.94&quot;
       emma:tokens=&quot;downstairs&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.9&quot;<br />       emma:stream-id=&quot;s1&quot;<br />       emma:stream-seq-num=&quot;4&quot;<br />       emma:stream-status=&quot;in-progress&quot;
       emma:stream-full-result=&quot;false&quot;<br />       emma:stream-token-span=&quot;7-8&quot;<br />       emma:stream-token-immortals=&quot;true&quot;<br />       emma&quot;stream-immortal-vertex=&quot;8&quot;&gt;<br />      &lt;emma:literal&gt;downstairs&lt;/emma:literal&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;</pre>
In the next example we see how incremental results can be used for a voice search application, where there is a semantic interpretation in addition to a sequence of results.

<h4 id="s4.2.24.2" >4.2.24.2 Example use case of incremental results in voice search application</h4>

<p >In the following example we consider a series of partial results in a incremental voice search query, this differs from the dictation example above in that in addition to the tokens, there is also an emerging semantic interpretation evolving in application specific markup within <code>&lt;emma:interpretation/&gt;. </code>The example domain is a query about flights and as each incremental EMMA result is received the semantic interpretation is expanded.  In this case, the partial result is for the whole input up until that point.</p>
<pre class="example">
1. flights from boston ...
2. flights from austin to dallas ...
3. flights from austin to denver tomorrow.</pre>
<p></p>
<p>1. [flights from boston] ...</p>
<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int21&quot; <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.75&quot;
       emma:tokens=&quot;flights from boston&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.9 0.8 0.5&quot;<br />       emma:stream-id=&quot;s2&quot;<br />       emma:stream-seq-num=&quot;0&quot;<br />       emma:stream-status=&quot;begin&quot;<br />       emma:stream-token-span=&quot;0-3&quot;
       emma:stream-full-result=&quot;true&quot;<br />       emma:stream-token-immortals=&quot;true true false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;2&quot;&gt;<br />      &lt;flight&gt;
        &lt;src&gt;boston&lt;/src&gt;
      &lt;/flight&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre>
<p></p>
<p>2. [flights from austin to dallas] ...</p>
<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int22&quot; <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.80&quot;
       emma:tokens=&quot;flights from austin to dallas&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.9 0.8 0.9 0.8 0.5&quot;<br />       emma:stream-id=&quot;s2&quot;<br />       emma:stream-seq-num=&quot;1&quot;<br />       emma:stream-status=&quot;in-progress&quot;
       emma:stream-full-result=&quot;true&quot;<br />       emma:stream-token-span=&quot;0-5&quot;<br />       emma:stream-token-immortals=&quot;true true true false false&quot;<br />       emma&quot;stream-immortal-vertex=&quot;3&quot;&gt;<br />      &lt;flight&gt;
        &lt;src&gt;austin&lt;/src&gt;
        &lt;dest&gt;dallas&lt;/dest&gt;
      &lt;/flight&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;
</pre>
<p></p>
<p>3. [flights from austin to dallas tomorrow] </p>
<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />  &lt;emma:interpretation id=&quot;int23&quot; <br />       emma:medium=&quot;acoustic&quot;<br />       emma:mode=&quot;voice&quot;<br />       emma:confidence=&quot;0.85&quot;
       emma:tokens=&quot;flights from austin to denver tomorrow&quot;
       emma:token-type=&quot;word&quot;
       emma:token-score=&quot;0.9 0.8 0.9 0.8 0.9 0.9&quot;<br />       emma:stream-id=&quot;s2&quot;<br />       emma:stream-seq-num=&quot;2&quot;<br />       emma:stream-status=&quot;end&quot;
       emma:stream-full-result=&quot;true&quot;<br />       emma:stream-token-span=&quot;0-6&quot;<br />       emma:stream-token-immortals=&quot;true true true true true true&quot;<br />       emma&quot;stream-immortal-vertex=&quot;6&quot;&gt;<br />      &lt;flight&gt;
        &lt;src&gt;austin&lt;/src&gt;
        &lt;dest&gt;denver&lt;/dest&gt;
        &lt;time&gt;tomorrow&lt;/time&gt;
      &lt;/flight&gt;<br />  &lt;/emma:interpretation&gt;<br />&lt;/emma:emma&gt;

</pre>
<h4  id="s4.2.24.3">4.2.24.3 Example use case of incremental recognition of handwritten characters</h4>

<p >In the next example we show the use of incremental results in EMMA for representing the results of  incremental handwriting recognition. Tokens returned by the recognizer in this example correspond to individual characters (<code>emma:token-type="character"</code>). The <code>emma:stream-id</code> value <code>"s3"</code> identifies the interpretations as being part of the same set of incremental results.
  <code>emma:stream-seq-num</code> indicates the number of the incremental result in sequence, with a value of <code>"0"</code> corresponding to the first result, 
  <code>"1"</code> corresponding to the second result, and so on.
  <br/>
</p>
<p>0. [1]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int31" 
      emma:confidence="0.75"
      emma:token-type="character"
      emma:tokens="'1'"
      emma:token-score="0.75"
      emma:stream-id="s3"
      emma:stream-seq-num="0"
      emma:stream-status="begin"
      emma:stream-token-span="0-1"
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="0"
      emma:stream-full-result="true">
      &lt;emma:literal>1&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>


<p>1. 1[1]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int32" 
      emma:confidence="0.8"
      emma:token-type="character"
      emma:tokens="'1'"
      emma:token-score="0.8"
      emma:stream-id="s3"
      emma:stream-seq-num="1"
      emma:stream-status="in-progress"
      emma:stream-token-span="1-2"
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="0"
      emma:stream-full-result="false">
      &lt;emma:literal>1&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>


<p>2. [H]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int33" 
      emma:confidence="0.8"
      emma:token-type="character"
      emma:tokens="'H'"
      emma:token-score="0.9"
      emma:stream-id="s3"
      emma:stream-seq-num="2"
      emma:stream-status="in-progress"
      emma:stream-token-span="0-1"
      emma:stream-token-span-full=&quot;0-1&quot;
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="0"
      emma:stream-full-result="true">
      &lt;emma:literal>H&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p >In this case, <span class="example"><code>emma:stream-token-span-full</code></span><code>=&quot;0-1&quot;</code> is used to indicate that there is now only one token in the stream, that is the sequence of two '1's (0-2) has been reinterpreted as a single 'H' (0-1).</p>
<p>3. H[i]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int34" 
      emma:confidence="0.6"
      emma:token-type="character"
      emma:tokens="'i'"
      emma:token-score="0.6"
      emma:stream-id="s3"
      emma:stream-seq-num="3"
      emma:stream-status="in-progress"
      emma:stream-token-span="1-2"
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="0"
      emma:stream-full-result="false">
      &lt;emma:literal>i&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p>4. Hi[ J]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int35" 
      emma:confidence="0.6"
      emma:token-type="character"
      emma:tokens="' ' 'J'"
      emma:token-score="0.75 0.6"
      emma:stream-id="s3"
      emma:stream-seq-num="4"
      emma:stream-status="in-progress"
      emma:stream-token-span="2-4"
      emma:stream-token-immortals="false false"
      emma:stream-immortal-vertex="3"
      emma:stream-full-result="false">
      &lt;emma:literal> J&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>


<p>5. Hi J[oe]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int36" 
      emma:confidence="0.8"
      emma:token-type="character"
      emma:tokens="'o' 'e'"
      emma:token-score="0.75 0.8"
      emma:stream-id="s3"
      emma:stream-seq-num="5"
      emma:stream-status="in-progress"
      emma:stream-token-span="4-6"
      emma:stream-token-immortals="false false"
      emma:stream-immortal-vertex="3"
      emma:stream-full-result="false">
      &lt;emma:literal>oe&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p>6. Hi Joe[l]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int37" 
      emma:confidence="0.5"
      emma:token-type="character"
      emma:tokens="'l'"
      emma:token-score="0.5"
      emma:stream-id="s3"
      emma:stream-seq-num="6"
      emma:stream-status="in-progress"
      emma:stream-token-span="6-7"
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="3"
      emma:stream-full-result="false">
      &lt;emma:literal>l&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p>7. Hi Joe[,]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int38" 
      emma:confidence="0.7"
      emma:token-type="character"
      emma:tokens="','"
      emma:token-score="0.7"
      emma:stream-id="s3"
      emma:stream-seq-num="7"
      emma:stream-status="in-progress"
      emma:stream-token-span="6-7"
      emma:stream-token-immortals="false"
      emma:stream-immortal-vertex="3"
      emma:stream-full-result="false">
      &lt;emma:literal>,&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p>8. Hi Joe,[ the]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int39" 
      emma:confidence="0.7"
      emma:token-type="character"
      emma:tokens="' ' 't' 'h' 'e'"
      emma:token-score="0.6 0.7 0.75 0.65"
      emma:stream-id="s3"
      emma:stream-seq-num="8"
      emma:stream-status="in-progress"
      emma:stream-token-span="7-11"
      emma:stream-token-immortals="false false false false"
      emma:stream-immortal-vertex="8"
      emma:stream-full-result="false">
      &lt;emma:literal> the&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>

<p>9. Hi Joe, the[ meeting has moved]</p>
<pre class="example">
&lt;emma:emma version="2.0"
   xmlns:emma="http://www.w3.org/2003/04/emma"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
   xmlns="http://www.example.com/example">
 &lt;emma:interpretation id="int40" 
      emma:confidence="0.7"
      emma:token-type="character"
      emma:tokens="' ' 'm' 'e' 'e' 't' 'i' 'n' 'g' ' ' 'h' 'a' 's' ' ' 'm' 'o' 'v' 'e' 'd'"
      emma:token-score="0.6 0.7 0.5 0.5 0.6 0.6 0.7 0.75 0.7 0.75 0.8 0.8 0.8 0.6 0.7 0.7 0.65 0.65"
      emma:stream-id="s3"
      emma:stream-seq-num="9"
      emma:stream-status="in-progress"
      emma:stream-token-span="11-29"
      emma:stream-token-immortals="false false false false false false false false false false false false false false false false false false"
      emma:stream-immortal-vertex="8"
      emma:stream-full-result="false">
      &lt;emma:literal>m&lt;/emma:literal>
 &lt;/emma:interpretation>
&lt;/emma:emma>
</pre>


<p>10. [Hi Joe, the meeting has moved]</p>
<pre class="example">
&lt;emma:emma version=&quot;2.0&quot;
   xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;
   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
   xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma
    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;
   xmlns=&quot;http://www.example.com/example&quot;&gt;
 &lt;emma:interpretation id=&quot;int41&quot; 
      emma:confidence=&quot;0.8&quot;
      emma:token-type=&quot;character&quot;
      emma:tokens=&quot;'H' 'i' ' ' 'J' 'o' 'e' ' ' 't' 'h' 'e' ' ' 'm' 'e' 'e' 't' 'i' 'n' 'g' ' ' 
                   'h' 'a' 's' ' ' 'm' 'o' 'v' 'e' 'd'&quot;
      emma:token-score=&quot;0.6 0.7 0.7 0.65 0.7 0.75 0.6 0.7 0.5 0.5
                        0.6 0.6 0.7 0.75 0.8 0.8 0.65 0.6 0.7 0.7
                        0.65 0.65 0.7 0.75 0.8 0.8 0.65 0.6 0.7&quot;
      emma:stream-id=&quot;s3&quot;
      emma:stream-seq-num=&quot;13&quot;
      emma:stream-status=&quot;end&quot;
      emma:stream-token-span=&quot;0-29&quot;
      emma:stream-immortal-vertex=&quot;29&quot;
      emma:stream-full-result=&quot;true&quot;&gt;
      &lt;emma:literal&gt;Hi Joe the meeting has moved&lt;/emma:literal&gt;
 &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>

<p >In this case the final message in the stream contains the full result as indicated by <code>emma:stream-full-result=&quot;true&quot;</code>.</p>
<p>&nbsp;</p>
<h2 class="notoc">4.3 Scope of EMMA annotations</h2>
<p>The <code>emma:derived-from</code> element (<a href="#s4.1.2">Section 4.1.2</a>) can be used to capture both sequential
and composite derivations. This section concerns the scope of EMMA
annotations across <span>sequential</span> derivations of user
input connected using the <code>emma:derived-from</code> element
(<a href="#s4.1.2">Section 4.1.2</a>). Sequential derivations
involve processing steps that do not involve multimodal
integration, such as applying natural language understanding and
then reference resolution to a speech transcription. EMMA
derivations describe only single turns of user input and are not
intended to describe a sequence of dialog turns.</p>
<p>For example, an EMMA document could contain
<code>emma:interpretation</code> elements for the transcription,
interpretation, and reference resolution of a speech input,
utilizing the <code>id</code> values: <code>raw</code>,
<code>better</code>, and <code>best</code> respectively:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
 &lt;emma:derivation&gt;
  &lt;emma:interpretation id="raw"
      emma:process="http://example.com/myasr1.xml"
      <span>emma:medium="acoustic" emma:mode="voice"</span>&gt;
    &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
  &lt;/emma:interpretation&gt;
  &lt;emma:interpretation id="better"
      emma:process="http://example.com/mynlu1.xml"&gt;
    &lt;emma:derived-from resource="#raw" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;tomorrow&lt;/date&gt;
  &lt;/emma:interpretation&gt;
 &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="best"
      emma:process="http://example.com/myrefresolution1.xml"&gt;
    &lt;emma:derived-from resource="#better" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Each member of the derivation chain is linked to the previous
one by a <code>derived-from</code> element (<a href="#s4.1.2">Section 4.1.2</a>), which has an attribute
<code>resource</code> that provides a pointer to the
<code>emma:interpretation</code> from which it is derived. The
<code>emma:process</code> annotation (<a href="#s4.2.2">Section
4.2.2</a>) provides a pointer to the process used for each stage of
the derivation.</p>
<p>The following EMMA example represents the same derivation as
above but with a more fully specified set of annotations:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:interpretation id="raw"
        emma:process="http://example.com/myasr1.xml"
        emma:source="http://example.com/microphone/NC-61"
        emma:signal="http://example.com/signals/sg23.wav"
        emma:confidence="0.6"
        emma:medium="acoustic"
        emma:mode="voice"
        emma:function="dialog"
        emma:verbal="true"
        emma:tokens="from boston to denver tomorrow"
        emma:lang="en-US"&gt;
      &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="better"
        emma:process="http://example.com/mynlu1.xml"
        emma:source="http://example.com/microphone/NC-61"
        emma:signal="http://example.com/signals/sg23.wav"
        emma:confidence="0.8"
        emma:medium="acoustic"
        emma:mode="voice"
        emma:function="dialog"
        emma:verbal="true"
        emma:tokens="from boston to denver tomorrow"
        emma:lang="en-US"&gt;
      &lt;emma:derived-from resource="#raw" composite="false"/&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="best"
      emma:process="http://example.com/myrefresolution1.xml"
      emma:source="http://example.com/microphone/NC-61"
      emma:signal="http://example.com/signals/sg23.wav"
      emma:confidence="0.8"
      emma:medium="acoustic"
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:tokens="from boston to denver tomorrow"
      emma:lang="en-US"&gt;
    &lt;emma:derived-from resource="#better" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>EMMA annotations on earlier stages of the derivation often
remain accurate at later stages of the derivation. Although this
can be captured in EMMA by repeating the annotations on each
<code>emma:interpretation</code> within the derivation, as in the
example above, there are two disadvantages of this approach to
annotation. First, the repetition of annotations makes the
resulting EMMA documents significantly more verbose. Second, EMMA
processors used for intermediate tasks such as natural language
understanding and reference resolution will need to read in all of
the annotations and write them all out again.</p>
<p>EMMA overcomes these problems by assuming that annotations on
earlier stages of a derivation automatically apply to later stages
of the derivation unless a new value is specified. Later stages of
the derivation essentially inherit annotations from earlier stages
in the derivation. For example, if there was an
<code>emma:source</code> annotation on the transcription
(<code>raw</code>) it would also apply to the later stages of the
derivation such as the result of natural language understanding
(<code>better</code>) or reference resolution
(<code>best</code>).</p>
<p>Because of the assumption in EMMA that annotations have scope
over later stages of a sequential derivation, the example EMMA
document above can be equivalently represented as follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:derivation&gt;
    &lt;emma:interpretation id="raw"
        emma:process="http://example.com/myasr1.xml"
        emma:source="http://example.com/microphone/NC-61"
        emma:signal="http://example.com/signals/sg23.wav"
        emma:confidence="0.6"
        emma:medium="acoustic"
        emma:mode="voice"
        emma:function="dialog"
        emma:verbal="true"
        emma:tokens="from boston to denver tomorrow"
        emma:lang="en-US"&gt;
      &lt;answer&gt;From Boston to Denver tomorrow&lt;/answer&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation id="better"
        emma:process="http://example.com/mynlu1.xml"
        emma:confidence="0.8"&gt;
      &lt;emma:derived-from resource="#raw" composite="false"/&gt;
      &lt;origin&gt;Boston&lt;/origin&gt;
      &lt;destination&gt;Denver&lt;/destination&gt;
      &lt;date&gt;tomorrow&lt;/date&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:derivation&gt;
  &lt;emma:interpretation id="best"
      emma:process="http://example.com/myrefresolution1.xml"&gt;
    &lt;emma:derived-from resource="#better" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The fully specified derivation illustrated above is equivalent
to the reduced form derivation following it where only annotations
with new values are specified at each stage. These two EMMA
documents MUST yield the same result when processed by an EMMA
processor.</p>
<p>The <code>emma:confidence</code> annotation is respecified on
the <code>better</code> interpretation. This indicates the
confidence score for natural language understanding, whereas
<code>emma:confidence</code> on the <code>raw</code> interpretation
indicates the speech recognition confidence score.</p>
<p>In order to determine the full set of annotations that apply to
an <code>emma:interpretation</code> element an EMMA processor or
script needs to access the annotations directly on that element and
for any that are not specified follow the reference in the
<code>resource</code> attribute of the
<code>emma:derived-from</code> element to add in annotations from
earlier stages of the derivation.</p>
<p>The EMMA annotations break down into three groups with respect
to their scope in sequential derivations. One group of annotations
always hold<span>s</span> true for all members of a sequential
derivation. A second group <span>is</span> always respecified on
each stage of the derivation. A third group may or may not be
respecified.</p>
<table summary="7 columns" border="1" cellpadding="3" cellspacing="0">
<caption>Scope of Annotations in Sequential Derivations</caption>
<tbody>
<tr>
<th>Classification</th>
<th>Annotation</th>
</tr>
<tr>
<td rowspan="16">Applies to whole derivation</td>
<td><code>emma:signal</code></td>
</tr>
<tr>
<td><code><span>emma:signal-size</span></code></td>
</tr>
<tr>
<td><code><span>emma:dialog-turn</span></code></td>
</tr>
<tr>
<td><code>emma:source</code></td>
</tr>
<tr>
<td><code>emma:medium</code></td>
</tr>
<tr>
<td><code>emma:mode</code></td>
</tr>
<tr>
<td><code>emma:function</code></td>
</tr>
<tr>
<td><code>emma:verbal</code></td>
</tr>
<tr>
<td><code>emma:lang</code></td>
</tr>
<tr>
<td><code>emma:tokens</code></td>
</tr>
<tr>
<td><code>emma:start</code></td>
</tr>
<tr>
<td><code>emma:end</code></td>
</tr>
<tr>
<td><code>emma:time-ref-uri</code></td>
</tr>
<tr>
<td><code>emma:time-ref-anchor-point</code></td>
</tr>
<tr>
<td><code>emma:offset-to-start</code></td>
</tr>
<tr>
<td><code>emma:duration</code></td>
</tr>
<tr>
<td rowspan="2">Specified at each stage of derivation</td>
<td><code>emma:derived-from</code></td>
</tr>
<tr>
<td><code>emma:process</code></td>
</tr>
<tr>
<td rowspan="6">May be respecified</td>
<td><code>emma:confidence</code></td>
</tr>
<tr>
<td><code>emma:cost</code></td>
</tr>
<tr>
<td><code>emma:grammar-ref</code></td>
</tr>
<tr>
<td><code>emma:model-ref</code></td>
</tr>
<tr>
<td><code>emma:no-input</code></td>
</tr>
<tr>
<td><code>emma:uninterpreted</code></td>
</tr>
</tbody>
</table>
<p>One potential problem with this annotation scoping mechanism is
that earlier annotations could be lost if earlier stages of a
derivation were dropped in order to reduce message size. This
problem can be overcome by considering annotation scope at the
point where earlier derivation stages are discarded and populating
the final interpretation in the derivation with all of the
annotations which it could inherit. For example, if the
<code>raw</code> and <code>better</code> stages were dropped the
resulting EMMA document would be:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="best"
      emma:start="1087995961542"
      emma:end="1087995963542"
      emma:process="http://example.com/myrefresolution1.xml"
      emma:source="http://example.com/microphone/NC-61"
      emma:signal="http://example.com/signals/sg23.wav"
      emma:confidence="0.8"
      emma:medium="acoustic"
      emma:mode="voice"
      emma:function="dialog"
      emma:verbal="true"
      emma:tokens="from boston to denver tomorrow"
      emma:lang="en-US"&gt;
    &lt;emma:derived-from resource="#better" composite="false"/&gt;
    &lt;origin&gt;Boston&lt;/origin&gt;
    &lt;destination&gt;Denver&lt;/destination&gt;
    &lt;date&gt;03152003&lt;/date&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>Annotations on an <code>emma:one-of</code> element are assumed
to apply to all of the container elements within the
<code>emma:one-of</code>.</p>
<p>If <code>emma:one-of</code> appears with another
<code>emma:one-of</code> then annotations on the parent
<code>emma:one-of</code> are assumed to apply to the children of
the child <code>emma:one-of</code>.</p>
<p>Annotations on <code>emma:group</code> or
<code>emma:sequence</code> do not apply to their child
elements.</p>
<h2 id="s5">5. Conformance</h2>
<p>The contents of this section are normative.</p>
<h3 id="s5.1">5.1 Conforming EMMA Documents</h3>
<p>A document is a Conforming EMMA Document if it meets both the
following conditions:</p>
<ul>
<li>It is a well-formed XML document [<a href="#XML">XML</a>]
conforming to Namespaces in XML [<a href="#XMLNS">XMLNS</a>].</li>
<li>It adheres to the specification described in this document
(EMMA Specification) including the constraints expressed in the
Schema (see <a href="#appA">Appendix A</a>) and having an XML
Prolog and root element as specified in <a href="#s3.1">Section
3.1</a>.</li>
</ul>
<p>The EMMA specification and these conformance criteria provide no
designated size limits on any aspect of EMMA documents. There are
no maximum values on the number of elements, the amount of
character data, or the number of characters in attribute
values.</p>
<p><span>Within this specification, the term URI refers to a
Universal Resource Identifier as defined in [<a href="#RFC3986">RFC3986</a>] and extended in [<a href="#RFC3987">RFC3987</a>] with the new name IRI. The term URI has
been retained in preference to IRI to avoid introducing new names
for concepts such as "Base URI" that are defined or referenced
across the whole family of XML specifications</span>.</p>
<h3 id="s5.2">5.2 Using EMMA with other Namespaces</h3>
<p>The EMMA namespace is intended to be used with other XML
namespaces as per the Namespaces in XML Recommendation [<a href="#XMLNS">XMLNS</a>]. Future work by W3C is expected to address ways
to specify conformance for documents involving multiple
namespaces.</p>
<h3 id="s5.3">5.3 Conforming EMMA Processors</h3>
<p>A EMMA processor is a program that can process and/or generate
Conforming EMMA documents.</p>
<p>In a Conforming EMMA Processor, the XML parser MUST be able to
parse and process all XML constructs defined by XML 1.1 [<a href="#XML">XML</a>] and Namespaces in XML [<a href="#XMLNS">XMLNS</a>].
It is not required that a Conforming EMMA Processor uses a
validating XML parser.</p>
<p>A Conforming EMMA Processor MUST correctly understand and apply
the semantics of each markup element or attribute as described by
this document.</p>
<p>There is, however, no conformance requirement with respect to
performance characteristics of the EMMA Processor. For instance, no
statement is required regarding the accuracy, speed or other
characteristics of output produced by the processor. No statement
is made regarding the size of input that a EMMA Processor is
required to support.</p>
<h2 id="s6">6. Integration of EMMA with other Standards Related to Output</h2>
<p>This section is Informative</p>
<p>EMMA can be used with other standards that provide metadata about system output, for example, WAI-ARIA and TTML as discussed below.</p>
<h3 id=6.1>6.1 WAI-ARIA (Accessible Rich Internet Applications)</h3>
<p>The ARIA <a href="#aria">[WAI-ARIA</a>] standard defines a   way to make Web content and Web applications more accessible to   people with disabilities, in part by providing a vocabulary for describing the functions of controls in a relatively abstract way that relates to the purpose of the control. Thus, assistive technology can use ARIA tags to provide a functionally equivalent presentation of a control to a user. EMMA output can be useful in this context because it can initially be represented at an abstract way and then can be progressively refined through further stages of processing (multimodal fission) to eventually produce an actual, contextually appropriate, presentation that accommodates the user's preferences. For example, if an application needs to warn the user about an invalid input, the warning can be realized in a variety of ways, such as an alert popup, a spoken message, or a vibration, but the underlying semantics of the message will be the same. This example shows the abstract, high level EMMA message.</p>
<pre class="example">&lt;emma:output id=&quot;output1&quot; role=&quot;alert&quot;&gt;    
  &lt;item aria-invalid=&quot;true&quot;&gt;phone number&lt;/item&gt;    
  &lt;warning&gt;invalid format&lt;/warning&gt; 
&lt;/emma:output&gt;</pre>
<p>As processing proceeds, the decision would be made as to how the messge would be presented, either by assistive technology or by other means (for example, the user has selected &quot;voice output&quot; as a preference). If voice output is selected, and the message is to be spoken by text-to-speech software, the final EMMA message would look like this. </p>
<pre class="example">&lt;emma:emma version=&quot;2.0&quot;<br />  &lt;emma:output id=&quot;tts1&quot;<br />    emma:medium=&quot;acoustic&quot;
    emma:mode=&quot;voice&quot;
    emma:output-format=&quot;application/ssml+xml&quot;
    emma:lang=&quot;en-US&quot;
    emma:process=&quot;http://example.com/nlg&quot;&gt;
    emma:confidence=&quot;0.8&quot;
    role=&quot;alert&quot;&gt;
    &lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot; xml:lang=&quot;en-US&quot;&gt;
   The phone number format is not valid.
    &lt;/speak&gt;
  &lt;/emma:output&gt;
&lt;emma:emma&gt;</pre>
<h3>6.2 Integration of EMMA with TTML (Timed Text Markup Language)</h3>
<p>Timed Text Markup Language <a href="#TTML">[TTML]</a> refers to formats used for the          representation of text synchronized with other timed media, like audio          and video. An important use case, for example, is captioning video. Timed text could be embedded in EMMA for use in presenting system output which consists of synchronized text and video. </p>
<pre class="example">&lt;emma:emma version=&quot;1.1&quot;<br />    xmlns:emma=&quot;http://www.w3.org/2003/04/emma&quot;<br />    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://www.w3.org/2003/04/emma<br />    http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd&quot;<br />    xmlns=&quot;http://www.example.com/example&quot;&gt;<br />&lt;emma:one-of disjunction-type=&quot;recognition&quot; start=&quot;12457990&quot; end=&quot;12457995&quot;<br />emma:medium=&quot;visual&quot; emma:mode=&quot;ttml&quot;&gt;<br />     &lt;emma:one-of&gt;<br />       &lt;emma:output&gt;<br />          &lt;tt xml:lang=&quot;en&quot; xmlns=&quot;http://www.w3.org/ns/ttml&quot; xmlns:ttm=&quot;<br />http://www.w3.org/ns/ttml#metadata&quot;&gt;<br />  &lt;head&gt;<br />    &lt;ttm:agent xml:id=&quot;bond&quot; type=&quot;character&quot;&gt;<br />      &lt;ttm:name type=&quot;family&quot;&gt;Bond&lt;/ttm:name&gt;<br />      &lt;ttm:name type=&quot;given&quot;&gt;James&lt;/ttm:name&gt;<br />      &lt;ttm:name type=&quot;alias&quot;&gt;007&lt;/ttm:name&gt;<br />    &lt;/ttm:agent&gt;<br />    &lt;ttm:agent xml:id=&quot;No&quot; type=&quot;character&quot;&gt;<br />      &lt;ttm:name type=&quot;family&quot;&gt;No&lt;/ttm:name&gt;<br />      &lt;ttm:name type=&quot;given&quot;&gt;Dr. Julius No&lt;/ttm:name&gt;<br />      &lt;ttm:name type=&quot;alias&quot;&gt;Dr. No&lt;/ttm:name&gt;<br />    &lt;/ttm:agent&gt;<br />     &lt;layout&gt;<br />      &lt;region xml:id=&quot;r1&quot;&gt;<br />        &lt;style tts:origin=&quot;10px 100px&quot;/&gt;<br />        &lt;style tts:extent=&quot;620px 96px&quot;/&gt;<br />        &lt;style tts:fontSize=&quot;40px&quot;/&gt;<br />        &lt;style tts:fontWeight=&quot;bold&quot;/&gt;<br />        &lt;style tts:backgroundColor=&quot;black&quot;/&gt;<br />        &lt;style tts:color=&quot;red&quot;/&gt;<br />        &lt;style tts:textAlign=&quot;center&quot;/&gt;<br />        &lt;style tts:displayAlign=&quot;center&quot;/&gt;<br />      &lt;/region&gt;<br />      &lt;region xml:id=&quot;r2&quot;&gt;<br />        &lt;style tts:origin=&quot;10px 300px&quot;/&gt;<br />        &lt;style tts:fontWeight=&quot;bold&quot;/&gt;<br />        &lt;style tts:backgroundColor=&quot;black&quot;/&gt;<br />        &lt;style tts:color=&quot;yellow&quot;/&gt;<br />      &lt;/region&gt;<br />    &lt;/layout&gt;<br />  &lt;/head&gt;<br />   &lt;body xml:id=&quot;b1&quot;&gt;<br />    &lt;div xml:id=&quot;d1&quot; begin=&quot;0s&quot; dur=&quot;2s&quot;&gt;<br />      &lt;p xml:id=&quot;p1&quot; region=&quot;r1&quot; ttm:agent=&quot;bond&quot;&gt;Text 1&lt;/p&gt;<br />      &lt;p xml:id=&quot;p2&quot; region=&quot;r2&quot; ttm:agent=&quot;Dr. No&quot;&gt;Text 2&lt;/p&gt;<br />    &lt;/div&gt;<br />    &lt;div xml:id=&quot;d2&quot; begin=&quot;1s&quot; dur=&quot;2s&quot;&gt;<br />      &lt;p xml:id=&quot;p3&quot; region=&quot;r2&quot; ttm:agent=&quot;No&quot;&gt;Text 3&lt;/p&gt;<br />      &lt;p xml:id=&quot;p4&quot; region=&quot;r1&quot; ttm:agent=&quot;bond&quot;&gt;Text 4&lt;/p&gt;<br />    &lt;/div&gt;<br />  &lt;/body&gt;<br />&lt;/tt&gt;<br />       &lt;/emma:output&gt;<br />     &lt;/emma:one-of&gt;<br />  &lt;/emma:one-of&gt;<br />&lt;/emma:emma&gt;<br />
</pre>
<h2>Appendices</h2>
<h3 id="appA">Appendix A. XML and <span>RELAX NG</span>
schemata</h3>
<p>This section is Normative.</p>
<p>This section defines the formal syntax for EMMA documents in
terms of a normative XML Schema.</p>
<p>The schema provided here is for the EMMA 1.0 Recommendation. No schema exists as of yet for the EMMA <span class="remove">1.1 </span>2.0 Working Draft as it is a work in progress.</p>
<p>There are both an XML Schema and <span>RELAX NG</span> Schema
  for the EMMA markup. The latest version of the XML Schema for EMMA
  is available at <a href="http://www.w3.org/TR/emma/emma.xsd">http://www.w3.org/TR/emma/emma.xsd</a>
  and the RELAX NG Schema can be found at <a href="http://www.w3.org/TR/emma/emma.rng">http://www.w3.org/TR/emma/emma.rng</a>.</p>
<p>For stability it is RECOMMENDED that you use the dated URI
available at <a href="http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd">http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd</a>
and <a href="http://www.w3.org/TR/2009/REC-emma-20090210/emma.rng">http://www.w3.org/TR/2009/REC-emma-20090210/emma.rng</a>.</p>
<h2 id="appB">Appendix B. MIME type</h2>
<p>This section is <span>N</span>ormative.</p>
<p>This appendix registers a new MIME media type,
"<code>application/emma+xml</code>".</p>

<p>The "<code>application/emma+xml</code>" media type is
registered with IANA at
<a href="http://www.iana.org/assignments/media-types/application/">
http://www.iana.org/assignments/media-types/application/</a>.
</p>


<div>
<h3 id="media-type-registration">B.1 Registration of MIME media
type application/emma+xml</h3>
<dl>
<dt>MIME media type name:</dt>
<dd>
<p><code>application</code></p>
</dd>
<dt>MIME subtype name:</dt>
<dd>
<p><code>emma+xml</code></p>
</dd>
<dt>Required parameters:</dt>
<dd>
<p>None.</p>
</dd>
<dt>Optional parameters:</dt>
<dd>
<dl>
<dt><code>charset</code></dt>
<dd>
<p>This parameter has identical semantics to the
<code>charset</code> parameter of the <code>application/xml</code>
media type as specified in [<a href="#RFC3023">RFC3023</a>] or its
successor.</p>
</dd>
</dl>
</dd>
<dt>Encoding considerations:</dt>
<dd>
<p>By virtue of EMMA content being XML, it has the same
considerations when sent as "<code>application/emma+xml</code>"as
does XML. See RFC 3023 (or its successor), section 3.2.</p>
</dd>
<dt>Security considerations:</dt>
<dd>
<p>Several features of EMMA require dereferencing arbitrary URIs.
Implementers are advised to heed the security issues of [<a href="#RFC3986">RFC3986</a>] section 7.</p>
<p>In addition, because of the extensibility features for EMMA, it
is possible that "<code>application/emma+xml</code>" will describe
content that has security implications beyond those described here.
However, if the processor follows only the normative semantics of
this specification, this content will be ignored. Only in the case
where the processor recognizes and processes the additional
content, or where further processing of that content is dispatched
to other processors, would security issues potentially arise. And
in that case, they would fall outside the domain of this
registration document.</p>
</dd>
<dt>Interoperability considerations:</dt>
<dd>
<p>This specification describes processing semantics that dictate
the required behavior for dealing with, among other things,
unrecognized elements.</p>
<p>Because EMMA is extensible, conformant
"<code>application/emma+xml</code>" processors MAY expect that
content received is well-formed XML, but processors SHOULD NOT
assume that the content is valid EMMA or expect to recognize all of
the elements and attributes in the document.</p>
</dd>
<dt>Published specification:</dt>
<dd>
<p>
This media type registration is extracted from Appendix B of the
"<a href="http://www.w3.org/TR/emma/">EMMA: Extensible MultiModal Annotation markup language</a>"
specification.
</p>
</dd>
<dt>Additional information:</dt>
<dd>
<dl>
<dt>Magic number(s):</dt>
<dd>
<p>There is no single initial octet sequence that is always present
in EMMA documents.</p>
</dd>
<dt>File extension(s):</dt>
<dd>
<p>EMMA documents are most often identified with the extensions
"<code>.emma</code>"<!-- or "<code>.mma</code>"-->.</p>
</dd>
<dt>Macintosh File Type Code(s):</dt>
<dd>
<p>TEXT</p>
</dd>
</dl>
</dd>
<dt>Person &amp; email address to contact for further
information:</dt>
<dd>
<p>Kazuyuki Ashimura, &lt;<a href="mailto:ashimura@w3.org">ashimura@w3.org</a>&gt;.</p>
</dd>
<dt>Intended usage:</dt>
<dd>
<p>COMMON</p>
</dd>
<dt>Author/Change controller:</dt>
<dd>
<p>The EMMA specification is a work product of the World Wide Web
Consortium's Multimodal Interaction Working Group. The W3C has
change control over these specifications.</p>
</dd>
</dl>
</div>
<h2 id="appC">Appendix C. <code>emma:hook</code> and SRGS</h2>
<p>This section is <span>I</span>nformative.</p>
<div>
<p>One of the most powerful aspects of multimodal interfaces is
their ability to provide support for user inputs which are
distributed over the available input modes. These <b>composite</b>
inputs are contributions made by the user within a single turn
which have component parts in different modes. For example, the
user might say "zoom in here" in the speech mode while drawing an
area on a graphical display in the ink mode. One of the central
motivating factors for this kind of input is that different kinds
of communicative content are best suited to different input modes.
In the example of a user drawing an area on a map and saying "zoom
in here", the zoom command is easiest to provide in speech but the
spatial information, the specific area, is easier to provide in
ink.</p>
<p>Enabling composite multimodality is critical in ensuring that
multimodal systems support more natural and effective interaction
for users. In order to support composite inputs, a multimodal
architecture must provide some kind of multimodal integration
mechanism. In the W3C Multimodal Interaction Framework
<span>[<a href="#MMIF">MMI Framework</a>]</span>, multimodal
integration can be handled by an integration component which
follows the application of speech understanding and other kinds of
interpretation procedures for individual modes.</p>
<p>Given the broad range of different techniques being employed for
multimodal integration and the extent to which this is an ongoing
research problem, standardization of the specific method or
algorithm used for multimodal integration is not appropriate at
this time. In order to facilitate the development and
inter-operation of different multimodal integration mechanisms EMMA
provides markup language enabling application independent
specification of elements in the application markup where content
from another mode needs to be integrated. These representation
'hooks' can then be used by different kinds of multimodal
integration components and algorithms to drive the process of
multimodal integration. In the processing of a composite multimodal
input, the result of applying a mode-specific interpretation
component to each of the individual modes will be EMMA markup
describing the possible interpretation of that input.</p>
</div>
<p>One way to build an EMMA representation of a spoken input such
as "zoom in here" is to use grammar rules in the W3C Speech
Recognition Grammar Specification [<a href="#SRGS">SRGS</a>] using
the Semantic Interpretation <span>[<a href="#SI">SISR</a>]</span>
tags to build the application semantics with the
<code>emma:hook</code> attribute. In this approach <span>[<a href="#ECMASCRIPT">ECMAScript</a>]</span> is specified in order to build
up an object representing the semantics. The resulting ECMAScript
object is then translated to XML.</p>
<p>For our example case of "zoom in here". The following SRGS rule
could be used. The <span>Semantic Interpretation for Speech
Recognition</span> specification <span>[<a href="#SI">SISR</a>]</span> provides a reserved property
<b>_nsprefix</b> for indicating the namespace to be used with an
attribute.</p>
<pre class="example">&lt;rule id="zoom"&gt;
  zoom in here
  &lt;tag&gt;
    $.command = new Object();
    $.command.action = "zoom";
    $.command.location = new Object();
    $.command.location._attributes = new Object();
    $.command.location._attributes.hook = new Object();
    $.command.location._attributes.hook._nsprefix = "emma";
    $.command.location._attributes.hook._value = "ink";
    $.command.location.type = "area";
  &lt;/tag&gt;
&lt;/rule&gt;
</pre>
<p>Application of this rule will result in the following ECMAScript
object being built.</p>
<pre class="example">command: {
      action: "zoom"
      location: {
        _attributes: {
           hook: {
             _nsprefix: "emma"
             _value: "ink"
             }
           }
        type: "area"
      }
}</pre>
<p><a href="#SI">SI</a> processing in an XML environment would
generate the following document:</p>
<pre class="example">&lt;command&gt;
  &lt;action&gt;zoom&lt;/action&gt;
  &lt;location emma:hook="ink"&gt;
     &lt;type&gt;area&lt;/type&gt;
  &lt;/location&gt;
&lt;/command&gt;
</pre>
<p>This XML fragment might then appear within an EMMA document as
follows:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="voice1"
      emma:medium="acoustic"
      emma:mode="voice"&gt;
    &lt;command&gt;
      &lt;action&gt;zoom&lt;/action&gt;
      &lt;location emma:hook="ink"&gt;
         &lt;type&gt;area&lt;/type&gt;
      &lt;/location&gt;
    &lt;/command&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The <code>emma:hook</code> annotation indicates that this speech
input needs to be combined with ink input such as the
following:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation id="pen1"
      emma:medium="tactile"
      emma:mode="ink"&gt;
    &lt;location&gt;
      &lt;type&gt;area&lt;/type&gt;
      &lt;points&gt;42.1345 -37.128 42.1346 -37.120 ... &lt;/points&gt;
    &lt;/location&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;</pre>
<p>This representation could be generated by a pen modality
component performing gesture recognition and interpretation. The
input to the component would be an <span>Ink Markup Language</span>
specification <span>[<a href="#InkML">INKML</a>]</span> of the ink
trace and the output would be the EMMA document above.</p>
<p>The combination will result in the following EMMA document for
the combined speech and pen multimodal input.</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation
      emma:medium="acoustic tactile" 
      emma:mode="<span>voice ink</span>"
      emma:process="http://example.com/myintegrator.xml"&gt;
    &lt;emma:derived-from resource="<span>http://example.com/voice1.emma/</span>#voice1" composite="true"/&gt;
    &lt;emma:derived-from resource="<span>http://example.com/pen1.emma/</span>#pen1" composite="true"/&gt;
    &lt;command&gt;
       &lt;action&gt;zoom&lt;/action&gt;
       &lt;location&gt;
         &lt;type&gt;area&lt;/type&gt;
         &lt;points&gt;42.1345 -37.128 42.1346 -37.120 ... &lt;/points&gt;
        &lt;/location&gt;
     &lt;/command&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<div>
<p>There are two components to the process of integrating these two
pieces of semantic markup. The first is to ensure that the two are
compatible; that is, that no semantic constraints are violated. The
second is to fuse the content from the two sources. In our example,
the <code>&lt;type&gt;area&lt;/type&gt;</code> element is intended
to indicate that this speech command requires integration with an
area gesture rather than, for example, a line gesture, which would
have the subelement <code>&lt;type&gt;line&lt;/type&gt;</code>.
This constraint needs to be enforced by whatever mechanism is
responsible for multimodal integration.</p>
<p>Many different techniques could be used for achieving this
integration of the semantic interpretation of the pen input, a
<code>&lt;location&gt;</code> element, with the corresponding
<code>&lt;location&gt;</code> element in the speech. The
<span><code>emma:hook</code></span> simply serves to indicate the
existence of this relationship.</p>
<p>One way to achieve both the compatibility checking and fusion of
content from the two modes is to use a well-defined general purpose
matching mechanism such as unification. <span>Graph unification
[</span><a href="#graphunification">Graph
unification</a><span>]</span> is a mathematical operation defined
over directed acylic graphs which captures both of the components
of integration in a single operation: the applications of the
semantic constraints and the fusing of content. One possible
semantics for the <code>emma:hook</code> markup indicates that
content from the required mode needs to be unified with that
position in the application semantics. In order to unify, two
elements must not have any conflicting values for subelements or
attributes. This procedure can be defined recursively so that
elements within the subelements must also not clash and so on. The
result of unification is the union of all of the elements and
attributes of the two elements that are being unified.</p>
<p>In addition to the unification operation, in the resulting
<code>emma:interpretation</code> the <code>emma:hook</code>
attribute needs to be removed and the <code>emma:mode</code>
attribute changed to <span>the list of the modes of the individual
inputs</span> <span>, e.g. <code>"voice ink"</code></span>.</p>
<p>Instead of the unification operation, for a specific application
semantics, integration could be achieved using some other algorithm
or script. The benefit of using the unification semantics for
<code>emma:hook</code> is that it provides a general purpose
mechanism for checking the compatibility of elements and fusing
them, whatever the specific elements are in the application
specific semantic representation.</p>
<p>The benefit of using the <code>emma:hook</code> annotation for
authors is that it provides an application independent method for
indicating where integration with content from another mode is
required. If a general purpose integration mechanism is used, such
as the unification approach described above, authors should be able
to use the same integration mechanism for a range of different
applications without having to change the integration rules or
logic. For each application the speech grammar rules [<a href="#SRGS">SRGS</a>] need to assign <code>emma:hook</code> to the
appropriate elements in the semantic representation of the speech.
The general purpose multimodal integration mechanism will use the
<code>emma:hook</code> annotations in order to determine where to
add in content from other modes. Another benefit of the
<code>emma:hook</code> mechanism is that it facilitates
interoperability among different multimodal integration components,
so long as they are all general purpose and utilize
<code>emma:hook</code> in order to determine where to integrate
content.</p>
<p>The following provides a more detailed example of the use of the
<code>emma:hook</code> annotation. In this example, spoken input is
combined with two <span>ink</span> gestures. The semantic
representation assigned to the spoken input "send this file to
this" indicates two locations where content is required from ink
input using <code>emma:hook="ink"</code>:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:interpretation<span> id="voice2"
      emma:medium="acoustic"
      emma:mode="voice"
      emma:tokens="send this file to this"
      emma:start="1087995961500"
      emma:end="1087995963542"</span>&gt;
    &lt;command&gt;
      &lt;action&gt;send&lt;/action&gt;
        &lt;arg1&gt;
          &lt;object emma:hook="ink"&gt;
            &lt;type&gt;file&lt;/type&gt;
            &lt;number&gt;1&lt;/number&gt;
          &lt;/object&gt;
        &lt;/arg1&gt;
       &lt;arg2&gt;
         &lt;object emma:hook="ink"&gt;
           &lt;number&gt;1&lt;/number&gt;
         &lt;/object&gt;
       &lt;/arg2&gt;
    &lt;/command&gt;
  &lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre>
<p>The user gesturing on the two locations on the display can be
represented using <code>emma:sequence</code>:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
  &lt;emma:sequence<span> id="ink2"</span>&gt;
    &lt;emma:interpretation <span>emma:start="1087995960500"
      emma:end="1087995960900"
      emma:medium="tactile"
      emma:mode="ink"</span>&gt;
      &lt;object&gt;
       &lt;type&gt;file&lt;/type&gt;
       &lt;number&gt;1&lt;/number&gt;
       &lt;id&gt;test.pdf&lt;/id&gt;
      &lt;object&gt;
    &lt;/emma:interpretation&gt;
    &lt;emma:interpretation <span>emma:start="1087995961000"
      emma:end="1087995961100"
      emma:medium="tactile"
      emma:mode="ink"</span>&gt;
      &lt;object&gt;
        &lt;type&gt;printer&lt;/type&gt;
        &lt;number&gt;1&lt;/number&gt;
        &lt;id&gt;lpt1&lt;/id&gt;
      &lt;object&gt;
    &lt;/emma:interpretation&gt;
  &lt;/emma:sequence&gt;
&lt;/emma:emma&gt;
</pre>
<p>A general purpose unification-based multimodal integration
algorithm could use the <code>emma:hook</code> annotation as
follows. It identifies the elements marked with
<code>emma:hook</code> in document order. For each of those in
turn, it attempts to unify the element with the corresponding
element in order in the <code>emma:sequence</code>. Since none of
the subelements conflict, the unification goes through and as a
result, we have the following EMMA for the composite result:</p>
<pre class="example">&lt;emma:emma version="1.1"
    xmlns:emma="http://www.w3.org/2003/04/emma"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.w3.org/2003/04/emma
     http://www.w3.org/TR/2009/REC-emma-20090210/emma.xsd"
    xmlns="http://www.example.com/example"&gt;
&lt;emma:interpretation<span> id="multimodal2"
      emma:medium="acoustic tactile"
      emma:mode="voice ink"
      emma:tokens="send this file to this"
      emma:process="http://example.com/myintegration.xml"
      emma:start="1087995960500"
      emma:end="1087995963542"</span>&gt;
  &lt;emma:derived-from resource="<span>http://example.com/voice2.emma/</span>#voice2" composite="true"/&gt;
  &lt;emma:derived-from resource="<span>http://example.com/ink2.emma/</span>#ink2" composite="true"/&gt;
  &lt;command&gt;
   &lt;action&gt;send&lt;/action&gt;
    &lt;arg1&gt;
     &lt;object&gt;
       &lt;type&gt;file&lt;/type&gt;
       &lt;number&gt;1&lt;/number&gt;
        &lt;id&gt;test.pdf&lt;/id&gt;
     &lt;/object&gt;
    &lt;/arg1&gt;
    &lt;arg2&gt;
     &lt;object&gt;
       &lt;type&gt;printer&lt;/type&gt;
        &lt;number&gt;1&lt;/number&gt;
       &lt;id&gt;lpt1&lt;/id&gt;
     &lt;/object&gt;
    &lt;/arg2&gt;
  &lt;/command&gt;
&lt;/emma:interpretation&gt;
&lt;/emma:emma&gt;
</pre></div>
<h2 id="appD">Appendix D. EMMA event interface</h2>
<p>This section is <span>I</span>nformative.</p>
<p>The W3C Document Object Model [<a href="#DOM">DOM</a>] defines
platform and language neutral interfaces that gives programs and
scripts the means to dynamically access and update the content,
structure and style of documents. DOM Events define a generic event
system which allows registration of event handlers, describes event
flow through a tree structure, and provides basic contextual
information for each event.</p>
<p>This section of the EMMA specification extends the DOM Event
interface for use with events that describe interpreted user input
in terms of a DOM Node for an EMMA document.</p>
<pre class="example">// File: emma.idl

#ifndef _EMMA_IDL_
#define _EMMA_IDL_

#include "dom.idl"#include "views.idl"#include "events.idl"
#pragma prefix "dom.w3c.org"module emma
{
  typedef dom::DOMString DOMString;
  typedef dom::Node Node;

  interface EMMAEvent : events::UIEvent {
    readonly attribute dom::Node  node;
    void               initEMMAEvent(in DOMString typeArg,
                                   in boolean canBubbleArg,
                                   in boolean cancelableArg,
                                   in Node node);
  };
};

#endif // _EMMA_IDL_
</pre>
<h2 id="appE">Appendix E. References</h2>
<h3 id="appE1">E.1 Normative references</h3>
<dl>
<dt id="BCP47">BCP47</dt>
<dd>A. Phillips and M. Davis, editors. <a href="http://www.rfc-editor.org/rfc/bcp/bcp47.txt">Tags for the
Identification of Languages</a>, IETF, September 2006.</dd>
<dt id="RFC3023">RFC3023</dt>
<dd>M. Murata et al.<span>,</span> editors. <a href="http://www.ietf.org/rfc/rfc3023.txt">XML Media Types</a>. IETF RFC
3023<span>, January 2001</span>.</dd>
<dt id="RFC2046">RFC2046</dt>
<dd>N. Freed and N. Borenstein<span>,</span> editors. <a href="http://www.ietf.org/rfc/rfc2046.txt">Multipurpose Internet Mail
Extensions (MIME) Part Two: Media Types</a>. IETF RFC 2046<span>,
November 1996</span>.</dd>
<dt><a id="ref-rfc2119" name="ref-rfc2119" shape="rect">RFC2119</a></dt>
<dd>S. Bradner, <span>e</span>ditor. <a href="http://www.ietf.org/rfc/rfc2119.txt">Key words for use in RFCs to
Indicate Requirement Levels</a>, IETF <span>RFC 2119</span>, March
1997.</dd>
<dt id="RFC3986">RFC3986</dt>
<dd>T. Berners-Lee et al.<span>,</span> editors. <a href="http://www.ietf.org/rfc/rfc3986.txt">Uniform Resource Identifier
(URI): Generic Syntax</a>. IETF RFC 3986<span>, January
2005</span>.</dd>
<dt id="RFC3987">RFC3987</dt>
<dd>M. Duerst and M. Suignard<span>,</span> editors. <a href="http://www.ietf.org/rfc/rfc3987.txt">Internationalized Resource
Identifiers (IRIs)</a>. IETF RFC 3987<span>, January
2005</span>.</dd>
<dt id="XML">XML</dt>
<dd>Tim Bray <span>et al.,</span> editors. <a href="http://www.w3.org/TR/2004/REC-xml11-20040204/">Extensible Markup
Language (XML) 1.1</a>. World Wide Web Consortium, <span>W3C
Recommendation,</span> 2004.</dd>
<dt id="XMLNS">XMLNS</dt>
<dd>Tim Bray <span>et al.</span>, editors<span>.</span> <a href="http://www.w3.org/TR/xml-names11/">Namespaces in XML 1.1</a>,
World Wide Web Consortium, <span>W3C Recommendation,</span>
200<span>6</span>.</dd>
<dt id="XSD1">XML Schema Structures</dt>
<dd>Henry S. Thompson <span>et al.</span>, editors. <a href="http://www.w3.org/TR/xmlschema-1/">XML Schema Part 1: Structures
Second Edition</a>, World Wide Web Consortium<span>, W3C
Recommendation</span>, 2004.</dd>
<dt id="XSD2">XML Schema Datatypes</dt>
<dd>Paul V. Biron <span>and</span> Ashok Malhotra, editors.
<a href="http://www.w3.org/TR/xmlschema-2/">XML Schema Part 2:
Datatypes Second Edition</a>, World Wide Web Consortium, <span>W3C
Recommendation,</span> 2004.</dd>
</dl>
<h3 id="appE2">E.2 Informative references</h3>
<dl>
<dt id="DOM">DOM</dt>
<dd><a href="http://www.w3.org/DOM/">Document Object Model</a>,
World Wide Web Consortium, 2005.</dd>
<dt id="ECMASCRIPT">ECMAScript</dt>
<dd><a href="http://www.ecma-international.org/publications/files/ECMA-ST/Ecma-262.pdf">
ECMAScript</a></dd>
<dt id="InkML">INKML</dt>
<dd>Stephen M. Watt and Tom Underhill, editors. <a href="http://www.w3.org/TR/InkML/">Ink Markup Language (InkML)</a>,
World Wide Web Consortium, W3C Recommendation 2011.</dd>
<dt id="json">JSON</dt>
<dd>	D. Crockford. <a href="http://tools.ietf.org/html/rfc4627">The application/json Media Type for JavaScript Object Notation</a>. RFC 4627. IETF Network Working Group Memo.</dd>
<dt id="SI">SI<span>SR</span></dt>
<dd>Luc Van Tichelen <span>and Dave Burke</span>,
editor<span>s</span>. <a href="http://www.w3.org/TR/semantic-interpretation/">Semantic
Interpretation for Speech Recognition</a>, World Wide Web
Consortium, <span>W3C Proposed Recommendation, 2007</span>.</dd>
<dt id="SRGS">SRGS</dt>
<dd>Andrew Hunt, Scott McGlashan, editors. <a href="http://www.w3.org/TR/speech-grammar/">Speech Recognition Grammar
Specification Version 1.0</a>, World Wide Web Consortium<span>, W3C
Recommendation,</span> 2004.</dd>
<dt id="XFORMS">XFORMS</dt>
<dd><span>John M. Boyer et al., editors.</span> <a href="http://www.w3.org/TR/2006/REC-xforms-20060314/">XForms <span>1.0
(Second Edition)</span></a>, World Wide Web Consortium, <span>W3C
Recommendation,</span> 2006.</dd>
<dt id="RELAXNG">RELAX-NG</dt>
<dd><span>James Clark and Makoto Murata, editors.</span> <a href="http://www.oasis-open.org/committees/relax-ng/spec-20011203.html"><span>
RELAX NG Specification</span></a><span>, OASIS, Committee
Specification, 2001.</span></dd>
<dt id="EMMAreqs">EMMA Requirements</dt>
<dd>Stephane H. Maes and Stephen Potter, editors. <a href="http://www.w3.org/TR/EMMAreqs/">Requirements for EMMA</a>, World
Wide Web Consortium, <span>W3C Note,</span> 2003<span>.</span></dd>
<dt id="graphunification">Graph Unification</dt>
<dd>Bob Carpenter. <cite>The Logic of Typed Feature
Structures</cite>, Cambridge Tracts in Theoretical Computer Science
32, Cambridge University Press, 1992.</dd>
<dd>Kevin Knight. <cite>Unification: A Multidisciplinary
Survey</cite>, ACM Computing Surveys, 21(1), 1989.</dd>
<dd>Michael Johnston. <cite>Unification-based Multimodal
Parsing</cite>, Proceedings of Association for Computational
Linguistics, pp. 624-630, 1998.</dd>
<dt id="MMIF">MMI Framework</dt>
<dd>James A. Larson, T.V. Raman and Dave Raggett, editors. <a href="http://www.w3.org/TR/mmi-framework/">W3C Multimodal Interaction
Framework</a>, World Wide Web Consortium<span>, W3C Note</span>,
2003<span>.</span></dd>
<dt id="MMIreqs">MMI Requirements</dt>
<dd>Stephane H. Maes and Vijay Saraswat, editors. <a href="http://www.w3.org/TR/mmi-reqs/">Multimodal Interaction
Requirements</a>, World Wide Web Consortium<span>, W3C Note</span>,
2003<span>.</span></dd>
<dt id="emotionml">Emotion ML</dt>
<dd>Mark Schroeder, editor. <a href="http://www.w3.org/TR/emotionml/">
Emotion Markup Language (Emotion ML ) 1.0.</a> World Wide Web Consortium, W3C Last Call Working Draft, 2011.</dd>
<dt id="emma_use_cases">EMMA Use Cases</dt>
<dd>Michael Johnston, editor. <a href"http:="" www.w3.org="" tr="" emma-usecases="" "=""> Use Cases for Possible Future EMMA Features</a> World Wide Web Consortium, W3C Note, 2009.</dd>
  <dt><a id="ref-geo">[Geolocation]</a></dt>
  <dd><a href="http://www.w3.org/TR/geolocation-API/">Geolocation API Specification
    World Wide Web Consortium Proposed Recommendation 10 May 2012.</a> See   http://www.w3.org/TR/geolocation-API/ </dd>
  <dt><a name="TTML" id="TTML"></a>Timed Text Markup Language</dt>
  <dd><a href="http://www.w3.org/TR/ttml1/">Timed Text Markup Language 1 (TTML1) (Second Edition)</a>. See http://www.w3.org/TR/ttml1/</dd>
  <dt><a name="aria" id="aria"></a>WAI-ARIA</dt>
  <dd><a href="http://www.w3.org/TR/wai-aria/">Accessible Rich Internet Applications (WAI-ARIA) 1.0</a>. See http://www.w3.org/TR/wai-aria/</dd>
  <dd>&nbsp;</dd>
  <dt><a id="ref-wgs">[WGS84]</a></dt>
  <dd><a href="http://earth-info.nga.mil/GandG/publications/tr8350.2/wgs84fin.pdf">National   Imagery and Mapping Agency Technical Report 8350.2, Third Edition</a>.   National Imagery and Mapping Agency, 3 January 2000. See   http://earth-info.nga.mil/GandG/publications/tr8350.2/wgs84fin.pdf </dd>
</dl>
<h2 id="appF">Appendix F. Changes since EMMA 1.0</h2>
<p>This section is <span>I</span>nformative.</p>
<p>
Since the publication of the  EMMA 1.0 Recommendation, the following changes have been made.</p>
<ul>
<li><code> emma:annotation</code> element for specification of human annotations on the input (4.1.9)</li>
<li><code> emma:process-model</code> for specifying a non-grammar model used in processing of the input (4.1.7)</li>
<li><code>emma:parameters</code>, <code>emma:parameter</code> for specification of a set of parameters used to configure a processor (4.1.8)</li>
<li><code>emma:grammar-active, emma:active </code>elements for specifying the specific grammars in a set that were active for a particular interpretation or set of interpretations (4.1.4)</li>
<li><code>emma:expressed-through</code> for specification of the modalities used in order to express an input (4.2.11)</li>
<li><code>emma:result-format</code> for specification of the specific format type for EMMA semantic payloads (4.2.18)</li>
<li><code>emma:info-ref</code> for referencing the emma:info that applies to an interpretation or set of interpretations (4.2.19)</li>
<li>Support for multiple <code>emma:info</code> elements</li>
<li><code>emma:process-model-ref</code> for referencing the <code>emma:process-model </code>that applies to an interpretation or set of interpretations(4.2.20)</li>
<li><code>emma:parameter-ref</code> for referencing the <code>emma:parameters </code>that applies to an interpretation or set of interpretations(4.2.21)<br>
  </li>
<li><code>emma:annotated-tokens</code> shorthand method for adding reference transcription without needing full <code>emma:annotation</code> (4.2.22)</li>
<li>Clarification of differences between <code>emma:medium</code> and <code>emma:mode</code> (4.2.11)</li>
<li>Added touchscreen example to medium/mode table (4.2.11)</li>
<li>Text added to Section 2 to clarify scope of EMMA annotations in<code> emma:one-of</code></li>
<li>Clarification on namespace needing to be overtly specified: (3.1) "Application markup MUST be declared either" in an explicit application namespace, or an undefined namespace by setting xmlns="".</li>
<li>Clarification <code>emma:process</code> can be used as syntax rather than actual reference to process description (4.2.2)</li>
<li>Clarification on use of <code>emma:signal</code> (4.2.6)</li>
<li>Added reference to rfc4627 for JSON</li>
<li>Added example of <code>emma:annotation</code> on lattice <code>emma:arc</code></li>
<li>Added clarification text to 4.1.9 on annotation in whole specification vs the <code>emma:annotation</code> and <code>emma:annotated-tokens </code></li>
<li>Added text in 4.2.15 <code>emma:grammar-ref</code> on use of <code>emma:grammar-ref</code> on <code>emma:active</code> to indicate which grammars are active</li>
<li>Added text to 4.1.7 and 4.1.8 indicating that <code>emma:process-model </code>and <code>emma:parameters</code> are required to have index scope and cannot have scope over interpretations based on their position in the document</li>
<li>Added <code>emma:device-type</code> to 4.2.11 and extended example and added to tables of relevant elements</li>

<li>Added <code>ref</code> to several more elements enabling documents to refer to content on the server: <code>emma:info</code>, <code>emma:parameters</code>, <code>emma:one-of</code>, <code>emma:group</code>, <code>emma:sequence</code>, <code>emma:lattice</code></li>
<li>Replaced <code>src</code> attribute on <code>emma:annotation</code> with <code>ref</code> to keep it consistent with other elements that allow for reference to remote content, and added an example with Emotion ML.</li>
<li>Added new <code>emma:location</code> element enabling annotation of the location of the device capturing the input. 4.1.10</li>
<li>Added <code>prev-doc</code> and <code>doc-ref</code> attributes to <code>emma:emma</code>.</li>
<li>Added ability to specific a lattice and an N-best in a single EMMA document</li>
<li>Added <code>emma:partial-content</code> attribute 4.2.23</li>
<li>Added attributes and mechanisms for incremental results Section 4.2.24</li>
<li>Revisions throughout to support output and description of <code>emma:output</code> in Section 3.3</li>
<li>Extensions to support incremental results (Section 4.2.24)</li>

</ul>

<h2 id="appG">Appendix G. Acknowledgements</h2>
<p>This section is <span>I</span>nformative.</p>
<p>The editors would like to recognize the contributions of the
current and former members of the W3C Multimodal Interaction Group
<em>(listed in alphabetical order)</em>:</p>
<dl>
<dd>Kazuyuki Ashimura, W3C</dd>
<dd>Paolo Baggia (while at Loquendo, currently Nuance Communications)</dd>
<dd>Patrizio Bergallo, (until 2008, while at Loquendo)</dd>
<dd>Michael Bodell (until May 2012, while at Microsoft)</dd>
<dd>Daniel C. Burnett (while at Voxeo)</dd>
<dd>Jerry Carter (while at Nuance Communications)</dd>
<dd>Wu Chou, Avaya</dd>
<dd>Max Froumentin, (until 2006, while at W3C)</dd>
<dd>Katriina Halonen, Nokia</dd>
<dd>Jin Liu, T-Systems</dd>
<dd>Gerry McCobb, Openstream</dd>
<dd>Roberto Pieraccini, (while at Speechcycle)</dd>
<dd>Stephen Potter, (while at Microsoft)</dd>
<dd>Dave Raggett, (until 2007, while at Volantis and Canon)</dd>
<dd>B. Helena Rodriguez, Invited Expert</dd>
<dd>Massimo Romanelli, DFKI</dd>
<dd>Yuan Shao, Canon</dd>
<dd>Raj Tumuluri, Openstream</dd>
<dd>&nbsp;</dd>
<dd>&nbsp;</dd>
<dd>&nbsp;</dd>
<dt>&nbsp;</dt>
<dd>&nbsp;</dd>
<dd>&nbsp;</dd>
<dt>&nbsp;</dt>
</dl>


</body></html>
