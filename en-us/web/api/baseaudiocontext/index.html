<p>{{APIRef(“Web Audio API”)}}</p>
<p>The <code>BaseAudioContext</code> interface of the <a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> acts as a base definition for online and offline audio-processing graphs, as represented by {{domxref(“AudioContext”)}} and {{domxref(“OfflineAudioContext”)}} respectively. You wouldn’t use <code>BaseAudioContext</code> directly — you’d use its features via one of these two inheriting interfaces.</p>
<p>A <code>BaseAudioContext</code> can be a target of events, therefore it implements the {{domxref(“EventTarget”)}} interface.</p>
<p>{{InheritanceDiagram}}</p>
<h2 id="properties">Properties</h2>
<ul>
<li>{{domxref(“BaseAudioContext.audioWorklet”)}} {{experimental_inline}} {{readonlyInline}} {{securecontext_inline}}
<ul>
<li>: Returns the {{domxref(“AudioWorklet”)}} object, which can be used to create and manage {{domxref(“AudioNode”)}}s in which JavaScript code implementing the {{domxref(“AudioWorkletProcessor”)}} interface are run in the background to process audio data.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.currentTime”)}} {{readonlyInline}}
<ul>
<li>: Returns a double representing an ever-increasing hardware time in seconds used for scheduling. It starts at <code>0</code>.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.destination”)}} {{readonlyInline}}
<ul>
<li>: Returns an {{domxref(“AudioDestinationNode”)}} representing the final destination of all audio in the context. It can be thought of as the audio-rendering device.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.listener”)}} {{readonlyInline}}
<ul>
<li>: Returns the {{domxref(“AudioListener”)}} object, used for 3D spatialization.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.sampleRate”)}} {{readonlyInline}}
<ul>
<li>: Returns a float representing the sample rate (in samples per second) used by all nodes in this context. The sample-rate of an {{domxref(“AudioContext”)}} cannot be changed.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.state”)}} {{readonlyInline}}
<ul>
<li>: Returns the current state of the <code>AudioContext</code>.</li>
</ul></li>
</ul>
<h3 id="event-handlers">Event handlers</h3>
<ul>
<li>{{domxref(“BaseAudioContext.onstatechange”)}}
<ul>
<li>: An event handler that runs when an event of type {{event(“statechange”)}} has fired. This occurs when the <code>AudioContext</code>’s state changes, due to the calling of one of the state change methods ({{domxref(“AudioContext.suspend”)}}, {{domxref(“AudioContext.resume”)}}, or {{domxref(“AudioContext.close”)}}).</li>
</ul></li>
</ul>
<h2 id="methods">Methods</h2>
<p><em>Also implements methods from the interface</em> {{domxref(“EventTarget”)}}.</p>
<ul>
<li>{{domxref(“BaseAudioContext.createAnalyser()”)}}
<ul>
<li>: Creates an {{domxref(“AnalyserNode”)}}, which can be used to expose audio time and frequency data and for example to create data visualisations.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createBiquadFilter()”)}}
<ul>
<li>: Creates a {{domxref(“BiquadFilterNode”)}}, which represents a second order filter configurable as several different common filter types: high-pass, low-pass, band-pass, etc</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createBuffer()”)}}
<ul>
<li>: Creates a new, empty {{ domxref(“AudioBuffer”) }} object, which can then be populated by data and played via an {{ domxref(“AudioBufferSourceNode”) }}.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createBufferSource()”)}}
<ul>
<li>: Creates an {{domxref(“AudioBufferSourceNode”)}}, which can be used to play and manipulate audio data contained within an {{ domxref(“AudioBuffer”) }} object. {{ domxref(“AudioBuffer”) }}s are created using {{domxref(“BaseAudioContext/createBuffer”, “AudioContext.createBuffer()”)}} or returned by {{domxref(“BaseAudioContext/decodeAudioData”, “AudioContext.decodeAudioData()”)}} when it successfully decodes an audio track.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createConstantSource()”)}}
<ul>
<li>: Creates a {{domxref(“ConstantSourceNode”)}} object, which is an audio source that continuously outputs a monaural (one-channel) sound signal whose samples all have the same value.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createChannelMerger()”)}}
<ul>
<li>: Creates a {{domxref(“ChannelMergerNode”)}}, which is used to combine channels from multiple audio streams into a single audio stream.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createChannelSplitter()”)}}
<ul>
<li>: Creates a {{domxref(“ChannelSplitterNode”)}}, which is used to access the individual channels of an audio stream and process them separately.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createConvolver()”)}}
<ul>
<li>: Creates a {{domxref(“ConvolverNode”)}}, which can be used to apply convolution effects to your audio graph, for example a reverberation effect.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createDelay()”)}}
<ul>
<li>: Creates a {{domxref(“DelayNode”)}}, which is used to delay the incoming audio signal by a certain amount. This node is also useful to create feedback loops in a Web Audio API graph.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createDynamicsCompressor()”)}}
<ul>
<li>: Creates a {{domxref(“DynamicsCompressorNode”)}}, which can be used to apply acoustic compression to an audio signal.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createGain()”)}}
<ul>
<li>: Creates a {{domxref(“GainNode”)}}, which can be used to control the overall volume of the audio graph.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createIIRFilter()”)}}
<ul>
<li>: Creates an {{domxref(“IIRFilterNode”)}}, which represents a second order filter configurable as several different common filter types.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createOscillator()”)}}
<ul>
<li>: Creates an {{domxref(“OscillatorNode”)}}, a source representing a periodic waveform. It basically generates a tone.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createPanner()”)}}
<ul>
<li>: Creates a {{domxref(“PannerNode”)}}, which is used to spatialise an incoming audio stream in 3D space.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createPeriodicWave()”)}}
<ul>
<li>: Creates a {{domxref(“PeriodicWave”)}}, used to define a periodic waveform that can be used to determine the output of an {{ domxref(“OscillatorNode”) }}.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createScriptProcessor()”)}} {{deprecated_inline}}
<ul>
<li>: Creates a {{domxref(“ScriptProcessorNode”)}}, which can be used for direct audio processing via JavaScript.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createStereoPanner()”)}}
<ul>
<li>: Creates a {{domxref(“StereoPannerNode”)}}, which can be used to apply stereo panning to an audio source.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.createWaveShaper()”)}}
<ul>
<li>: Creates a {{domxref(“WaveShaperNode”)}}, which is used to implement non-linear distortion effects.</li>
</ul></li>
<li>{{domxref(“BaseAudioContext.decodeAudioData()”)}}
<ul>
<li>: Asynchronously decodes audio file data contained in an {{jsxref(“ArrayBuffer”)}}. In this case, the <code>ArrayBuffer</code> is usually loaded from an {{domxref(“XMLHttpRequest”)}}’s <code>response</code> attribute after setting the <code>responseType</code> to <code>arraybuffer</code>. This method only works on complete files, not fragments of audio files.</li>
</ul></li>
</ul>
<h2 id="examples">Examples</h2>
<p>Basic audio context declaration:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode js"><code class="sourceCode javascript"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">const</span> audioContext <span class="op">=</span> <span class="kw">new</span> <span class="at">AudioContext</span>()<span class="op">;</span></a></code></pre></div>
<p>Cross browser variant:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode js"><code class="sourceCode javascript"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">const</span> AudioContext <span class="op">=</span> <span class="va">window</span>.<span class="at">AudioContext</span> <span class="op">||</span> <span class="va">window</span>.<span class="at">webkitAudioContext</span><span class="op">;</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="kw">const</span> audioContext <span class="op">=</span> <span class="kw">new</span> <span class="at">AudioContext</span>()<span class="op">;</span></a>
<a class="sourceLine" id="cb2-3" title="3"></a>
<a class="sourceLine" id="cb2-4" title="4"><span class="kw">const</span> oscillatorNode <span class="op">=</span> <span class="va">audioContext</span>.<span class="at">createOscillator</span>()<span class="op">;</span></a>
<a class="sourceLine" id="cb2-5" title="5"><span class="kw">const</span> gainNode <span class="op">=</span> <span class="va">audioContext</span>.<span class="at">createGain</span>()<span class="op">;</span></a>
<a class="sourceLine" id="cb2-6" title="6"><span class="kw">const</span> finish <span class="op">=</span> <span class="va">audioContext</span>.<span class="at">destination</span><span class="op">;</span></a></code></pre></div>
<h2 id="specifications">Specifications</h2>
<p>{{Specifications}}</p>
<h2 id="browser-compatibility">Browser compatibility</h2>
<p>{{Compat}}</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
<li>{{domxref(“AudioContext”)}}</li>
<li>{{domxref(“OfflineAudioContext”)}}</li>
</ul>
